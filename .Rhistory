#for this one, get rid of track loss rows
filter(trackloss == FALSE) %>%
group_by(recording_name, trial_number) %>%
mutate(looking_stretch_id = data.table::rleid(target)) %>%
group_by(recording_name, trial_number, looking_stretch_id) %>%
#keep stretches that are at least 200 ms or 12 rows
filter(n() >= 12) %>%
mutate(where_looking = case_when(target == TRUE ~ "target",
distractor == TRUE ~ "distractor",
TRUE ~ "neither")) %>%
filter(where_looking != "neither") %>%
distinct(recording_name, trial_number, looking_stretch_id, where_looking, media_name, subject_id) %>%
group_by(recording_name, trial_number) %>%
mutate(AOI_switches = case_when(lag(where_looking) == "target" & where_looking == "distractor" ~ 1,
lag(where_looking) == "distractor" & where_looking == "target" ~ 1)) %>%
group_by(recording_name, trial_number) %>%
summarise(total_aoi_switches = sum(AOI_switches, na.rm = T)) %>%
ungroup()
number_of_switches_by_subject <- number_of_switches_by_trial %>%
group_by(recording_name) %>%
summarise(total_aoi_switches = sum(total_aoi_switches, na.rm = T),
n_trials_total_aoi_switches = length(unique(trial_number))) %>%
ungroup()
#7. Mean latency of refixation during trial - COME BACK TO THIS ------- We decided to eliminate this one because our studies don't have a central image from which to refixate, and when we tried adding a narrow central strip, no one was looking there.
#Mean latency of correct saccadic shifts from the center to the peripheral target (refixations) during the trial.
#I would need to calculate the center point (shouldn't be too hard)
#
# kbh_data_center <- arch_final%>%
#   group_by(studio_project_name, studio_test_name, trial_number, recording_name)%>%
#   mutate(trial_from_zero = recording_timestamp-min(recording_timestamp))%>%
#   group_by(studio_project_name)%>%
#   mutate(noun_onset = case_when(studio_project_name=="CompMix-36"~trial_from_zero-3000, #Substracting noun onset to normalize
#                                 studio_project_name=="LearnMix-36"~trial_from_zero-4500,
#                                 studio_project_name=="Mix-20"~trial_from_zero-5400,
#                                 studio_project_name=="Mix-14"~trial_from_zero-5400,
#                                 studio_project_name=="CogMisp-24"~trial_from_zero-1500))%>%
#   ungroup()%>%
#   rename(target_side=target, distractor_side=distractor,
#          gaze_point_x= gaze_point_x_adc_spx,
#          gaze_point_y = gaze_point_y_adc_spx)%>%
#   mutate(trackloss = case_when(gaze_point_x<0 ~ TRUE,
#                                gaze_point_x> 1920 ~ TRUE,
#                                gaze_point_y<0 ~ TRUE,
#                                gaze_point_y > 1200 ~ TRUE,
#                                is.na(gaze_point_x) ~ TRUE,
#                                is.na(gaze_point_y) ~ TRUE,
#                                is.na(validity_left) ~ TRUE,
#                                is.na(validity_right) ~ TRUE,
#                                validity_left > 1 ~ TRUE,
#                                validity_right > 1 ~ TRUE,
#                                TRUE~ FALSE)) %>% #MAKE VISUALIZATIONS ABOUT TRACKLOSS FOR SANITY CHECK
#   mutate(target = case_when(gaze_point_x >= target_x_min&gaze_point_x <= target_x_max&gaze_point_y >= target_y_min&gaze_point_y <= target_y_max~TRUE,
#                             TRUE~FALSE)) %>%
#   mutate(distractor = case_when(gaze_point_x >= distractor_x_min&gaze_point_x <= distractor_x_max&gaze_point_y >= distractor_y_min&gaze_point_y <= distractor_y_max~TRUE,
#                                  TRUE ~ FALSE)) %>%
#   mutate(looks_to_center = case_when(gaze_point_x >= 950 & gaze_point_x <= 970 &gaze_point_y >= 0&gaze_point_y <= 1080 ~ TRUE,
#                                      TRUE~ FALSE)) %>% #creating a looks to center column
# mutate(where_looking = case_when(target == TRUE & looks_to_center == FALSE~ "target",
#                          target == TRUE & looks_to_center == TRUE~ "center",
#                          distractor == TRUE & looks_to_center == TRUE~ "center",
#                          distractor == TRUE & looks_to_center == FALSE~ "distractor",
#                          target == FALSE & distractor == FALSE & looks_to_center == TRUE ~ "center",
#                          TRUE ~ "neither"))
#
#
# mean_latency_refixation <- kbh_data_center %>%
#   filter(noun_onset >= 360 & noun_onset <= 3000) %>%
#   group_by(recording_name, trial_number) %>%
#   dplyr::select(looks, media_name, studio_project_name, studio_test_name, trial_number, recording_name, recording_timestamp, where_looking) %>%
#   mutate(looking_area_id = data.table::rleid(where_looking)) %>%
#   group_by(recording_name, trial_number, looking_area_id) %>%
#   mutate(how_long_looking_area = n(),
#          length_center_look = case_when(where_looking == "center" ~ how_long_looking_area))
#
#   filter(looks %in% c("target", "center")) %>% #filtering out disctractor looks because I am only interest in latency to look to taget
# group_by(recording_name, media_name) %>%
#   filter("target" %in% looks & "center" %in% looks) %>% #keeping only trials where there were looks to target and to center
#   arrange()%>%
#  filter(!(looks == "target" & lag(looks) == "target")) %>% #getting rid of consecutive target looks because I am not interested in duration of looks to target I am interested in duration of looks to center before the switch.
#  ungroup() %>%
#   mutate(consecutive_looks_center= looks == "center" & lag(looks) == "center") %>%
#     group_by(recording_name, media_name, consecutive_looks_center, looks) %>%
#   reframe(total_time = sum(recording_timestamp)) %>%
#       ungroup()
#
# mean_latency_refixation2 <- mean_latency_refixation %>%
# group_by(recording_name, media_name) %>%
#    filter(looks == "center" & lead(looks) == "target") # not working
#
#   summarise(time_to_refixate = diff(total_time))
#8. Mean fixation duration during trial
#Mean duration of fixations during the window of analysis within a trial. Mean by subject by trial?
mean_fixation_dur_by_trial <- analysis_dataset %>%
filter(noun_onset>= 360 & noun_onset <= 3000)%>%
group_by(recording_name, trial_number) %>%
mutate(trackloss_group_id = data.table::rleid(trackloss)) %>%
group_by(trackloss_group_id, recording_name, trial_number) %>%
mutate(num_consec_trackloss_rows = n()) %>%
ungroup() %>%
filter(trackloss == FALSE | (trackloss == TRUE & num_consec_trackloss_rows >= 2)) %>%
group_by(recording_name, trial_number) %>%
mutate(looking_stretch_id = data.table::rleid(target)) %>%
group_by(recording_name, trial_number, looking_stretch_id) %>%
#filter to fixations of at least 12 rows or ~ 200 ms
filter(n() >= 12) %>%
filter(target == TRUE) %>%
group_by(recording_name, trial_number, media_name, looking_stretch_id) %>%
summarise(length_of_looks = n()) %>%
mutate(duration_of_look = length_of_looks*(1000/60)) %>%
group_by(recording_name, trial_number) %>%
summarise(duration_of_look = mean(duration_of_look, na.rm = T)) %>%
ungroup()
mean_fixation_dur_by_subject <- mean_fixation_dur_by_trial %>%
group_by(recording_name) %>%
summarise(mean_duration_of_look = mean(duration_of_look, na.rm = T),
sd_duration_of_look = sd(duration_of_look, na.rm = T),
n_trials_duration_of_look = length(unique(trial_number))) %>%
ungroup()
#When you have time make some of the calculations by hand to make sure the duration is correct.
#I guess here is by subject the mean duration. But check on the paper.
#9. Proportion of fixation duration (better named target divergence time)
#The target divergence time measure is defined as the time at which fixations to the “target” object diverges from fixations to the “distractor”. point-by-point t-tests at each 10 ms bin between mean looking proportions to the target object and mean looking proportions to the distractor object were calculated. the time point reported is the earliest time point that a minimum of five consecutive two tailed t-tests with an alpha level of p < .05 indicate a significant difference between the fixation to the target compared to distractor
#What we need to do in our research: By participant, collapsing across trials average prop looking to target and average proportion looking to distractor eavery 17ms (or whatever or bin size is). So at that stage the participant has 2 columns with 8 rows (1 row per trial), one column for the average prop looks to target, one for the average prop looks to distractor. THEN we do a t test between column A and B, so we get column C that again has 8 rows (this is a rowwise t test, bonferroni corrected I guess). Then we summarize to get a single number per participant. that number is the ms slice at which 5 (?) t-tests are p>0.05.
#Get average looking to target and looking to distractor for each 220-ms time bin (the reference paper used 10-ms time bins, but their eyetracker sampled every 2ms and ours only did ever 16-17 ms)
divergence_point <- analysis_dataset %>%
filter(noun_onset>= -2000 & noun_onset <= 3000)%>%
#make timestamp that is offset by the time it takes to initiate a look, related to the noun onset
mutate(timestamp_zero_interest_period = noun_onset - 360) %>%
ungroup()%>%
group_by(recording_name, trial_number, media_name, age_months) %>%
#Need to align timestamps for each trial, so make the one closest to 0 equal zero and then add the eyetracker frame rate for each row
mutate(new_noun_onset = case_when(abs(noun_onset) == min(abs(noun_onset)) ~ 0)) %>%
dplyr::select(recording_name, trial_number, recording_timestamp, trial_from_zero, noun_onset, new_noun_onset, target, distractor, trackloss, age_months) %>%
mutate(parallel_timestamp = (row_number() - which(new_noun_onset == 0))*(1000/60),
parallel_timestamp = round(parallel_timestamp)) %>%
dplyr::select(media_name, recording_name, trial_number, parallel_timestamp, target, distractor, trackloss, age_months) %>%
pivot_longer(c(target, distractor), names_to = "aoi", values_to = "value") %>%
arrange(recording_name, trial_number, aoi, parallel_timestamp) %>%
mutate(value = as.numeric(value)) %>%
filter(trackloss == FALSE) %>%
ungroup() %>%
mutate(age_group = case_when(age_months >= 14 & age_months < 21 ~ "14-20",
age_months >= 21 & age_months < 31 ~ "21-30",
age_months >= 31 & age_months < 51 ~ "31-48"))
divergence_plot_data <- divergence_point %>%
group_by(recording_name, aoi, parallel_timestamp, age_group) %>%
summarise(mean_fixation = mean(value))
#This takes a little while to run because of the bootstrapping
divergence_plot <- ggplot(divergence_plot_data, aes(x=parallel_timestamp, y=mean_fixation, colour=aoi)) +
geom_vline(xintercept=0, linetype="dashed", colour="gray28") +
stat_summary(fun.data=mean_cl_boot, aes(fill=aoi),
geom="ribbon", alpha=.2, linetype="blank") +
stat_summary(fun=mean, geom="path",
aes(group=aoi, linetype=aoi), size=.7) + facet_wrap(~age_group)
divergence_point_stat <- divergence_point %>%
#reduce the time span for calculating stats since the bootstrapping takes a while.
filter(parallel_timestamp >= -500 & parallel_timestamp <= 2500)
#Apply statistical test to each time point
divergence_p_table <- divergence_point_stat %>%
# select only rows in the dataframe where a fixation occurred
filter(value == 1) %>%
# label fixations that were on the target as 1 and as 0 otherwise,
mutate(looking_to_target = ifelse(aoi == "target", 1, 0)) %>%
# we want to test for each timepoint at each age group
group_by(parallel_timestamp, age_group) %>%
# apply logistic regression and extract z-values
summarise(z = summary(lme4::glmer(looking_to_target ~ 1 +
(1|recording_name), family="binomial",
control=lme4::glmerControl(calc.derivs=FALSE)))$coefficients[1,3]) %>%
# add p-values
mutate(p = pnorm(-abs(z))*2)
# Set alpha level and calculate Bonferroni correction
alpha           <- 0.05
N_tests         <- length(unique(divergence_point_stat$parallel_timestamp))
alpha_corrected <- alpha/N_tests
# Find the earliest timepoint with a significant uncorrected p-value
(uncorr <- divergence_p_table %>%
group_by(age_group) %>%
# extract positive z-scores ("target advantage") and significant p-values
filter(z > 0, p < alpha) %>%
# extract the earliest significant p-value and its timepoint
slice(1))
# Find the earliest timepoint that survives the Bonferroni correction
(bnf <- divergence_p_table %>%
group_by(age_group) %>%
filter(z > 0, p < alpha_corrected) %>%
slice(1))
# Find the earliest timepoint after FDR control
(fdr <- divergence_p_table %>%
group_by(age_group) %>%
# apply FDR control from `stats` package
mutate(p_fdr = stats::p.adjust(p, method = "BY", n = length(p))) %>%
filter(z > 0, p_fdr < alpha) %>%
slice(1))
plot_points <- tibble(correction = c(rep("Uncorrected", 3), rep("Bonferroni", 3), rep("FDR", 3)),
age_group = rep(c("14-20", "21-30", "31-48"),3),
mean_fixation = .5,
aoi = "target")  %>%
left_join(uncorr %>% dplyr::select(parallel_timestamp, age_group) %>% mutate(correction = "Uncorrected") %>%
bind_rows(bnf %>% dplyr::select(parallel_timestamp, age_group) %>% mutate(correction = "Bonferroni")) %>%
bind_rows(fdr%>% dplyr::select(parallel_timestamp, age_group) %>% mutate(correction = "FDR")))
overall_divergence_plot <- ggplot(divergence_plot_data, aes(x=parallel_timestamp, y=mean_fixation, colour=aoi)) +
geom_vline(xintercept=0, linetype="dashed", colour="gray28") +
stat_summary(fun.data=mean_cl_boot, aes(fill=aoi),
geom="ribbon", alpha=.2, linetype="blank") +
stat_summary(fun=mean, geom="path",
aes(group=aoi, linetype=aoi), size=.7) +
facet_wrap(~age_group) +
geom_point(data = plot_points, color = "black", aes(shape = plot_points$correction))
#Apply statistical test to each time point for each kid
divergence_p_table_by_subject <- divergence_point_stat %>%
# select only rows in the dataframe where a fixation occurred
filter(value == 1) %>%
# label fixations that were on the target as 1 and as 0 otherwise,
mutate(looking_to_target = ifelse(aoi == "target", 1, 0)) %>%
# we want to test for each timepoint for each subject
group_by(parallel_timestamp, recording_name) %>%
# apply logistic regression and extract z-values
summarise(z = summary(glm(looking_to_target ~ 1, family="binomial"))$coefficients[1,3]) %>%
# add p-values
mutate(p = pnorm(-abs(z))*2)
# Find the earliest timepoint with a significant uncorrected p-value
(uncorr_by_subject <- divergence_p_table_by_subject %>%
group_by(recording_name) %>%
# extract positive z-scores ("target advantage") and significant p-values
filter(z > 0, p < alpha) %>%
# extract the earliest significant p-value and its timepoint
slice(1))
# Find the earliest timepoint that survives the Bonferroni correction ----------- Looks like when you split by subject, there isn't enough data for the corrected p values to be significant, so statistically, individual children don't have a divergence point after correcting
(bnf_by_subject <- divergence_p_table_by_subject %>%
group_by(recording_name) %>%
filter(z > 0, p < alpha_corrected) %>%
slice(1))
# Find the earliest timepoint after FDR control
(fdr_by_subject <- divergence_p_table_by_subject %>%
group_by(recording_name) %>%
# apply FDR control from `stats` package
mutate(p_fdr = stats::p.adjust(p, method = "BY", n = length(p))) %>%
filter(z > 0, p_fdr < alpha) %>%
slice(1))
#10. Pupil dilation
#Baseline pupil size in the 200ms before noun onset and then subtracted the baseline from the pupil size measurements on each trial.
#In Liz's paper they contrasted time slice by time slice across two conditions, but here we don't have switched and same language conditions. I'll do average size at baseline and avg size after noun onset for now. But then talk with team about it.
pupil_dilation <- analysis_dataset %>%
ungroup() %>%
filter(noun_onset>= -200 & noun_onset <= 500)%>%
mutate(pupil_period = case_when(noun_onset >= -200 & noun_onset <= 0 ~ "baseline",
TRUE ~ "post_onset"))%>%
dplyr::select(recording_timestamp, subject_id, recording_name, trial_number, media_name, pupil_period, pupil_right, pupil_left) %>%
mutate(two_pupil_mean = case_when(is.na(pupil_left) & is.na(pupil_right) ~ NA,
is.na(pupil_left)  ~ pupil_right,
is.na(pupil_right) ~ pupil_left,
TRUE ~ (pupil_left + pupil_right)/2)) %>%
filter(!is.na(two_pupil_mean))
#The next steps are confusing to me.Should we average baseline pupil? Should we contrast each post onset time slice to a partricular baseline time slice? We could use mean dilation, peak dilation (or peak amplitude), and/or peak latency (i.e., the time between onset and peak pupil dilation). The problem with mean dilation is that the baseline has less sampling than the post-onset. Could we do peak dilation of baseline vs. peak dilation post onset? Or peak dilation but from which baseline point? from peak? We will for sure do GCA's as extra analyses
#Peak dilation
peak_dilation_by_trial <- pupil_dilation %>%
ungroup()%>%
group_by(trial_number, recording_name, pupil_period) %>%
summarise(peak_pupil = max(two_pupil_mean)) %>%
pivot_wider(names_from = pupil_period, values_from ="peak_pupil")%>%
mutate(peak_pupil_size_difference = post_onset - baseline) %>% #difference in peak pupil points
filter(!is.na(peak_pupil_size_difference)) %>%
rename(max_pupil_baseline = baseline,
max_pupil_post_onset = post_onset) %>%
ungroup()
peak_dilation_by_subject <- peak_dilation_by_trial %>%
group_by(recording_name) %>%
summarise(mean_peak_pupil_size_difference = mean(peak_pupil_size_difference),
sd_peak_pupil_size_difference = sd(peak_pupil_size_difference),
n_trials_peak_pupil_size_difference = length(unique(trial_number))) %>%
ungroup()
#Mean dilation
mean_dilation_by_trial <- pupil_dilation %>%
ungroup()%>%
group_by(trial_number, recording_name, pupil_period) %>%
summarise(mean_pupil = mean(two_pupil_mean, na.rm = T)) %>%
pivot_wider(names_from = pupil_period, values_from ="mean_pupil")%>%
mutate(mean_pupil_size_difference = post_onset - baseline) %>% #difference in peak pupil points
filter(!is.na(mean_pupil_size_difference)) %>%
rename(mean_pupil_baseline = baseline,
mean_pupil_post_onset = post_onset) %>%
ungroup()
mean_dilation_by_subject <- mean_dilation_by_trial %>%
group_by(recording_name) %>%
summarise(mean_mean_pupil_size_difference = mean(mean_pupil_size_difference),
sd_mean_pupil_size_difference = sd(mean_pupil_size_difference),
n_trials_mean_pupil_size_difference = length(unique(trial_number))) %>%
ungroup()
#peak latency
peak_pupil_latency_by_trial <- pupil_dilation %>%
ungroup()%>%
group_by(trial_number, recording_name, pupil_period) %>%
slice(which.max(two_pupil_mean)) %>%
dplyr::select(recording_name, pupil_period, peak_time_stamp = recording_timestamp) %>%
group_by(trial_number, recording_name) %>%
summarise(peak_pupil_latency = diff(peak_time_stamp)) %>%
ungroup()
peak_pupil_latency_by_subject <- peak_pupil_latency_by_trial %>%
group_by(recording_name) %>%
summarise(mean_peak_pupil_latency = mean(peak_pupil_latency),
sd_peak_pupil_latency = sd(peak_pupil_latency),
n_trials_peak_pupil_latency = length(unique(trial_number)))
#11. Duration of first look
### Duration of the first look recorded toward a particular AOI. - To target specifically, with at least 200 ms fixation length
first_look_duration_by_trial <- analysis_dataset %>%
ungroup() %>%
filter(noun_onset >= 360 & noun_onset <= 3000) %>%
group_by(recording_name, trial_number) %>%
mutate(looking_stretch_id = data.table::rleid(target)) %>%
group_by(recording_name, trial_number, looking_stretch_id) %>%
mutate(row = row_number()) %>%
mutate(where_looking = case_when(target == TRUE ~ "target",
distractor == TRUE ~ "distractor",
TRUE ~ "neither")) %>%
filter(where_looking == "target") %>%
mutate(first_look_dur = max(row_number())*(1000/60)) %>%
filter(first_look_dur >= 200) %>%
group_by(trial_number, recording_name) %>%
filter(looking_stretch_id == min(looking_stretch_id)) %>%
ungroup() %>%
distinct(recording_name, trial_number, media_name, first_look_dur) %>%
ungroup()
first_look_duration_by_subject <- first_look_duration_by_trial %>%
group_by(recording_name) %>%
summarise(mean_first_look_dur = mean(first_look_dur, na.rm = T),
sd_first_look_dur = sd(first_look_dur, na.rm = T),
n_trials_first_look_dur = length(unique(trial_number))) %>%
ungroup()
data_new_dvs_by_trial <- analysis_dataset %>%
distinct(recording_name, trial_number, yoked_pair, target_word, age_months, exp_to_target_lang) %>%
left_join(prop_looking_by_trial) %>%
#double check if kids see the same word more than once... if so, this item will be ducplicated in the dataset
left_join(prop_looking_diff_by_item) %>%
# commenting out for now until we verify how to do this one left_join(sampling_fixations_total %>% dplyr::select(-subject_id)) %>%
left_join(fixations_total_by_trial) %>%
left_join(prop_shifts_distractor_initial_by_trial) %>%
left_join(prop_shifts_target_initial_by_subject) %>%
left_join(RT_by_trial) %>%
left_join(number_of_switches_by_trial) %>%
left_join(mean_fixation_dur_by_trial) %>%
left_join(peak_dilation_by_trial) %>%
left_join(mean_dilation_by_trial) %>%
left_join(peak_pupil_latency_by_trial) %>%
left_join(first_look_duration_by_trial) %>%
ungroup() %>%
mutate(exp_to_target_lang_centred = (exp_to_target_lang/100)-.5,
age_months_centred = age_months - 25,
correct_shift = case_when(correct_shift == T ~ 1,
correct_shift == F ~ 0))
data_new_dvs_by_subject <- analysis_dataset %>%
distinct(recording_name, age_months, exp_to_target_lang, fre_exp, eng_exp) %>% #Added french and english exposure to be able to calculate balance for some analyses.
left_join(prop_looking_by_subject) %>%
#double check if kids see the same word more than once... if so, this item will be ducplicated in the dataset
left_join(prop_looking_diff_by_subject) %>%
# commenting out for now until we verify how to do this one left_join(sampling_fixations_total %>% dplyr::select(-subject_id)) %>%
left_join(mean_num_fixations_by_subject) %>%
left_join(prop_shifts_distractor_initial_by_subject) %>%
left_join(prop_shifts_target_initial_by_subject) %>%
left_join(RT_by_subject) %>%
left_join(number_of_switches_by_subject) %>%
left_join(mean_fixation_dur_by_subject) %>%
left_join(peak_dilation_by_subject) %>%
left_join(mean_dilation_by_subject) %>%
left_join(peak_pupil_latency_by_subject) %>%
left_join(first_look_duration_by_subject) %>%
ungroup()%>%
mutate(exp_to_target_lang_centred = (exp_to_target_lang/100)-.5,
age_months_centred = age_months - 25)
#export to get means, SDs for calculating Cohen's D when dataset is run with the other experimental type
data_new_dvs_by_subject %>% write_csv(here(paste0("by_subject_means_sds_", analysis_type, ".csv")))
#How many trials in average when we collapse by subject?
data_new_dvs_by_trial %>%
group_by(recording_name) %>%
summarise(num_trials = length(unique(trial_number))) %>%
summarise(avg_num_trials = mean(num_trials))
#Save datasets (run depending on which dataset is loaded)
#Non-Experimental trials
#save(data_new_dvs_by_subject, file= here("ALL_DVs_datasets/kbh_bysubject_nonexperimental.Rda"))
#Experimental trials
#save(data_new_dvs_by_subject, file= here("ALL_DVs_datasets/kbh_bysubject_experimental.Rda"))
icc_prop_looking <- data_new_dvs_by_trial %>%
dplyr::select(c(recording_name, prop_looking)) %>%
group_by(recording_name) %>%
mutate(ntrial = row_number()) %>%
pivot_wider(names_from = ntrial, values_from = prop_looking) %>%
#The code up to here makes the data wide with one row per subject and one DV value per trial (trials = cols)
ungroup() %>%
dplyr::select(where(is.numeric))
icc_prop_looking_diff <- data_new_dvs_by_trial %>%
dplyr::select(c(recording_name, prop_looking_diff)) %>%
group_by(recording_name) %>%
mutate(ntrial = row_number()) %>%
pivot_wider(names_from = ntrial, values_from = prop_looking_diff) %>%
#The code up to here makes the data wide with one row per subject and one DV value per trial (trials = cols)
ungroup() %>%
dplyr::select(where(is.numeric))
icc_number_fixations <- data_new_dvs_by_trial %>%
dplyr::select(c(recording_name, number_fixations)) %>%
group_by(recording_name) %>%
mutate(ntrial = row_number()) %>%
pivot_wider(names_from = ntrial, values_from = number_fixations) %>%
#The code up to here makes the data wide with one row per subject and one DV value per trial (trials = cols)
ungroup() %>%
dplyr::select(where(is.numeric))
icc_prop_shift_distractor_initial <- data_new_dvs_by_trial %>%
dplyr::select(c(recording_name, prop_shift_distractor_initial)) %>%
group_by(recording_name) %>%
mutate(ntrial = row_number()) %>%
pivot_wider(names_from = ntrial, values_from = prop_shift_distractor_initial) %>%
#The code up to here makes the data wide with one row per subject and one DV value per trial (trials = cols)
ungroup() %>%
dplyr::select(where(is.numeric))
colnames(data_new_dvs_by_trial)
icc_prop_shift_distractor_initial <- data_new_dvs_by_trial %>%
dplyr::select(c(recording_name, correct_shift)) %>%
group_by(recording_name) %>%
mutate(ntrial = row_number()) %>%
pivot_wider(names_from = ntrial, values_from = correct_shift) %>%
#The code up to here makes the data wide with one row per subject and one DV value per trial (trials = cols)
ungroup() %>%
dplyr::select(where(is.numeric))
icc_prop_shift_target_initial <- data_new_dvs_by_trial %>%
dplyr::select(c(recording_name, mean_prop_shift_target_initial)) %>%
group_by(recording_name) %>%
mutate(ntrial = row_number()) %>%
pivot_wider(names_from = ntrial, values_from = mean_prop_shift_target_initial) %>%
#The code up to here makes the data wide with one row per subject and one DV value per trial (trials = cols)
ungroup() %>%
dplyr::select(where(is.numeric))
icc_mean_RT <- data_new_dvs_by_trial %>%
dplyr::select(c(recording_name, latency_to_switch)) %>%
group_by(recording_name) %>%
mutate(ntrial = row_number()) %>%
pivot_wider(names_from = ntrial, values_from = latency_to_switch) %>%
#The code up to here makes the data wide with one row per subject and one DV value per trial (trials = cols)
ungroup() %>%
dplyr::select(where(is.numeric))
icc_aoi_switches <- data_new_dvs_by_trial %>%
dplyr::select(c(recording_name, total_aoi_switches)) %>%
group_by(recording_name) %>%
mutate(ntrial = row_number()) %>%
pivot_wider(names_from = ntrial, values_from = total_aoi_switches) %>%
#The code up to here makes the data wide with one row per subject and one DV value per trial (trials = cols)
ungroup() %>%
dplyr::select(where(is.numeric))
icc_duration_of_look <- data_new_dvs_by_trial %>%
dplyr::select(c(recording_name, duration_of_looks)) %>%
group_by(recording_name) %>%
mutate(ntrial = row_number()) %>%
pivot_wider(names_from = ntrial, values_from = duration_of_look) %>%
#The code up to here makes the data wide with one row per subject and one DV value per trial (trials = cols)
ungroup() %>%
dplyr::select(where(is.numeric))
icc_duration_of_look <- data_new_dvs_by_trial %>%
dplyr::select(c(recording_name, duration_of_look)) %>%
group_by(recording_name) %>%
mutate(ntrial = row_number()) %>%
pivot_wider(names_from = ntrial, values_from = duration_of_look) %>%
#The code up to here makes the data wide with one row per subject and one DV value per trial (trials = cols)
ungroup() %>%
dplyr::select(where(is.numeric))
icc_peak_pupil_size_difference <- data_new_dvs_by_trial %>%
dplyr::select(c(recording_name, peak_pupil_size_difference)) %>%
group_by(recording_name) %>%
mutate(ntrial = row_number()) %>%
pivot_wider(names_from = ntrial, values_from = peak_pupil_size_difference) %>%
#The code up to here makes the data wide with one row per subject and one DV value per trial (trials = cols)
ungroup() %>%
dplyr::select(where(is.numeric))
icc_mean_pupil_size_difference <- data_new_dvs_by_trial %>%
dplyr::select(c(recording_name, mean_pupil_size_difference)) %>%
group_by(recording_name) %>%
mutate(ntrial = row_number()) %>%
pivot_wider(names_from = ntrial, values_from = mean_pupil_size_difference) %>%
#The code up to here makes the data wide with one row per subject and one DV value per trial (trials = cols)
ungroup() %>%
dplyr::select(where(is.numeric))
icc_peak_pupil_latency <- data_new_dvs_by_trial %>%
dplyr::select(c(recording_name, peak_pupil_latency)) %>%
group_by(recording_name) %>%
mutate(ntrial = row_number()) %>%
pivot_wider(names_from = ntrial, values_from = peak_pupil_latency) %>%
#The code up to here makes the data wide with one row per subject and one DV value per trial (trials = cols)
ungroup() %>%
dplyr::select(where(is.numeric))
icc_first_look_dur <- data_new_dvs_by_trial %>%
dplyr::select(c(recording_name, first_look_dur)) %>%
group_by(recording_name) %>%
mutate(ntrial = row_number()) %>%
pivot_wider(names_from = ntrial, values_from = first_look_dur) %>%
#The code up to here makes the data wide with one row per subject and one DV value per trial (trials = cols)
ungroup() %>%
dplyr::select(where(is.numeric))
ICC(icc_prop_looking , missing = FALSE, lmer = TRUE, alpha=.05)
ICC(icc_prop_looking , missing = FALSE, lmer = TRUE, alpha=.05)
ICC(icc_prop_looking_diff , missing = FALSE, lmer = TRUE, alpha=.05)
ICC(icc_number_fixations  , missing = FALSE, lmer = TRUE, alpha=.05)
ICC(icc_prop_shift_distractor_initial, missing = FALSE, lmer = TRUE, alpha=.05)
ICC(icc_prop_shift_target_initial , missing = FALSE, lmer = TRUE, alpha=.05)
ICC(icc_mean_RT , missing = FALSE, lmer = TRUE, alpha=.05)
ICC(icc_duration_of_look , missing = FALSE, lmer = TRUE, alpha=.05)
ICC(icc_mean_pupil_size_difference , missing = FALSE, lmer = TRUE, alpha=.05)
ICC(icc_peak_pupil_size_difference , missing = FALSE, lmer = TRUE, alpha=.05)
ICC(icc_peak_pupil_latency , missing = FALSE, lmer = TRUE, alpha=.05)
ICC(icc_first_look_dur , missing = FALSE, lmer = TRUE, alpha=.05)
ICC(icc_mean_RT , missing = FALSE, lmer = TRUE, alpha=.05)
ICC(icc_duration_of_look , missing = FALSE, lmer = TRUE, alpha=.05) #
ICC(icc_mean_pupil_size_difference , missing = FALSE, lmer = TRUE, alpha=.05)
ICC(icc_peak_pupil_size_difference , missing = FALSE, lmer = TRUE, alpha=.05)
ICC(icc_peak_pupil_latency , missing = FALSE, lmer = TRUE, alpha=.05)
ICC(icc_first_look_dur , missing = FALSE, lmer = TRUE, alpha=.05)
