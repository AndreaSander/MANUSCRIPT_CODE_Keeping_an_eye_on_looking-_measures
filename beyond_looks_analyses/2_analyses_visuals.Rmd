---
title: "2_Analyses_and_visuals"
author: "ASM"
date: "2023-10-25"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r call in libraries and clean data, include=FALSE}
library(here)
library(dplyr)
library(stringr)
library(Hmisc)
library(corrplot)
library(zoo)
library(tidyverse)
library(eyetrackingR)

load(here("archival_KBH_anonimyzed/arch_final.Rda"))
```


```{r clean data to be used in analyses}

kbh_data_clean <- arch_final%>%
  group_by(studio_project_name, studio_test_name, trial_number, recording_name)%>%
  mutate(trial_from_zero = recording_timestamp-min(recording_timestamp))%>%
  group_by(studio_project_name)%>%
  mutate(noun_onset = case_when(studio_project_name=="CompMix-36"~trial_from_zero-3000, #Substracting noun onset to normalize
                                studio_project_name=="LearnMix-36"~trial_from_zero-4500,
                                studio_project_name=="Mix-20"~trial_from_zero-5400,
                                studio_project_name=="Mix-14"~trial_from_zero-5400,
                                studio_project_name=="CogMisp-24"~trial_from_zero-1500))%>%
  ungroup()%>%
  rename(target_side=target, distractor_side=distractor,
         gaze_point_x= gaze_point_x_adc_spx, 
         gaze_point_y = gaze_point_y_adc_spx)%>%
  mutate(trackloss = case_when(gaze_point_x<0 ~ TRUE,
                               gaze_point_x> 1920 ~ TRUE,
                               gaze_point_y<0 ~ TRUE,
                               gaze_point_y > 1200 ~ TRUE,
                               is.na(gaze_point_x) ~ TRUE,
                               is.na(gaze_point_y) ~ TRUE,
                               is.na(validity_left) ~ TRUE,
                               is.na(validity_right) ~ TRUE,
                               validity_left > 1 ~ TRUE,
                               validity_right > 1 ~ TRUE,
                               TRUE~ FALSE)) %>% #MAKE VISUALIZATIONS ABOUT TRACKLOSS FOR SANITY CHECK
  mutate(target = case_when(gaze_point_x >= target_x_min&gaze_point_x <= target_x_max&gaze_point_y >= target_y_min&gaze_point_y <= target_y_max~TRUE, 
                            TRUE~FALSE)) %>%
  mutate(distractor = case_when(gaze_point_x >= distractor_x_min&gaze_point_x <= distractor_x_max&gaze_point_y >= distractor_y_min&gaze_point_y <= distractor_y_max~TRUE, 
                                 TRUE ~ FALSE))

#Create trial language column to describe the language in which the babies were tested
kbh_data_clean <- kbh_data_clean %>%
  ungroup()%>%
  group_by(studio_test_name, eng_exp, fre_exp)%>%
  mutate(trial_lang = case_when(str_detect(studio_test_name,"E")~ "english",
                                str_detect(studio_test_name, "F")~ "french")) %>%
  mutate(exp_to_target_lang = case_when(trial_lang == "english" ~ eng_exp,
                                        trial_lang == "french" ~ fre_exp))


#Add a column with the yolked pairs information---yoking info taken from lab server

kbh_w_items<- kbh_data_clean %>%
mutate(yolked_pair = case_when(
  grepl("Ear|Spoon", media_name) & studio_project_name== "CompMix-36" & grepl("E", studio_test_name) ~"ear-spoon",
  grepl("Apple|Toothbrush", media_name) & studio_project_name== "CompMix-36" & grepl("E", studio_test_name) ~"apple-toothbrush",
  grepl("Fish|Duck", media_name) & studio_project_name== "CompMix-36" & grepl("E", studio_test_name) ~"fish-duck",
  grepl("Sheep|Monkey", media_name) & studio_project_name== "CompMix-36" & grepl("E", studio_test_name) ~"sheep-monkey",
  grepl("Dog|Bunny", media_name) & studio_project_name== "CompMix-36" & grepl("E", studio_test_name) ~"dog-bunny",
  grepl("Hand|Door", media_name) & studio_project_name== "CompMix-36" & grepl("E", studio_test_name) ~"hand-door",
  grepl("Pencil|Coat", media_name) & studio_project_name== "CompMix-36" & grepl("E", studio_test_name) ~"pencil-coat",
  grepl("Froggy|Cow", media_name) & studio_project_name== "CompMix-36" & grepl("E", studio_test_name) ~"froggy-cow",
 
  
    grepl("Ear|Spoon", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~"oreille-cuillere",
  grepl("Apple|Toothbrush", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~"pomme-brosse a dents",
  grepl("Fish|Duck", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~"poisson-canard",
  grepl("Sheep|Monkey", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~"mouton-singe",
  grepl("Dog|Bunny", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~"chien-lapin",
  grepl("Hand|Door", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~"main-porte",
  grepl("Pencil|Coat", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~"crayon-manteau",
  grepl("Froggy|Cow", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~"grenouille-vache",
  
   
   studio_project_name== "LearnMix-36"& media_name %in% 
    c("FR_Single_ChienWalem_R.wmv", "FR_Single_LapinWalem_L.wmv", "FR_Single_LapinTeelo_R.wmv", "FR_Single_ChienTeelo_L.wmv")~ "chien-lapin",
  
     studio_project_name== "LearnMix-36"& media_name %in% 
    c("EN_Single_DogWalem_R.wmv", "EN_Single_BunnyWalem_L.wmv","EN_Single_DogTeelo_L.wmv", "EN_Single_BunnyTeelo_R.wmv")
  ~ "dog-bunny",
  
    studio_project_name== "LearnMix-36"& media_name %in% 
    c("FR_Single_LapinTeelo_L.wmv", "FR_Single_PoissonTeelo_L.wmv","FR_Single_PoissonWalem_R.wmv", "FR_Single_LapinWalem_R.wmv")
  ~ "poisson-lapin",
  
      studio_project_name== "LearnMix-36"& media_name %in% 
    c("EN_Single_BunnyTeelo_L.wmv", "EN_Single_FishTeelo_L.wmv","EN_Single_FishWalem_R.wmv", "EN_Single_BunnyWalem_R.wmv")
  ~ "fish-bunny",
  
      studio_project_name== "LearnMix-36"& media_name %in% c( "FR_Single_ChienWalem_L.wmv","FR_Single_PoissonWalem_L.wmv","FR_Single_PoissonTeelo_R.wmv", "FR_Single_ChienTeelo_R.wmv") 
  ~ "poisson-chien",
 
      studio_project_name== "LearnMix-36"& media_name %in% c( "EN_Single_FishWalem_L.wmv",
"EN_Single_DogWalem_L.wmv","EN_Single_FishTeelo_R.wmv", "EN_Single_DogTeelo_R.wmv") 
  ~ "fish-dog", 

  grepl("banC|girC", media_name) & studio_project_name== "CogMisp-24"  ~"banana-giraffe",
  grepl("monC|butC", media_name) & studio_project_name=="CogMisp-24" ~"monkey-butterfly",
  grepl("winC|mouC", media_name) & studio_project_name== "CogMisp-24" ~"window-mouth",
  grepl("pizC|tabC", media_name) & studio_project_name== "CogMisp-24" ~"pizza-table",
  grepl("choC|bowC", media_name) & studio_project_name== "CogMisp-24" ~"chocolate-bowl",
  grepl("fooC|cooC", media_name) & studio_project_name== "CogMisp-24"~"cookie-foot",


  grepl("Toothbrush|Apple", media_name) & studio_project_name %in% c("Mix-20","Mix-14")  ~"toothbrush-apple",
  grepl("Ear|Spoon", media_name) & studio_project_name %in% c("Mix-20","Mix-14")  ~"ear-spoon",
  grepl("Mouth|Door", media_name) & studio_project_name %in% c("Mix-20","Mix-14")  ~"mouth-door",
  grepl("Bird|Hand", media_name) & studio_project_name %in% c("Mix-20","Mix-14")  ~"bird-hand",
  grepl("Dog|Book", media_name) & studio_project_name %in% c("Mix-20","Mix-14")  ~"dog-book",
  grepl("Cookie|Foot", media_name) & studio_project_name %in% c("Mix-20","Mix-14") ~"cookie-foot",

  grepl("Brosse|Pomme", media_name) & studio_project_name %in% c("Mix-20","Mix-14")  ~"brosse a dents-pomme",
  grepl("Oreille|Cuillere", media_name) & studio_project_name %in% c("Mix-20","Mix-14")  ~"oreille-cuillere",
  grepl("Bouche|Porte", media_name) & studio_project_name %in% c("Mix-20","Mix-14")  ~"bouche-porte",
  grepl("Hand|Main", media_name) & studio_project_name %in% c("Mix-20","Mix-14")  ~"oisseau-main",
  grepl("Chien|Livre", media_name) & studio_project_name %in% c("Mix-20","Mix-14")  ~"chien-livre",
  grepl("Biscuit|Pied", media_name) & studio_project_name %in% c("Mix-20","Mix-14") ~"biscuit-pied",

  TRUE~"OTHER"
  )
)



#Adding a column with word tested information
kbh_w_items<- kbh_w_items %>%
  mutate(target_word= case_when(
  grepl("Ear", media_name) ~"ear",
  grepl("Spoon", media_name) ~"spoon",
  grepl("Dog", media_name) ~"dog",
  grepl("Cookie", media_name) ~"cookie",
  grepl("cooC", media_name) ~"cookie",  
  grepl("Mouth", media_name) ~"mouth",
  grepl("mouC", media_name) ~"mouth",
  grepl("Book", media_name) ~"book",
  grepl("Foot", media_name) ~"foot",
   grepl("fooC", media_name) ~"foot",
  grepl("Bird", media_name) ~"bird",
  grepl("Hand", media_name) ~"hand",
  grepl("Toothbrush", media_name) ~"toothbrush",
  grepl("Apple", media_name) ~"apple",
  grepl("Fish", media_name) ~"fish",
  grepl("Bunny", media_name) ~"bunny",
  grepl("Monkey", media_name) ~"monkey",
    grepl("monC", media_name) ~"monkey",
  grepl("butC", media_name) ~"buterfly",
  grepl("Duck", media_name) ~"duck",
  grepl("Sheep", media_name) ~"sheep",
  grepl("Pencil", media_name) ~"pencil",
  grepl("Coat", media_name) ~"coat",
  grepl("Cow", media_name) ~"cow",
  grepl("Froggy", media_name) ~"frog",
  grepl("Door", media_name) ~"door",
  grepl("banC", media_name) ~"banana",
  grepl("winC", media_name) ~"window",
  grepl("pizC", media_name) ~"pizza",
  grepl("fooC", media_name) ~"foot",
  grepl("bowC", media_name) ~"bowl",
  grepl("choC", media_name) ~"chocolate",
  grepl("girC", media_name) ~"giraffe",
  grepl("tabC", media_name) ~"table",
  
  
    grepl("Oreille", media_name) ~"oreille",
  grepl("Cuillere", media_name) ~"cuillere",
  grepl("Chien", media_name) ~"chien",
  grepl("Biscuit", media_name) ~"biscuit",
  grepl("Bouche", media_name) ~"bouche",
  grepl("Livre", media_name) ~"livre",
  grepl("Pied", media_name) ~"pied",
  grepl("Oisseau", media_name) ~"oisseau",
  grepl("Main", media_name) ~"main",
  grepl("Porte", media_name) ~"porte",
  grepl("Brosse", media_name) ~"brosse a dents",
  grepl("Pomme", media_name) ~"pomme",
  grepl("Poisson", media_name) ~"poisson",
  grepl("Lapin", media_name) ~"lapin",
  grepl("Ear", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "oreille",
  grepl("Spoon", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "cuillere",
  grepl("Apple", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "pomme",
  grepl("Toothbrush", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "brosse a dents",
   grepl("Fish", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "poisson",
   grepl("Duck", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "canard",
   grepl("Ear", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "oreille",
   grepl("Monkey", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "singe",
   grepl("Sheep", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "sheep",
   grepl("Dog", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "chien",
   grepl("Book", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "livre",
   grepl("Cookie", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "biscuit",
   grepl("Foot", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "pied",
   grepl("Hand", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "main",
   grepl("Door", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "porte",
   grepl("Pencil", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "crayon",
   grepl("Coat", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "manteau",
   grepl("Froggy", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "grenouille",
   grepl("Cow", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "vache",

  TRUE~"OTHER"
  )
)

```


```{r calculate all the different dependent variables}

###### First, create variables that will be useful for the calculations below ## TRY TO DO IT IN THE SAME DATA SET
initial_looks <- kbh_data_clean %>%
  filter(noun_onset >= 260 & noun_onset < 360) %>%
  group_by(recording_name, trial_number, media_name) %>% 
     summarise(
    distractor_count = sum(distractor),
    target_count = sum(target),
    trackloss_count = sum(trackloss)
     )%>%
  mutate(initial_look = case_when(target_count >0 ~ "target",
                                        distractor_count/(distractor_count+trackloss_count) >=0.5 ~ "distractor",
                                        target_count/(target_count +trackloss_count) >=0.5 ~ "target",
                                        TRUE ~ "neither"))

kbh_data_clean <- left_join(kbh_data_clean, initial_looks, by= c("recording_name", "trial_number", "media_name"))

#We arfe considering distractor initial trials as trials where in the first 100 ms ofr the analyses window the child looked at the distractor at least 50% of the time and never looked to target.

#1. Proportion looking to target

prop_looking <- kbh_data_clean %>%
  filter(noun_onset>= 360 & noun_onset <= 3000)%>%
  group_by(recording_name, subject_id, trial_number, media_name, age_months, exp_to_target_lang)%>%
  summarise(samples_target=sum(target),
            samples_distractor=sum(distractor))%>%
  mutate(prop_looking= samples_target/(samples_target + samples_distractor)) %>%
  ungroup()

#2. Proportion looking difference 
#Now it is done but there is something strange happening with learnmix items--to check.
#Within a pair of pictures A and B, the fixation to picture A relative to B when A was the target, minus the fixation #to A when A was the distractor.

#Question if two studies have the same item pair (e.g. dog-apple), should they still be grouped as the same yolked pair? They might have had different carrier sentences but, the words are the same.
#Question: should it be absolute difference or true difference?


prop_looking_diff <- kbh_w_items %>%
  ungroup()%>%
  filter(noun_onset>= 360 & noun_onset <= 3000)%>%
  select(recording_name, recording_timestamp, yolked_pair, target_word, target, distractor)%>%
  group_by(yolked_pair, target_word) %>%
    summarise(samples_target=sum(target),
            samples_distractor=sum(distractor))%>%
  mutate(prop_looking_target= samples_target/(samples_target + samples_distractor)) %>%
  mutate(prop_looking_distractor= samples_distractor/(samples_target + samples_distractor)) %>%
  mutate(prop_look_diff = prop_looking_target-prop_looking_distractor)
  

  
#3. Number of fixations
### Total number of fixations to the target during the window of analyses.
#### Question: What is considered a fixation? --> In TOBII we kept only valid fixations (as in Mills-Smith, 2016), they also excluded by subject and by trial (which we will do).


#constum function to count how many consecutive blocks of looking to target there are each trial.
count_consecutive_blocks <- function(x) {
  r <- rle(x)
  sum(r$values & r$lengths >= 12) #this would be 200ms 
} 


#we defined fixations as the number of consecutive runs within a trial where looks were in the target for at least 200ms while getting rid of short bouts of trackloss (17 to 38 ms)

# Group by subject and summarize consecutive TRUE values in target column

fixations_total <- kbh_data_clean   %>%
   filter(noun_onset >= 360 & noun_onset <= 3000) %>%
   filter(!(lag(trackloss) == FALSE & trackloss == TRUE & lead(trackloss) == TRUE & lead(lead(trackloss))== FALSE))%>%  #This got rid of short tracklosses in a run
filter(!(trackloss == TRUE & lag(trackloss) == FALSE & lead(trackloss) == FALSE))%>%
  group_by(recording_name, subject_id, trial_number, media_name) 
  summarise(consecutive_target = count_consecutive_blocks(target))


  
#4. Correct first shift to target
#On trials where infants were fixated on the distractor upon hearing the target word (i.e., distractor-initial trials), the number of first shifts to the target picture within the 300–1,800 ms window following target word onset, as a proportion of all distractor-initial trials.
  


first_shift_target <- kbh_data_clean %>%
  filter(noun_onset >= 360 & noun_onset <= 1800) %>% #Keeping the shorter window to be consistent with Fernald

  
    #Grouping and summarizing to get by subject by trial flagging of whether there was switching or not.
     group_by(recording_name, subject_id, trial_number, media_name, initial_look) %>%  
  summarise(target = sum(target),
            distractor =  sum(distractor)) %>% #Counting how many looks to target and distractor by timeslice grouped by target or distractor initial trials.
  ungroup() %>%
  mutate(correct_shift = case_when(initial_look == "target" & distractor ==0 ~ TRUE,
                                   initial_look == "distractor" & target >0 ~ TRUE,
                                   TRUE~FALSE)) #Making a column to calculate correct shifts. We defined correct shift as never looking to the distractor on target initial trial, or switching to the taget on distractor initial trials

  prop_shifts_distractor_initial <- first_shift_target %>%
    filter(initial_look == "distractor") %>%
    group_by(recording_name) %>%
    summarise(sum (isTRUE(correct_shift))/sum((isTRUE(correct_shift)+ !isTRUE(correct_shift))))
  
    prop_shifts_target_initial <- first_shift_target %>%
    filter(initial_look == "target") %>%
    group_by(recording_name) %>%
    summarise(sum (isTRUE(correct_shift))/sum((isTRUE(correct_shift)+ !isTRUE(correct_shift))))
  

#5. Reaction time
#Question: How do we define distractor initial trials. Lets define a 100ms pre-analyses window from 260 post noun onset to 360 (the start of analyses window)

RT <- full_join (kbh_data_clean, distractor_initial_trials) %>%
  filter(initial_trial=="distractor_initial") %>%
  filter(noun_onset >= 360 & noun_onset <= 3000)%>%
mutate(first_true = ifelse(target == TRUE & lag(target) == FALSE, 1, 0)) %>%
  filter(first_true == 1) %>%
   group_by(recording_name, subject_id, trial_number, media_name,noun_onset) %>%  
  summarise() %>%
    arrange(recording_name, trial_number, by_group = T) %>%
  mutate(number_of_trial_instance = row_number()) %>%  #I only want to keep the first instance of switch because I am only interested in the latency of the very first switch towards target.
filter(number_of_trial_instance == 1) %>%
  mutate(latency_to_switch = noun_onset - 360)


#6. Total number of switches between AOIs

number_of_switches<- kbh_data_clean  %>%
  filter(noun_onset >= 360 & noun_onset <= 3000) %>%
  mutate(AOI_switches = ifelse(target == TRUE & lag(target) == FALSE | target == FALSE & lag(target) == TRUE, 1, 0))%>%
  filter(AOI_switches == 1) %>%
  group_by(recording_name, subject_id, trial_number, media_name) %>%
  summarise(total_aoi_switches = sum(AOI_switches))

#7. Mean latency of refixation during trial
#Mean latency of correct saccadic shifts from the center to the peripheral target (refixations)  during the trial. 
#I would need to calculate the center point (shouldn't be too hard)

kbh_data_center <- arch_final%>%
  group_by(studio_project_name, studio_test_name, trial_number, recording_name)%>%
  mutate(trial_from_zero = recording_timestamp-min(recording_timestamp))%>%
  group_by(studio_project_name)%>%
  mutate(noun_onset = case_when(studio_project_name=="CompMix-36"~trial_from_zero-3000, #Substracting noun onset to normalize
                                studio_project_name=="LearnMix-36"~trial_from_zero-4500,
                                studio_project_name=="Mix-20"~trial_from_zero-5400,
                                studio_project_name=="Mix-14"~trial_from_zero-5400,
                                studio_project_name=="CogMisp-24"~trial_from_zero-1500))%>%
  ungroup()%>%
  rename(target_side=target, distractor_side=distractor,
         gaze_point_x= gaze_point_x_adc_spx, 
         gaze_point_y = gaze_point_y_adc_spx)%>%
  filter(gaze_point_x>=0 & gaze_point_x<= 1920)%>% #keeps only observations that are in the screen
  filter(gaze_point_y>=0 & gaze_point_y<=1200)%>%
  filter(!is.na(gaze_point_x))%>% #gets rid of the observations where tobii didn't get any reading
  filter(!is.na(gaze_point_y))%>%
  filter(!is.na(validity_left)) %>%
  filter(!is.na(validity_right)) %>%
  filter(validity_left<= 1)%>%
  filter(validity_right <= 1)%>%
  mutate(target = case_when(gaze_point_x >= target_x_min&gaze_point_x <= target_x_max&gaze_point_y >= target_y_min&gaze_point_y <= target_y_max~TRUE, 
                            TRUE~FALSE)) %>%
  mutate(looks_to_center = case_when(gaze_point_x >= 950 & gaze_point_x <= 970 &gaze_point_y >= 0&gaze_point_y <= 1080 ~ TRUE,
                                     TRUE~ FALSE)) %>% #creating a looks to center column
mutate(looks = case_when(target == TRUE & looks_to_center == FALSE~ "target",
                         target == TRUE & looks_to_center == TRUE~ "center",
                         target == FALSE & looks_to_center == TRUE~ "center",
                         target == FALSE & looks_to_center == FALSE~ "distractor"))


mean_latency_refixation <- kbh_data_center %>%
    filter(noun_onset >= 360 & noun_onset <= 3000) %>%
  select(looks, media_name, studio_project_name, studio_test_name, trial_number, recording_name, recording_timestamp) %>%
  filter(looks %in% c("target", "center")) %>% #filtering out disctractor looks because I am only interest in latency to look to taget
group_by(recording_name, media_name) %>%
  filter("target" %in% looks & "center" %in% looks) %>% #keeping only trials where there were looks to target and to center
  arrange()%>%
 filter(!(looks == "target" & lag(looks) == "target")) %>% #getting rid of consecutive target looks because I am not interested in duration of looks to target I am interested in duration of looks to center before the switch.
 ungroup() %>%
  mutate(consecutive_looks_center= looks == "center" & lag(looks) == "center") %>%
    group_by(recording_name, media_name, consecutive_looks_center, looks) %>%
  reframe(total_time = sum(recording_timestamp)) %>%
      ungroup() 

mean_latency_refixation2 <- mean_latency_refixation %>%
group_by(recording_name, media_name) %>%
   filter(looks == "center" & lead(looks) == "target") # not working

  summarise(time_to_refixate = diff(total_time))
 

#8. Mean fixation duration during trial
#Mean duration of fixations during the window of analysis within a trial. Mean by subject by trial?

mean_fixation_dur<- mean_fixation_dur <- kbh_data_clean %>%
  filter(noun_onset>= 360 & noun_onset <= 3000)%>%
ungroup()%>%
    group_by(recording_name, subject_id, trial_number, media_name) %>%
  
  #getting only the time stamps for the moments when the looks where to the target
  mutate(looks_target_time_stamp = case_when(target==TRUE ~ noun_onset)) %>%
  
  #Calculating each individual row amount of milliseconds looking to target by subtracting a cell minus the cell above. that way if first look then 0 ms, if second look =  376 (second look) - 360 (first look) = 17ms of looking
  mutate(duration_of_look= looks_target_time_stamp - lag(looks_target_time_stamp, default = first(looks_target_time_stamp))) %>%
  
  #adding all the calculated duration for each row of each trial into a single total duration by trial
  summarise(target_fixation_duration = sum(duration_of_look, na.rm=T))

#When you have time make some of the calculations by hand to make sure the duration is correct.
#I guess here is by subject the mean duration. But check on the paper.


#9. Proportion of fixation duration (better named target divergence time)
#Mean proportional of fixations to target vs. mean proportional of fixations to distracter in each time slice (theirs was 10ms,our sampling is 16 so we could do every 48ms slice, so every 3 of our slices, because with only 2 slices the means are pretty much 1, 0, and 0.5), then point by point t-test and then report the earliest time at which a minimum of 5 consecutive t tests indicated a difference significant difference between fixations to target and fixations to disctracter.I suppose this earliest time will be our DV [p<.05, probably bonferroni corrected for multiple comparisons).

#Step 1 : calculate the mean proportional every 48ms slice

kbh_clean_w_distractor <- kbh_data_clean %>%
  mutate(distractor = case_when(target == FALSE ~ TRUE,
                                TRUE ~ FALSE))

mean_proportions <- kbh_clean_w_distractor %>%
  mutate(mean_proportion_target =  rollmean(target, k = 3, fill = NA, align = "right")) %>%
  mutate(mean_proportion_distractor =  rollmean(distractor, k = 2, fill = NA, align = "right"))

#Above we're using rollmean() from the zoo package to calculate the rolling mean of the 'column' every two rows.
#k = 2 specifies that we want to calculate the mean every 2 rows.
#fill = NA specifies that we want to fill missing values with NA.


# I can't find a way to calculate t tests row-wise that does not absolutely destroy my computer's memory. Could download # BiocManager::install("genefilter") to run row-wise tests but is it worth it?



#10. Pupil dilation
#Baseline pupil size in the 200ms before noun onset and then subtracted the baseline from the pupil size measurements on each trial.
#In Liz's paper they contrasted time slice by time slice across two conditions, but here we don't have switched and same language conditions. I'll do average size at baseline and avg size after noun onset for now. But then talk with team about it.


pupil_dilation <- kbh_data_clean %>%
  filter(noun_onset>= -200 & noun_onset <= 500)%>%
mutate(pupil_period = case_when(noun_onset >= -200 & noun_onset <= 0 ~ "baseline",
                                TRUE ~ "post_onset"))%>% 
  select(recording_timestamp, subject_id, recording_name, trial_number, media_name, pupil_period, pupil_right, pupil_left) %>%
  drop_na(pupil_right) %>%
  drop_na(pupil_left)

pupil_dilation$two_pupil_mean <- rowMeans(pupil_dilation[c("pupil_right", "pupil_left")]) #Adding a mean between left and right pupil.

#The next steps are confusing to me.Should we average baseline pupil? Should we contrast each post onset time slice to a partricular baseline time slice? We could use mean dilation, peak dilation (or peak amplitude), and/or peak latency (i.e., the time between onset and peak pupil dilation). The problem with mean dilation is that the baseline has less sampling than the post-onset. Could we do peak dilation of baseline vs. peak dilation post onset? Or peak dilation but from which baseline point? from peak? We will for sure do GCA's as extra analyses

#Peak dilation
peak_dilation <- pupil_dilation %>%
  ungroup()%>%
  group_by(recording_name, media_name, pupil_period) %>%
  summarise(max(two_pupil_mean)) %>%
  pivot_wider(names_from = pupil_period, values_from ="max(two_pupil_mean)")%>%
  mutate(peak_pupil_size_difference = post_onset - baseline) #difference in peak pupil points

  
#Mean dilation
mean_dilation <- pupil_dilation %>%
  ungroup() %>%
  group_by(recording_name, media_name, pupil_period) %>%
  summarise(mean(two_pupil_mean)) %>%
  pivot_wider(names_from = pupil_period, values_from ="mean(two_pupil_mean)")%>%
  mutate(mean_pupil_size_difference = post_onset - baseline) #difference in means


#peak latency
peak_pupil_latency <- pupil_dilation %>%
  ungroup()%>%
  group_by(recording_name, media_name, pupil_period) %>%
  slice(which.max(two_pupil_mean)) %>%
  select(recording_name, media_name, pupil_period, peak_time_stamp = recording_timestamp) %>%
 #Slice is giving me only the max meassures of pupil, then I am selecting the timestamp corresponding to the max measures by baseline versus post_noun onset
 pivot_wider(names_from = pupil_period, values_from =peak_time_stamp) %>%
  mutate(peak_pupil_size_latency = post_onset - baseline) #time between baseline peak and post onset peak.


#11. Duration of first look
### Duration of the first look recorded toward a particular AOI.

first_look_duration <- kbh_data_clean  %>%
  filter(noun_onset >= 360 & noun_onset <= 3000) %>%   
  mutate(AOI_switches = ifelse(target == TRUE & lag(target) == FALSE | target == FALSE & lag(target) == TRUE, 1, 0)) %>%
    filter(AOI_switches == 1) %>%
     group_by(recording_name, subject_id, trial_number, media_name,noun_onset) %>%  
  summarise() %>%
  arrange(recording_name, trial_number, by_group = T) %>%
  mutate(number_of_trial_instance = row_number()) %>%  #I only want to keep the first instance of switch because I am only interested in the duration of the very first look during the trial analyses window.
filter(number_of_trial_instance == 1) %>%
  mutate(first_look_dur = noun_onset - 360) 

```
```{r merging newly created DVs to the original dataset}

#clean variables to be merged

#1)
prop_looking_c<- prop_looking %>%
  select(recording_name, subject_id, trial_number, media_name, prop_looking)

#2)
fixations_total_c<- fixations_total %>%
  select(recording_name, subject_id, trial_number, media_name, looking_to_target)

#3)
RT_c<- RT %>%
select(recording_name, subject_id, trial_number, media_name, latency_to_switch)  

#4)
number_of_switches_c<- number_of_switches %>%
select(recording_name, subject_id, trial_number, media_name, total_aoi_switches)  

#5)
first_look_duration_c<- first_look_duration %>%
 select(recording_name, subject_id, trial_number, media_name, first_look_dur)   



data_new_dvs<- kbh_data_clean %>%
  select(recording_name, media_name, subject_id, trial_number, age_months, exp_to_target_lang)

  data_new_dvs<- full_join(data_new_dvs, prop_looking_c, by=(c("recording_name", "subject_id", "trial_number", "media_name")))
  
   data_new_dvs<- full_join(data_new_dvs, fixations_total_c, by=(c("recording_name", "subject_id", "trial_number", "media_name")))
   
    data_new_dvs<- full_join(data_new_dvs, RT_c, by=(c("recording_name", "subject_id", "trial_number", "media_name")))
    
     data_new_dvs<- full_join(data_new_dvs, number_of_switches_c, by=(c("recording_name", "subject_id", "trial_number", "media_name")))
     
     data_new_dvs<- full_join(data_new_dvs, first_look_duration_c, by=(c("recording_name", "subject_id", "trial_number", "media_name")))


```



```{r correlation matrix between DVs}

#Select only numerical variables for correlation

#PEARSON CORRELATION
for_correlation<- data_new_dvs %>%
  ungroup()%>%
  select(age_months, exp_to_target_lang, prop_looking, looking_to_target, latency_to_switch, total_aoi_switches, first_look_dur)

kbh_correlation <- cor(x=for_correlation, use="complete.obs")

coorelation_for_p<- rcorr(as.matrix(for_correlation))

corrplot(kbh_correlation)



#SPEARMAN CORRELATION

kbh_correlation_s <- cor(x=for_correlation, use="complete.obs", method = "spearman")



corrplot(kbh_correlation_s)


```


