---
title: "2_Analyses_and_visuals"
author: "ASM"
date: "2023-10-25"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r call in libraries and clean data, include=FALSE}
library(here)
library(dplyr)
library(stringr)
library(Hmisc)
library(corrplot)
library(zoo)
library(tidyverse)
library(eyetrackingR)

load(here("archival_KBH_anonimyzed/arch_final.Rda"))
```


```{r clean data to be used in analyses}

kbh_data_clean <- arch_final%>%
  group_by(studio_project_name, studio_test_name, trial_number, recording_name)%>%
  mutate(trial_from_zero = recording_timestamp-min(recording_timestamp))%>%
  group_by(studio_project_name)%>%
  mutate(noun_onset = case_when(studio_project_name=="CompMix-36"~trial_from_zero-3000, #Substracting noun onset to normalize
                                studio_project_name=="LearnMix-36"~trial_from_zero-4500,
                                studio_project_name=="Mix-20"~trial_from_zero-5400,
                                studio_project_name=="Mix-14"~trial_from_zero-5400,
                                studio_project_name=="CogMisp-24"~trial_from_zero-1500))%>%
  ungroup()%>%
  rename(target_side=target, distractor_side=distractor,
         gaze_point_x= gaze_point_x_adc_spx, 
         gaze_point_y = gaze_point_y_adc_spx)%>%
  mutate(trackloss = case_when(gaze_point_x<0 ~ TRUE,
                               gaze_point_x> 1920 ~ TRUE,
                               gaze_point_y<0 ~ TRUE,
                               gaze_point_y > 1200 ~ TRUE,
                               is.na(gaze_point_x) ~ TRUE,
                               is.na(gaze_point_y) ~ TRUE,
                               is.na(validity_left) ~ TRUE,
                               is.na(validity_right) ~ TRUE,
                               validity_left > 1 ~ TRUE,
                               validity_right > 1 ~ TRUE,
                               TRUE~ FALSE)) %>% #MAKE VISUALIZATIONS ABOUT TRACKLOSS FOR SANITY CHECK
  mutate(target = case_when(gaze_point_x >= target_x_min&gaze_point_x <= target_x_max&gaze_point_y >= target_y_min&gaze_point_y <= target_y_max~TRUE, 
                            TRUE~FALSE)) %>%
  mutate(distractor = case_when(gaze_point_x >= distractor_x_min&gaze_point_x <= distractor_x_max&gaze_point_y >= distractor_y_min&gaze_point_y <= distractor_y_max~TRUE, 
                                 TRUE ~ FALSE))

#Create trial language column to describe the language in which the babies were tested
kbh_data_clean <- kbh_data_clean %>%
  ungroup()%>%
  group_by(studio_test_name, eng_exp, fre_exp)%>%
  mutate(trial_lang = case_when(str_detect(studio_test_name,"E")~ "english",
                                str_detect(studio_test_name, "F")~ "french")) %>%
  mutate(exp_to_target_lang = case_when(trial_lang == "english" ~ eng_exp,
                                        trial_lang == "french" ~ fre_exp))


#Add a column with the yoked pairs information---yoking info taken from lab server

kbh_w_items<- kbh_data_clean %>%
mutate(yoked_pair = case_when(
  grepl("Ear|Spoon", media_name) & studio_project_name== "CompMix-36" & grepl("E", studio_test_name) ~"ear-spoon",
  grepl("Apple|Toothbrush", media_name) & studio_project_name== "CompMix-36" & grepl("E", studio_test_name) ~"apple-toothbrush",
  grepl("Fish|Duck", media_name) & studio_project_name== "CompMix-36" & grepl("E", studio_test_name) ~"fish-duck",
  grepl("Sheep|Monkey", media_name) & studio_project_name== "CompMix-36" & grepl("E", studio_test_name) ~"sheep-monkey",
  grepl("Dog|Bunny", media_name) & studio_project_name== "CompMix-36" & grepl("E", studio_test_name) ~"dog-bunny",
  grepl("Hand|Door", media_name) & studio_project_name== "CompMix-36" & grepl("E", studio_test_name) ~"hand-door",
  grepl("Pencil|Coat", media_name) & studio_project_name== "CompMix-36" & grepl("E", studio_test_name) ~"pencil-coat",
  grepl("Froggy|Cow", media_name) & studio_project_name== "CompMix-36" & grepl("E", studio_test_name) ~"froggy-cow",
 
  
  grepl("Ear|Spoon", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~"oreille-cuillere",
  grepl("Apple|Toothbrush", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~"pomme-brosse a dents",
  grepl("Fish|Duck", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~"poisson-canard",
  grepl("Sheep|Monkey", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~"mouton-singe",
  grepl("Dog|Bunny", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~"chien-lapin",
  grepl("Hand|Door", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~"main-porte",
  grepl("Pencil|Coat", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~"crayon-manteau",
  grepl("Froggy|Cow", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~"grenouille-vache",
  
   
   studio_project_name== "LearnMix-36"& media_name %in% 
    c("FR_Single_ChienWalem_R.wmv", "FR_Single_LapinWalem_L.wmv", "FR_Single_LapinTeelo_R.wmv", "FR_Single_ChienTeelo_L.wmv")~ "chien-lapin",
  
     studio_project_name== "LearnMix-36"& media_name %in% 
    c("EN_Single_DogWalem_R.wmv", "EN_Single_BunnyWalem_L.wmv","EN_Single_DogTeelo_L.wmv", "EN_Single_BunnyTeelo_R.wmv")
  ~ "dog-bunny",
  
    studio_project_name== "LearnMix-36"& media_name %in% 
    c("FR_Single_LapinTeelo_L.wmv", "FR_Single_PoissonTeelo_L.wmv","FR_Single_PoissonWalem_R.wmv", "FR_Single_LapinWalem_R.wmv")
  ~ "poisson-lapin",
  
      studio_project_name== "LearnMix-36"& media_name %in% 
    c("EN_Single_BunnyTeelo_L.wmv", "EN_Single_FishTeelo_L.wmv","EN_Single_FishWalem_R.wmv", "EN_Single_BunnyWalem_R.wmv")
  ~ "fish-bunny",
  
      studio_project_name== "LearnMix-36"& media_name %in% c( "FR_Single_ChienWalem_L.wmv","FR_Single_PoissonWalem_L.wmv","FR_Single_PoissonTeelo_R.wmv", "FR_Single_ChienTeelo_R.wmv") 
  ~ "poisson-chien",
 
      studio_project_name== "LearnMix-36"& media_name %in% c( "EN_Single_FishWalem_L.wmv",
"EN_Single_DogWalem_L.wmv","EN_Single_FishTeelo_R.wmv", "EN_Single_DogTeelo_R.wmv") 
  ~ "fish-dog", 

  grepl("banC|girC", media_name) & studio_project_name== "CogMisp-24"  ~"banana-giraffe",
  grepl("monC|butC", media_name) & studio_project_name=="CogMisp-24" ~"monkey-butterfly",
  grepl("winC|mouC", media_name) & studio_project_name== "CogMisp-24" ~"window-mouth",
  grepl("pizC|tabC", media_name) & studio_project_name== "CogMisp-24" ~"pizza-table",
  grepl("choC|bowC", media_name) & studio_project_name== "CogMisp-24" ~"chocolate-bowl",
  grepl("fooC|cooC", media_name) & studio_project_name== "CogMisp-24"~"cookie-foot",


  grepl("Toothbrush|Apple", media_name) & studio_project_name %in% c("Mix-20","Mix-14")  ~"toothbrush-apple",
  grepl("Ear|Spoon", media_name) & studio_project_name %in% c("Mix-20","Mix-14")  ~"ear-spoon",
  grepl("Mouth|Door", media_name) & studio_project_name %in% c("Mix-20","Mix-14")  ~"mouth-door",
  grepl("Bird|Hand", media_name) & studio_project_name %in% c("Mix-20","Mix-14")  ~"bird-hand",
  grepl("Dog|Book", media_name) & studio_project_name %in% c("Mix-20","Mix-14")  ~"dog-book",
  grepl("Cookie|Foot", media_name) & studio_project_name %in% c("Mix-20","Mix-14") ~"cookie-foot",

  grepl("Brosse|Pomme", media_name) & studio_project_name %in% c("Mix-20","Mix-14")  ~"pomme-brosse a dents",
  grepl("Oreille|Cuillere", media_name) & studio_project_name %in% c("Mix-20","Mix-14")  ~"oreille-cuillere",
  grepl("Bouche|Porte", media_name) & studio_project_name %in% c("Mix-20","Mix-14")  ~"bouche-porte",
  grepl("Hand|Main", media_name) & studio_project_name %in% c("Mix-20","Mix-14")  ~"oisseau-main",
  grepl("Chien|Livre", media_name) & studio_project_name %in% c("Mix-20","Mix-14")  ~"chien-livre",
  grepl("Biscuit|Pied", media_name) & studio_project_name %in% c("Mix-20","Mix-14") ~"biscuit-pied",

  TRUE~"OTHER"
  )
)



#Adding a column with word tested information
kbh_w_items<- kbh_w_items %>%
  mutate(target_word= case_when(
  grepl("monC", media_name) ~"monkey",
  grepl("butC", media_name) ~"butterfly",
  grepl("Door", media_name) & grepl("Mix", studio_project_name) & grepl("Eng|ENG", media_name) ~"door",
  grepl("banC", media_name) ~"banana",
  grepl("winC", media_name) ~"window",
  grepl("pizC", media_name) ~"pizza",
  grepl("fooC", media_name) ~"foot",
  grepl("bowC", media_name) ~"bowl",
  grepl("choC", media_name) ~"chocolate",
  grepl("girC", media_name) ~"giraffe",
  grepl("tabC", media_name) ~"table",
  
  
  grepl("Oreille", media_name)  & grepl("Mix", studio_project_name) ~"oreille",
  grepl("Cuillere", media_name)  & grepl("Mix", studio_project_name) ~"cuillere",
  grepl("Chien", media_name)  & grepl("Mix", studio_project_name) ~"chien",
  grepl("Biscuit", media_name)  & grepl("Mix", studio_project_name) ~"biscuit",
  grepl("Bouche", media_name)  & grepl("Mix", studio_project_name)  ~"bouche",
  grepl("Livre", media_name) & grepl("Mix", studio_project_name) ~"livre",
  grepl("Pied", media_name)  & grepl("Mix", studio_project_name) ~"pied",
  grepl("Oisseau", media_name)  & grepl("Mix", studio_project_name) ~"oisseau",
  grepl("Main", media_name)  & grepl("Mix", studio_project_name) ~"main",
  grepl("Porte", media_name)  & grepl("Mix", studio_project_name) ~"porte",
  grepl("Brosse", media_name)  & grepl("Mix", studio_project_name) ~"brosse a dents",
  grepl("Pomme", media_name)  & grepl("Mix", studio_project_name) ~"pomme",
  grepl("Poisson", media_name)  & grepl("Mix", studio_project_name) ~"poisson",
  grepl("Lapin", media_name)  & grepl("Mix", studio_project_name) ~"lapin",
  
  grepl("Ear_Fr", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "oreille",
  grepl("Spoon_Fr", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "cuillere",
  grepl("Apple_Fr", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "pomme",
  grepl("Toothbrush_Fr", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "brosse a dents",
   grepl("Fish_Fr", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "poisson",
   grepl("Duck_Fr", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "canard",
   grepl("Monkey_Fr", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "singe",
   grepl("Sheep_Fr", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "mouton",
   grepl("Dog_Fr", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "chien",
   grepl("Book_Fr", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "livre",
   grepl("Cookie_Fr", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "biscuit",
   grepl("Foot_Fr", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "pied",
   grepl("Hand_Fr", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "main",
   grepl("Door_Fr", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "porte",
   grepl("Pencil_Fr", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "crayon",
   grepl("Coat_Fr", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "manteau",
   grepl("Froggy_Fr", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "grenouille",
   grepl("Cow_Fr", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "vache",
    grepl("Bunny_Fr", media_name) & studio_project_name== "CompMix-36" & grepl("F", studio_test_name) ~ "lapin",
  
    grepl("Ear", media_name) & studio_project_name== "CompMix-36" & grepl("E", studio_test_name) ~ "ear",
  grepl("Spoon", media_name) & studio_project_name== "CompMix-36" & grepl("E", studio_test_name) ~ "spoon",
  grepl("Apple", media_name) & studio_project_name== "CompMix-36" & grepl("E", studio_test_name) ~ "apple",
  grepl("Toothbrush", media_name) & studio_project_name== "CompMix-36" & grepl("E", studio_test_name) ~ "toothbrush",
   grepl("Fish", media_name) & studio_project_name== "CompMix-36" & grepl("E", studio_test_name) ~ "fish",
   grepl("Duck", media_name) & studio_project_name== "CompMix-36" & grepl("E", studio_test_name) ~ "duck",
   grepl("Monkey", media_name) & studio_project_name== "CompMix-36" & grepl("E", studio_test_name) ~ "monkey",
   grepl("Sheep", media_name) & studio_project_name== "CompMix-36" & grepl("E", studio_test_name) ~ "sheep",
   grepl("Dog", media_name) & studio_project_name== "CompMix-36" & grepl("E", studio_test_name) ~ "dog",
   grepl("Book", media_name) & studio_project_name== "CompMix-36" & grepl("E", studio_test_name) ~ "book",
   grepl("Cookie", media_name) & studio_project_name== "CompMix-36" & grepl("E", studio_test_name) ~ "cookie",
   grepl("Foot", media_name) & studio_project_name== "CompMix-36" & grepl("E", studio_test_name) ~ "foot",
   grepl("Hand", media_name) & studio_project_name== "CompMix-36" & grepl("E", studio_test_name) ~ "hand",
   grepl("Door", media_name) & studio_project_name== "CompMix-36" & grepl("E", studio_test_name) ~ "door",
   grepl("Pencil", media_name) & studio_project_name== "CompMix-36" & grepl("E", studio_test_name) ~ "pencil",
   grepl("Coat", media_name) & studio_project_name== "CompMix-36" & grepl("E", studio_test_name) ~ "coat",
   grepl("Froggy", media_name) & studio_project_name== "CompMix-36" & grepl("E", studio_test_name) ~ "froggy",
   grepl("Cow", media_name) & studio_project_name== "CompMix-36" & grepl("E", studio_test_name) ~ "cow",
  
    grepl("Ear", media_name) & grepl("Mix", studio_project_name) ~"ear",
  grepl("Spoon", media_name)  & grepl("Mix", studio_project_name) ~"spoon",
  grepl("Dog", media_name)  & grepl("Mix", studio_project_name) ~"dog",
  grepl("Cookie", media_name)  & grepl("Mix", studio_project_name)~"cookie",
  grepl("cooC", media_name) ~"cookie",  
  grepl("Mouth", media_name)  & grepl("Mix", studio_project_name)~"mouth",
  grepl("mouC", media_name) ~"mouth",
  grepl("Book", media_name)  & grepl("Mix", studio_project_name) ~"book",
  grepl("Foot", media_name)  & grepl("Mix", studio_project_name) ~"foot",
   grepl("fooC", media_name) ~"foot",
  grepl("Bird", media_name)  & grepl("Mix", studio_project_name) ~"bird",
  grepl("Hand", media_name)  & grepl("Mix", studio_project_name) ~"hand",
  grepl("Toothbrush", media_name)   & grepl("Mix", studio_project_name) ~"toothbrush",
  grepl("Apple", media_name)  & grepl("Mix", studio_project_name) ~"apple",
  grepl("Fish", media_name)  & grepl("Mix", studio_project_name) ~"fish",
  grepl("Bunny", media_name)  & grepl("Mix", studio_project_name) ~"bunny",
  
     studio_project_name== "LearnMix-36"& media_name %in% 
    c("FR_Single_ChienWalem_R.wmv", "FR_Single_ChienTeelo_L.wmv", "FR_Single_ChienWalem_L.wmv","FR_Single_ChienTeelo_R.wmv")~ "chien",
  
       studio_project_name== "LearnMix-36"& media_name %in% 
    c("FR_Single_LapinWalem_L.wmv", "FR_Single_LapinTeelo_R.wmv", "FR_Single_LapinTeelo_L.wmv","FR_Single_LapinWalem_R.wmv")~ "lapin",
  
     studio_project_name== "LearnMix-36"& media_name %in% 
    c("EN_Single_DogWalem_R.wmv","EN_Single_DogTeelo_L.wmv", "EN_Single_DogWalem_L.wmv","EN_Single_DogTeelo_R.wmv")
  ~ "dog",
  
       studio_project_name== "LearnMix-36"& media_name %in% 
    c("EN_Single_BunnyWalem_L.wmv", "EN_Single_BunnyTeelo_R.wmv", "EN_Single_BunnyTeelo_L.wmv", "EN_Single_BunnyWalem_R.wmv")
  ~ "bunny",
  
    studio_project_name== "LearnMix-36"& media_name %in% 
    c("FR_Single_PoissonTeelo_L.wmv","FR_Single_PoissonWalem_R.wmv", "FR_Single_PoissonWalem_L.wmv","FR_Single_PoissonTeelo_R.wmv")
  ~ "poisson",
  
      studio_project_name== "LearnMix-36"& media_name %in% 
    c("EN_Single_FishTeelo_L.wmv","EN_Single_FishWalem_R.wmv","EN_Single_FishWalem_L.wmv",
"EN_Single_FishTeelo_R.wmv")
  ~ "fish",
  
  TRUE~"OTHER"
  ),
distractor_word = str_remove(yoked_pair, target_word),
distractor_word = str_remove(distractor_word, "-")
)

```


```{r calculate all the different dependent variables}

###### First, create variables that will be useful for the calculations below ## TRY TO DO IT IN THE SAME DATA SET
initial_looks <- kbh_w_items %>%
  filter(noun_onset >= 260 & noun_onset < 360) %>%
  group_by(recording_name, trial_number, media_name) %>% 
     summarise(
    distractor_count = sum(distractor),
    target_count = sum(target),
    trackloss_count = sum(trackloss)
     )%>%
  mutate(initial_look = case_when(target_count >0 ~ "target", #if the child *ever* looks to target during first 100 ms, then counted as initial target look
                                  distractor_count/(distractor_count+trackloss_count) >=0.5 ~ "distractor",
                                  TRUE ~ "neither"))

kbh_w_items <- left_join(kbh_w_items, initial_looks, by= c("recording_name", "trial_number", "media_name"))

#We are considering distractor initial trials as trials where in the first 100 ms ofr the analyses window the child looked at the distractor at least 50% of the time and never looked to target.


#Mix 20 S052 has 23 rows for trials other than trial 1 with no data—remove these here, try to figure out why this happened

kbh_w_items <- kbh_w_items %>%
  filter(!(recording_name == "Mix_20_S52" & trial_number > 1))

#1. Proportion looking to target

prop_looking <- kbh_w_items %>%
  filter(noun_onset>= 360 & noun_onset <= 3000)%>%
  group_by(recording_name, subject_id, trial_number, media_name, age_months, exp_to_target_lang)%>%
  summarise(samples_target=sum(target, na.rm = T),
            samples_distractor=sum(distractor, na.rm = T))%>%
  mutate(prop_looking= samples_target/(samples_target + samples_distractor)) %>%
  ungroup()

#2. Proportion looking difference 
#Now it is done but there is something strange happening with compmix items--to check.
#Within a pair of pictures A and B, the fixation to picture A relative to B when A was the target, minus the fixation #to A when A was the distractor.

#Question if two studies have the same item pair (e.g. dog-apple), should they still be grouped as the same yoked pair? They might have had different carrier sentences but, the words are the same.
#Question: should it be absolute difference or true difference?


prop_looking_diff <- kbh_w_items %>%
  ungroup()%>%
  filter(noun_onset>= 360 & noun_onset <= 3000)%>%
  select(recording_name, recording_timestamp, target_word, distractor_word, target, distractor)%>%
  pivot_longer(c(target_word, distractor_word), names_to = "word_type", values_to = "word") %>%
  mutate(looking = case_when(word_type == "target_word" & target == TRUE ~ TRUE,
                             word_type == "distractor_word" & distractor == TRUE ~ TRUE,
                             TRUE ~ FALSE)) %>%
  group_by(recording_name, word_type, word) %>%
  #what percent of the time when x is target are kids looking at x, what percent of the time when x is distractor are kids looking at x
  summarise(prop_looking = sum(looking == T)/n()) %>%
  pivot_wider(names_from = "word_type", values_from = "prop_looking") %>%
  filter(!is.na(target_word) & !is.na(distractor_word)) %>%
  mutate(prop_looking_diff = target_word - distractor_word) %>%
  select(recording_name, target_word = word, prop_looking_diff)

  
#3. Number of fixations
### Total number of fixations to the target during the window of analyses.
#### Question: What is considered a fixation? --> In TOBII we kept only valid fixations (as in Mills-Smith, 2016), they also excluded by subject and by trial (which we will do).

#we defined fixations as the number of consecutive runs within a trial where looks were in the target for at least 200ms while getting rid of short bouts of trackloss (17 to 38 ms)

# Group by subject and summarize consecutive TRUE values in target column - we are counting how many consecutive groups of 12 rows of TRUE target looks there are per trial, which is around 200 ms of looking. We are counting each group of 200 ms of looking as one fixation.

fixations_total <- kbh_w_items   %>%
  ungroup() %>%
  filter(noun_onset >= 360 & noun_onset <= 3000) %>%
  group_by(recording_name, trial_number) %>%
  mutate(trackloss_group_id = data.table::rleid(trackloss)) %>%
  group_by(trackloss_group_id, recording_name, trial_number) %>%
  mutate(num_consec_trackloss_rows = n()) %>%
  ungroup() %>%
  filter(trackloss == FALSE | (trackloss == TRUE & num_consec_trackloss_rows > 2)) %>%
  group_by(recording_name, trial_number) %>% 
  mutate(targets_in_a_row = data.table::rleid(target)) %>%
  group_by(recording_name, trial_number, targets_in_a_row) %>%
  mutate(row = row_number(), 
         multi_of_twelve = case_when(row %% 12 == 0 & target == TRUE ~ "fixation")) %>% 
  group_by(recording_name, subject_id, trial_number, media_name) %>%
  summarise(consecutive_target = sum(multi_of_twelve == "fixation", na.rm = T)) %>%
  ungroup()

  
#4. Correct first shift to target
#On trials where infants were fixated on the distractor upon hearing the target word (i.e., distractor-initial trials), the number of first shifts to the target picture within the 300–1,800 ms window following target word onset, as a proportion of all distractor-initial trials.
  

first_shift_target <- kbh_w_items %>%
  ungroup() %>%
  filter(noun_onset >= 360 & noun_onset <= 1800) %>% #Keeping the shorter window to be consistent with Fernald

  
    #Grouping and summarizing to get by subject by trial flagging of whether there was switching or not.
     group_by(recording_name, subject_id, trial_number, media_name, initial_look) %>%  
  summarise(target = sum(target),
            distractor =  sum(distractor)) %>% #Counting how many looks to target and distractor by timeslice grouped by target or distractor initial trials.
  ungroup() %>%
  mutate(correct_shift = case_when(initial_look == "target" & distractor ==0 ~ TRUE,
                                   initial_look == "distractor" & target >0 ~ TRUE,
                                   TRUE~FALSE)) #Making a column to calculate correct shifts. We defined correct shift as never looking to the distractor on target initial trial, or switching to the taget on distractor initial trials

prop_shifts_distractor_initial <- first_shift_target %>%
    filter(initial_look == "distractor") %>%
    group_by(recording_name) %>%
    summarise(prop_shift_distractor_initial = sum(correct_shift == TRUE)/n())
  
prop_shifts_target_initial <- first_shift_target %>%
    filter(initial_look == "target") %>%
    group_by(recording_name) %>%
    summarise(prop_shift_target_initial = sum(correct_shift == TRUE)/n())
  

#5. Reaction time

#do we want the latency from noun onset (0) or from window of analysis(360)? Right now using window of analysis

RT <- kbh_w_items %>%
  ungroup() %>%
  filter(noun_onset >= 360 & noun_onset <= 1800) %>% #Keeping the shorter window to be consistent with Fernald
    #Grouping and summarizing to get by subject by trial flagging of whether there was switching or not.
  filter(initial_look == "distractor") %>%
  group_by(recording_name, subject_id, trial_number, media_name, initial_look, target) %>%
  slice_head() %>%
  filter(target == TRUE) %>%
  mutate(latency_to_switch = noun_onset - 360) 


#6. Total number of switches between AOIs - come back to this after discussion about whether to keep the part that specifies there must be 12 rows of same looks to be counted as a fixation before determining switches

number_of_switches <- kbh_w_items %>%
  ungroup() %>%
  filter(noun_onset >= 360 & noun_onset <= 3000) %>%
  group_by(recording_name, trial_number) %>% 
  mutate(targets_in_a_row = data.table::rleid(target)) %>%
  group_by(recording_name, trial_number, targets_in_a_row) %>%
  mutate(row = row_number(), 
         multi_of_twelve = case_when(row %% 12 == 0 ~ "fixation")) %>% 
  filter(multi_of_twelve == "fixation") %>%
  mutate(where_looking = case_when(target == TRUE ~ "target",
                                   distractor == TRUE ~ "distractor",
                                   TRUE ~ "neither")) %>%
  filter(where_looking != "neither") %>%
  group_by(recording_name, trial_number) %>%
  mutate(AOI_switches = case_when(lag(where_looking) == "target" & where_looking == "distractor" ~ 1,
                            lag(where_looking) == "distractor" & where_looking == "target" ~ 1)) %>%
  group_by(recording_name, subject_id, trial_number, media_name) %>%
  summarise(total_aoi_switches = sum(AOI_switches, na.rm = T)) %>%
  ungroup()
  
  
#7. Mean latency of refixation during trial - COME BACK TO THIS
#Mean latency of correct saccadic shifts from the center to the peripheral target (refixations) during the trial. 
#I would need to calculate the center point (shouldn't be too hard)

kbh_data_center <- arch_final%>%
  group_by(studio_project_name, studio_test_name, trial_number, recording_name)%>%
  mutate(trial_from_zero = recording_timestamp-min(recording_timestamp))%>%
  group_by(studio_project_name)%>%
  mutate(noun_onset = case_when(studio_project_name=="CompMix-36"~trial_from_zero-3000, #Substracting noun onset to normalize
                                studio_project_name=="LearnMix-36"~trial_from_zero-4500,
                                studio_project_name=="Mix-20"~trial_from_zero-5400,
                                studio_project_name=="Mix-14"~trial_from_zero-5400,
                                studio_project_name=="CogMisp-24"~trial_from_zero-1500))%>%
  ungroup()%>%
  rename(target_side=target, distractor_side=distractor,
         gaze_point_x= gaze_point_x_adc_spx, 
         gaze_point_y = gaze_point_y_adc_spx)%>%
  mutate(trackloss = case_when(gaze_point_x<0 ~ TRUE,
                               gaze_point_x> 1920 ~ TRUE,
                               gaze_point_y<0 ~ TRUE,
                               gaze_point_y > 1200 ~ TRUE,
                               is.na(gaze_point_x) ~ TRUE,
                               is.na(gaze_point_y) ~ TRUE,
                               is.na(validity_left) ~ TRUE,
                               is.na(validity_right) ~ TRUE,
                               validity_left > 1 ~ TRUE,
                               validity_right > 1 ~ TRUE,
                               TRUE~ FALSE)) %>% #MAKE VISUALIZATIONS ABOUT TRACKLOSS FOR SANITY CHECK
  mutate(target = case_when(gaze_point_x >= target_x_min&gaze_point_x <= target_x_max&gaze_point_y >= target_y_min&gaze_point_y <= target_y_max~TRUE, 
                            TRUE~FALSE)) %>%
  mutate(distractor = case_when(gaze_point_x >= distractor_x_min&gaze_point_x <= distractor_x_max&gaze_point_y >= distractor_y_min&gaze_point_y <= distractor_y_max~TRUE, 
                                 TRUE ~ FALSE)) %>%
  mutate(looks_to_center = case_when(gaze_point_x >= 950 & gaze_point_x <= 970 &gaze_point_y >= 0&gaze_point_y <= 1080 ~ TRUE,
                                     TRUE~ FALSE)) %>% #creating a looks to center column
mutate(where_looking = case_when(target == TRUE & looks_to_center == FALSE~ "target",
                         target == TRUE & looks_to_center == TRUE~ "center",
                         distractor == TRUE & looks_to_center == TRUE~ "center",
                         distractor == TRUE & looks_to_center == FALSE~ "distractor",
                         target == FALSE & distractor == FALSE & looks_to_center == TRUE ~ "center",
                         TRUE ~ "neither"))


mean_latency_refixation <- kbh_data_center %>%
  filter(noun_onset >= 360 & noun_onset <= 3000) %>%
  group_by(recording_name, trial_number) %>%
  select(looks, media_name, studio_project_name, studio_test_name, trial_number, recording_name, recording_timestamp, where_looking) %>%
  mutate(looking_area_id = data.table::rleid(where_looking)) %>%
  group_by(recording_name, trial_number, looking_area_id) %>%
  mutate(how_long_looking_area = n(),
         length_center_look = case_when(where_looking == "center" ~ how_long_looking_area))
  
  
#   
#   filter(looks %in% c("target", "center")) %>% #filtering out disctractor looks because I am only interest in latency to look to taget
# group_by(recording_name, media_name) %>%
#   filter("target" %in% looks & "center" %in% looks) %>% #keeping only trials where there were looks to target and to center
#   arrange()%>%
#  filter(!(looks == "target" & lag(looks) == "target")) %>% #getting rid of consecutive target looks because I am not interested in duration of looks to target I am interested in duration of looks to center before the switch.
#  ungroup() %>%
#   mutate(consecutive_looks_center= looks == "center" & lag(looks) == "center") %>%
#     group_by(recording_name, media_name, consecutive_looks_center, looks) %>%
#   reframe(total_time = sum(recording_timestamp)) %>%
#       ungroup() 
# 
# mean_latency_refixation2 <- mean_latency_refixation %>%
# group_by(recording_name, media_name) %>%
#    filter(looks == "center" & lead(looks) == "target") # not working
# 
#   summarise(time_to_refixate = diff(total_time))
 

#8. Mean fixation duration during trial
#Mean duration of fixations during the window of analysis within a trial. Mean by subject by trial?

mean_fixation_dur <- kbh_w_items %>%
  filter(noun_onset>= 360 & noun_onset <= 3000)%>%
  ungroup()%>%
  group_by(recording_name, subject_id, trial_number, media_name) %>%
  mutate(where_looking_group_id = data.table::rleid(target)) %>%
  filter(target == TRUE) %>%
  group_by(recording_name, trial_number, media_name, where_looking_group_id) %>%
  summarise(length_of_looks = n()) %>%
  mutate(length_of_looks = length_of_looks*(1000/60)) %>%
  group_by(recording_name, trial_number, media_name) %>%
  summarise(duration_of_look = mean(length_of_looks, na.rm = T)) %>%
  ungroup()


#When you have time make some of the calculations by hand to make sure the duration is correct.
#I guess here is by subject the mean duration. But check on the paper.


#9. Proportion of fixation duration (better named target divergence time)
#The target divergence time measure is defined as the time at which fixations to the “target” object diverges from fixations to the “distractor”. point-by-point t-tests at each 10 ms bin between mean looking proportions to the target object and mean looking proportions to the distractor object were calculated. the time point reported is the earliest time point that a minimum of five consecutive two tailed t-tests with an alpha level of p < .05 indicate a significant difference between the fixation to the target compared to distractor

#What we need to do in our research: By participant, collapsing across trials average prop looking to target and average proportion looking to distractor eavery 17ms (or whatever or bin size is). So at that stage the participant has 2 columns with 8 rows (1 row per trial), one column for the average prop looks to target, one for the average prop looks to distractor. THEN we do a t test between column A and B, so we get column C that again has 8 rows (this is a rowwise t test, bonferroni corrected I guess). Then we summarize to get a single number per participant. that number is the ms slice at which 5 (?) t-tests are p>0.05.


#Get average looking to target and looking to distractor for each 220-ms time bin (the reference paper used 10-ms time bins, but their eyetracker sampled every 2ms and ours only did ever 16-17 ms)

copy_data <- kbh_w_items %>%
  filter(noun_onset>= -2000 & noun_onset <= 3000)%>%
  mutate(timestamp_zero_interest_period = noun_onset - 360,
         trial_unique = paste0(recording_name, "_", trial_number, "_", media_name)) %>%
  ungroup()%>%
  group_by(recording_name, trial_number, media_name, age_months) %>%
  mutate(new_noun_onset = case_when(abs(noun_onset) == min(abs(noun_onset)) ~ 0)) %>% 
  select(recording_name, trial_number, recording_timestamp, trial_from_zero, noun_onset, new_noun_onset, target, distractor, trackloss, age_months) %>% 
  mutate(parallel_timestamp = (row_number() - which(new_noun_onset == 0))*(1000/60),
         parallel_timestamp = round(parallel_timestamp)) %>%
  select(media_name, recording_name, trial_number, parallel_timestamp, target, distractor, trackloss, age_months) %>%
  pivot_longer(c(target, distractor), names_to = "aoi", values_to = "value") %>%
  arrange(recording_name, trial_number, aoi, parallel_timestamp) %>%
  mutate(value = as.numeric(value)) %>%
  filter(trackloss == FALSE) %>%
  ungroup() %>%
  mutate(age_group = case_when(age_months >= 14 & age_months < 21 ~ "14-20",
                               age_months >= 21 & age_months < 31 ~ "21-30",
                               age_months >= 31 & age_months < 51 ~ "31-48"))

copy_dat_fig1 <- copy_data %>%
  group_by(recording_name, aoi, parallel_timestamp, age_group) %>%
  summarise(mean_fixation = mean(value))

#This takes a little while to run because of the bootstrapping
base_plot <- ggplot(copy_dat_fig1, aes(x=parallel_timestamp, y=mean_fixation, colour=aoi)) +
  geom_vline(xintercept=0, linetype="dashed", colour="gray28") +
  stat_summary(fun.data=mean_cl_boot, aes(fill=aoi),
               geom="ribbon", alpha=.2, linetype="blank") +
  stat_summary(fun=mean, geom="path", 
               aes(group=aoi, linetype=aoi), size=.7) + facet_wrap(~age_group)

copy_dat_stat <- copy_data %>%
  filter(parallel_timestamp >= -1000 & parallel_timestamp <= 2500)

#Apply statistical test to each time point
copy_p_table <- copy_dat_stat %>%
  # select only rows in the dataframe where a fixation occurred
  filter(value == 1) %>%
  # label fixations that were on the target as 1 and as 0 otherwise,
  mutate(looking_to_target = ifelse(aoi == "target", 1, 0)) %>%
  # we want to test for each timepoint
  group_by(parallel_timestamp) %>%
  # apply logistic regression and extract z-values
  summarise(z = summary(lme4::glmer(looking_to_target ~ 1 +
  (1|recording_name), family="binomial",
  control=lme4::glmerControl(calc.derivs=FALSE)))$coefficients[1,3]) %>%
  # add p-values
  mutate(p = pnorm(-abs(z))*2)

# Set alpha level and calculate Bonferroni correction
alpha           <- 0.05
N_tests         <- length(unique(copy_dat_stat$parallel_timestamp))
alpha_corrected <- alpha/N_tests

# Find the earliest timepoint with a significant uncorrected p-value
(uncorr <- copy_p_table %>%
  # extract positive z-scores ("target advantage") and significant p-values
  filter(z > 0, p < alpha) %>% 
  # extract the earliest significant p-value and its timepoint 
  slice(1))

# Find the earliest timepoint that survives the Bonferroni correction
(bnf <- copy_p_table %>%
  filter(z > 0, p < alpha_corrected) %>% 
  slice(1))

# Find the earliest timepoint after FDR control
(fdr <- copy_p_table %>%
  # apply FDR control from `stats` package
  mutate(p_fdr = stats::p.adjust(p, method = "BY", n = length(p))) %>%
  filter(z > 0, p_fdr < alpha) %>%
  slice(1))

plot_points <- tibble(correction = c("Uncorrected", "Bonferroni", "FDR"), 
                      parallel_timestamp = c(uncorr$parallel_timestamp, bnf$parallel_timestamp, fdr$parallel_timestamp),
                      mean_fixation = .5,
                      aoi = "target")

overall_plot <- ggplot(copy_dat_fig1, aes(x=parallel_timestamp, y=mean_fixation, colour=aoi)) +
  geom_vline(xintercept=0, linetype="dashed", colour="gray28") +
  stat_summary(fun.data=mean_cl_boot, aes(fill=aoi),
               geom="ribbon", alpha=.2, linetype="blank") +
  stat_summary(fun=mean, geom="path", 
               aes(group=aoi, linetype=aoi), size=.7) +
  geom_point(data = plot_points, color = "black", aes(shape = plot_points$correction))




#10. Pupil dilation
#Baseline pupil size in the 200ms before noun onset and then subtracted the baseline from the pupil size measurements on each trial.
#In Liz's paper they contrasted time slice by time slice across two conditions, but here we don't have switched and same language conditions. I'll do average size at baseline and avg size after noun onset for now. But then talk with team about it.


pupil_dilation <- kbh_w_items %>%
  filter(noun_onset>= -200 & noun_onset <= 500)%>%
mutate(pupil_period = case_when(noun_onset >= -200 & noun_onset <= 0 ~ "baseline",
                                TRUE ~ "post_onset"))%>% 
  select(recording_timestamp, subject_id, recording_name, trial_number, media_name, pupil_period, pupil_right, pupil_left) %>%
  mutate(two_pupil_mean = case_when(is.na(pupil_left) & is.na(pupil_right) ~ NA,
                                         is.na(pupil_left)  ~ pupil_right,
                                         is.na(pupil_right) ~ pupil_left,
                                         TRUE ~ (pupil_left + pupil_right)/2)) %>%
  filter(!is.na(two_pupil_mean))

#The next steps are confusing to me.Should we average baseline pupil? Should we contrast each post onset time slice to a partricular baseline time slice? We could use mean dilation, peak dilation (or peak amplitude), and/or peak latency (i.e., the time between onset and peak pupil dilation). The problem with mean dilation is that the baseline has less sampling than the post-onset. Could we do peak dilation of baseline vs. peak dilation post onset? Or peak dilation but from which baseline point? from peak? We will for sure do GCA's as extra analyses

#Peak dilation
peak_dilation <- pupil_dilation %>%
  ungroup()%>%
  group_by(recording_name, trial_number, media_name, pupil_period) %>%
  summarise(peak_pupil = max(two_pupil_mean)) %>%
  pivot_wider(names_from = pupil_period, values_from ="peak_pupil")%>%
  mutate(peak_pupil_size_difference = post_onset - baseline) %>% #difference in peak pupil points
  filter(!is.na(peak_pupil_size_difference)) %>%
  rename(max_pupil_baseline = baseline,
         max_pupil_post_onset = post_onset)
  
#Mean dilation
mean_dilation <- pupil_dilation %>%
  ungroup()%>%
  group_by(recording_name, trial_number, media_name, pupil_period) %>%
  summarise(mean_pupil = mean(two_pupil_mean, na.rm = T)) %>%
  pivot_wider(names_from = pupil_period, values_from ="mean_pupil")%>%
  mutate(mean_pupil_size_difference = post_onset - baseline) %>% #difference in peak pupil points
  filter(!is.na(mean_pupil_size_difference)) %>%
  rename(mean_pupil_baseline = baseline,
         mean_pupil_post_onset = post_onset)
  


#peak latency
peak_pupil_latency <- pupil_dilation %>%
  ungroup()%>%
  group_by(recording_name, media_name, pupil_period, trial_number) %>%
  slice(which.max(two_pupil_mean)) %>%
  select(recording_name, media_name, pupil_period, peak_time_stamp = recording_timestamp) %>%
  group_by(recording_name, trial_number, media_name) %>%
  summarise(peak_pupil_latency = diff(peak_time_stamp))


#11. Duration of first look
### Duration of the first look recorded toward a particular AOI. - To target specifically, with at least 200 ms fixation length

first_look_duration <- kbh_w_items %>%
  ungroup() %>%
  filter(noun_onset >= 360 & noun_onset <= 3000) %>%
  group_by(recording_name, trial_number) %>% 
  mutate(targets_in_a_row = data.table::rleid(target)) %>%
  group_by(recording_name, trial_number, targets_in_a_row) %>%
  mutate(row = row_number()) %>% 
  mutate(where_looking = case_when(target == TRUE ~ "target",
                                   distractor == TRUE ~ "distractor",
                                   TRUE ~ "neither")) %>%
  filter(where_looking == "target") %>%
  mutate(first_look_dur = max(row_number())*(1000/60)) %>% 
  filter(first_look_dur >= 200) %>%
  group_by(recording_name, trial_number) %>%
  filter(targets_in_a_row == min(targets_in_a_row)) %>% 
  ungroup() %>%
  distinct(recording_name, trial_number, media_name, first_look_dur)
 

```


```{r merging newly created DVs to the original dataset}

#clean variables to be merged

#1)
prop_looking_c<- prop_looking %>%
  select(recording_name, subject_id, trial_number, media_name, prop_looking)

#2)
fixations_total_c<- fixations_total %>%
  select(recording_name, subject_id, trial_number, media_name, looking_to_target)

#3)
RT_c<- RT %>%
select(recording_name, subject_id, trial_number, media_name, latency_to_switch)  

#4)
number_of_switches_c<- number_of_switches %>%
select(recording_name, subject_id, trial_number, media_name, total_aoi_switches)  

#5)
first_look_duration_c<- first_look_duration %>%
 select(recording_name, subject_id, trial_number, media_name, first_look_dur)   



data_new_dvs<- kbh_data_clean %>%
  select(recording_name, media_name, subject_id, trial_number, age_months, exp_to_target_lang)

  data_new_dvs<- full_join(data_new_dvs, prop_looking_c, by=(c("recording_name", "subject_id", "trial_number", "media_name")))
  
   data_new_dvs<- full_join(data_new_dvs, fixations_total_c, by=(c("recording_name", "subject_id", "trial_number", "media_name")))
   
    data_new_dvs<- full_join(data_new_dvs, RT_c, by=(c("recording_name", "subject_id", "trial_number", "media_name")))
    
     data_new_dvs<- full_join(data_new_dvs, number_of_switches_c, by=(c("recording_name", "subject_id", "trial_number", "media_name")))
     
     data_new_dvs<- full_join(data_new_dvs, first_look_duration_c, by=(c("recording_name", "subject_id", "trial_number", "media_name")))


```



```{r correlation matrix between DVs}

#Select only numerical variables for correlation

#PEARSON CORRELATION
for_correlation<- data_new_dvs %>%
  ungroup()%>%
  select(age_months, exp_to_target_lang, prop_looking, looking_to_target, latency_to_switch, total_aoi_switches, first_look_dur)

kbh_correlation <- cor(x=for_correlation, use="complete.obs")

coorelation_for_p<- rcorr(as.matrix(for_correlation))

corrplot(kbh_correlation)



#SPEARMAN CORRELATION

kbh_correlation_s <- cor(x=for_correlation, use="complete.obs", method = "spearman")



corrplot(kbh_correlation_s)


```


