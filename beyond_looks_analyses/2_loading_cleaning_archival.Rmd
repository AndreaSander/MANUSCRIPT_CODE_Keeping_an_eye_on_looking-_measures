---
title: "Archival"
output: html_document
date: "2024-10-23"
---

```{r setup, include=FALSE}

library(tidyverse)
library(dbplyr)
library(tidylog)
library(here)

`%notin%` <- negate(`%in%`)

```


```{r}

#Get data

load(here("archival_KBH_anonimyzed/kbh_w_items.Rda"))
load(here("archival_KBH_anonimyzed/kbh_experimental_items.Rda"))

anon_data <- kbh_w_items %>%
  mutate(exp_type = "non-experimental") %>%
  bind_rows(kbh_experimental_items %>%
  mutate(exp_type = "experimental",
  #fix one case where target word and distractor word are wrong (media name is door L, target side is L, trial lang is English, and yoked pair is door-mouth, so target word is door and distractor word is mouth)
    distractor_word = case_when(target_word == "OTHER" ~ "mouth",
                          TRUE ~ distractor_word),
    target_word = case_when(target_word == "OTHER" ~ "door",
                          TRUE ~ target_word)))  %>%
  rename(dataset_name = studio_project_name) %>%
  filter(!(recording_name == "Mix_20_S52" & trial_number > 1)) #Mix 20 S052 has 23 rows for trials other than trial 1 with no dataâ€”remove these here, try to figure out why this happened

#Get corrected set of yoked pairs

archival_yoked_pairs <- read_csv(here("archival_yoked_pairs.csv")) 
  
#add the same data to itself with the exp_type "both_types" for new analyses that aren't split between types

anon_data <- anon_data %>%
  bind_rows(anon_data %>% mutate(exp_type = "both_types")) %>%
  #Update with corrected list of yoked pairs
  left_join(archival_yoked_pairs) %>%
  mutate(
         yoked_target = case_when(dataset_name == "LearnMix-36" ~ NA_character_,
                                  str_detect(corrected_yoked_pair, target_word) ~ target_word,
                                  str_detect(fr_to_en1, target_word) ~ str_extract(fr_to_en1, "(?<=-).*"),
                                  str_detect(fr_to_en2, target_word) ~ str_extract(fr_to_en2, "(?<=-).*")),
         yoked_distractor = case_when(dataset_name == "LearnMix-36" ~ NA_character_,
                                  str_detect(corrected_yoked_pair, distractor_word) ~ distractor_word,
                                  str_detect(fr_to_en1, distractor_word) ~ str_extract(fr_to_en1, "(?<=-).*"),
                                  str_detect(fr_to_en2, distractor_word) ~ str_extract(fr_to_en2, "(?<=-).*")),
         yoked_pair = case_when(dataset_name == "LearnMix-36" ~ NA_character_,#these ones aren't actually yoked, so they shouldn't be used for prop_looking_diff calculation
                                is.na(corrected_yoked_pair) ~ yoked_pair,
                                TRUE ~ corrected_yoked_pair)) %>%
  select(-corrected_yoked_pair)
  
rm(kbh_w_items)
rm(kbh_experimental_items)

```

#Clean data for trackloss

```{r, message=FALSE}

print_list <- list()

####### Only keep kids with at least 50% of interest period looking AND who have at least 25% of trials
## Total trials for each study is usually 12 (CogMisp, Mix), except CompMix, CompLearn with 16, LearnMix with 6

trial_cutoff <- anon_data %>%
  filter(exp_type == "both_types") %>%
  group_by(recording_name, dataset_name) %>%
  distinct(trial_number) %>%
  count(recording_name) %>%
  rename(n_trials_subject = n) %>%
  group_by(dataset_name) %>%
  mutate(max_trials = max(n_trials_subject)) %>% #HK note: this works in our data because some kids have all possible trials, but will have to change how it's done for peekbank
  ungroup() %>%
  distinct(dataset_name, recording_name, max_trials)

n_subjects_original <- anon_data %>%
  filter(exp_type == "both_types") %>%
  distinct(recording_name, dataset_name) %>%
  count(dataset_name)

n_trials_original <- anon_data %>%
  filter(exp_type == "both_types") %>%
  distinct(recording_name, dataset_name, trial_number) %>%
  nrow()

print_list[[paste("Pre-exclusions N:")]] <- n_subjects_original
print_list[[paste("Pre-exclusions N trials:")]] <- n_trials_original
  
trackloss_cleaned <- anon_data %>%
  filter(exp_type == "both_types") %>%
  #filter to interest period
  filter(noun_onset>= 360 & noun_onset <= 3000) %>%
  #for each kid in each trial,
  group_by(recording_name, trial_number) %>%
  #get trackloss percentage
  mutate(trackloss_pct = sum(trackloss == TRUE)/n(),
         trackloss_cutoff = case_when(trackloss_pct <.5 ~ "keep",
                                      trackloss_pct >= .5 ~ "exclude")) %>%
  ungroup() %>%
  distinct(recording_name, trial_number, trackloss_pct, trackloss_cutoff, dataset_name) %>%
  filter(trackloss_cutoff == "keep") %>%
  group_by(recording_name) %>%
  mutate(n_valid_trials_subject = n()) %>%
  ungroup() %>%
  dplyr::select(dataset_name, recording_name, trial_number, trackloss_pct, n_valid_trials_subject)

n_subjects_after_trackloss_exclusion <- trackloss_cleaned %>%
  distinct(recording_name, dataset_name) %>%
  count(dataset_name)

n_trials_after_trackloss_exclusion <- trackloss_cleaned %>%
  distinct(recording_name, dataset_name, trial_number) %>%
  nrow()

print_list[[paste("After Trackloss Cleaning N subjects:")]] <- n_subjects_after_trackloss_exclusion
print_list[[paste("After Trackloss Cleaning N trials:")]] <- n_trials_after_trackloss_exclusion

anon_data_after_exclusions <- anon_data %>%
  right_join(trackloss_cleaned) %>%
  left_join(trial_cutoff) %>%
  mutate(trial_n_cutoff = round(max_trials*.25, digits = 0)) %>%
  filter(n_valid_trials_subject >= trial_n_cutoff) %>%
  ungroup()

n_subjects_after_trackloss_and_trials_exclusion <- anon_data_after_exclusions %>%
  filter(exp_type == "both_types") %>%
  distinct(recording_name, dataset_name) %>%
  count(dataset_name) #XX kids lost from these exclusions

n_trials_after_trackloss_and_trials_exclusion <- anon_data_after_exclusions %>%
  filter(exp_type == "both_types") %>%
  distinct(recording_name, dataset_name, trial_number) %>%
  nrow() #XX kids lost from these exclusions

print_list[[paste("After Trackloss and Trials Exclusions N subjects:")]] <- n_subjects_after_trackloss_and_trials_exclusion
print_list[[paste("After Trackloss and Trials Exclusions N trials:")]] <- n_trials_after_trackloss_and_trials_exclusion

```


#Make variables
```{r}

for (i in 1:n_distinct(anon_data$exp_type)) {
  
  analysis_type <- unique(anon_data$exp_type)[[i]]
  analysis_dataset <- anon_data_after_exclusions %>%
    filter(exp_type == analysis_type)

#create initial look variable 

initial_looks <- analysis_dataset %>%
  filter(noun_onset >= 260 & noun_onset < 360) %>%
  group_by(recording_name, trial_number, media_name) %>% 
     summarise(
    distractor_count = sum(distractor),
    target_count = sum(target),
    trackloss_count = sum(trackloss)
     ) %>%
  # mutate(initial_look = case_when(target_count >0 ~ "target", #if the child *ever* looks to target during first 100 ms, then counted as initial target look
  #                                 distractor_count/(distractor_count+trackloss_count) >=0.5 ~ "distractor",
  #                                 TRUE ~ "neither")) %>% 
  mutate(initial_look = case_when(target_count > distractor_count ~ "target",
                                  distractor_count > target_count ~ "distractor",
                                  TRUE ~ "neither")) %>%
  ungroup() 


analysis_dataset <- left_join(analysis_dataset, initial_looks, by= c("recording_name", "trial_number", "media_name"))

for (j in c("target", "distractor", "all")) {
  
  if (j %in% c("target", "distractor")) {
  
  analysis_dataset_split <- analysis_dataset %>%
    filter(initial_look == j)
  } else if (j == "all") {
    
    analysis_dataset_split <- analysis_dataset
  }

#1. Proportion looking to target

prop_looking_by_trial <- analysis_dataset_split %>%
  filter(noun_onset>= 360 & noun_onset <= 3000)%>%
  group_by(recording_name, subject_id, trial_number, media_name, 
           age_months, exp_to_target_lang, initial_look) %>%
  summarise(samples_target=sum(target, na.rm = T),
            samples_distractor=sum(distractor, na.rm = T))%>%
  mutate(prop_looking = samples_target/(samples_target + samples_distractor)) %>%
  ungroup()

prop_looking_by_subject <- prop_looking_by_trial %>%
  group_by(recording_name) %>%
  summarise(mean_prop_looking = mean(prop_looking),
            sd_prop_looking = sd(prop_looking),
            n_trials_prop_looking = length(unique(trial_number))) %>%
  ungroup()


#2. Proportion looking difference 
#Within a pair of pictures A and B, the fixation to picture A relative to B when A was the target, minus the fixation #to A when A was the distractor.

prop_looking_diff_by_item <- analysis_dataset_split %>%
  filter(!is.na(yoked_pair)) %>%
  ungroup()%>%
  filter(noun_onset>= 360 & noun_onset <= 3000)%>%
  dplyr::select(recording_name, recording_timestamp, yoked_target, yoked_distractor, target, distractor)%>%
  pivot_longer(c(yoked_target, yoked_distractor), names_to = "word_type", values_to = "word") %>%
  mutate(looking = case_when(word_type == "yoked_target" & target == TRUE ~ TRUE,
                             word_type == "yoked_distractor" & distractor == TRUE ~ TRUE,
                             TRUE ~ FALSE)) %>%
  group_by(recording_name, word_type, word) %>%
  #what percent of the time when x is target are kids looking at x, what percent of the time when x is distractor are kids looking at x
  summarise(prop_looking = sum(looking == T, na.rm = T)/n()) %>%
  pivot_wider(names_from = "word_type", values_from = "prop_looking") %>%
  filter(!is.na(yoked_target) & !is.na(yoked_distractor)) %>%
  mutate(prop_looking_diff = yoked_target - yoked_distractor) %>%
  dplyr::select(recording_name, yoked_target = word, prop_looking_diff) %>%
  ungroup()

prop_looking_diff_by_subject <- prop_looking_diff_by_item %>%  
  group_by(recording_name) %>% #Calculating this variable by subject instead of by trial for the correlation matrix.
  summarise(mean_prop_looking_diff = mean(prop_looking_diff),
            sd_prop_looking_diff = sd(prop_looking_diff),
            n_trials_prop_looking_diff = length(unique(yoked_target))) %>%
  ungroup() #only 165 kids have data for this variable, because they didn't have enough data/trials included with both words of each yoked pair


#3. Number of fixations

#For this one, stretches of same looks are counted as one fixation
fixations_total_by_trial <- analysis_dataset_split %>%
  ungroup() %>%
  filter(noun_onset >= 360 & noun_onset <= 3000) %>%
  group_by(recording_name, trial_number) %>%
  mutate(trackloss_group_id = data.table::rleid(trackloss)) %>%
  group_by(trackloss_group_id, recording_name, trial_number) %>%
  mutate(num_consec_trackloss_rows = n()) %>%
  ungroup() %>%
  filter(trackloss == FALSE | (trackloss == TRUE & num_consec_trackloss_rows >= 2)) %>%
  group_by(recording_name, trial_number) %>% 
  mutate(looking_stretch_id = data.table::rleid(target)) %>%
  group_by(recording_name, trial_number, looking_stretch_id) %>%
  #filter to fixations of at least 12 rows or ~ 200 ms
  filter(n() >= 12) %>%
  #filter to target fixations
  filter(target == TRUE) %>%
  distinct(recording_name, trial_number, looking_stretch_id, initial_look) %>%
  group_by(recording_name, trial_number, initial_look) %>%
  summarise(number_fixations = n()) %>%
  ungroup()

#before, this was just counting number of fixations... changed to mean number fixations per trial per child
mean_num_fixations_by_subject <- fixations_total_by_trial %>%
  group_by(recording_name) %>%
  summarise(mean_number_fixations = mean(number_fixations),
            sd_number_fixations = sd(number_fixations),
            n_trials_number_fixations = length(unique(trial_number))) %>%
  ungroup()



#3.1 Longest fixation to target

#For this one, stretches of same looks are counted as one fixation
longest_look_by_trial <- analysis_dataset_split %>%
  ungroup() %>%
  filter(noun_onset >= 360 & noun_onset <= 3000) %>%
  group_by(recording_name, trial_number) %>%
  mutate(trackloss_group_id = data.table::rleid(trackloss)) %>%
  group_by(trackloss_group_id, recording_name, trial_number) %>%
  mutate(num_consec_trackloss_rows = n()) %>%
  ungroup() %>%
  filter(trackloss == FALSE | (trackloss == TRUE & num_consec_trackloss_rows >= 2)) %>%
  group_by(recording_name, trial_number) %>% 
  mutate(looking_stretch_id = data.table::rleid(target)) %>%
  group_by(recording_name, trial_number, looking_stretch_id) %>%
  #filter to fixations of at least 12 rows or ~ 200 ms
  filter(n() >= 12) %>%
  #filter to target fixations
  filter(target == TRUE) %>%
  count(recording_name, trial_number, looking_stretch_id, initial_look) %>%
  group_by(recording_name, trial_number, initial_look) %>%
  filter(n == max(n)) %>%
  slice_head(n = 1) %>%
  ungroup() %>%
  mutate(longest_look_by_trial = n*(1000/60)) %>%
  dplyr::select(-n, -looking_stretch_id)

#before, this was just counting number of fixations... changed to mean number fixations per trial per child
mean_longest_look_by_subject <- longest_look_by_trial %>%
  group_by(recording_name) %>%
  summarise(mean_longest_look = mean(longest_look_by_trial),
            sd_longest_look = sd(longest_look_by_trial),
            n_trials_number_fixations = length(unique(trial_number))) %>%
  ungroup() 


#4. Correct first shift to target
#On trials where infants were fixated on the distractor upon hearing the target word (i.e., distractor-initial trials), does the kid shift to the target picture within the 300â€“1,800 ms window following target word onset, as a proportion of all distractor-initial trials.
  

first_shift_target <- analysis_dataset_split %>%
  ungroup() %>%
  filter(noun_onset >= 360 & noun_onset <= 1800) %>% #Keeping the shorter window to be consistent with Fernald

  
    #Grouping and summarizing to get by subject by trial flagging of whether there was switching or not.
     group_by(recording_name, subject_id, trial_number, media_name, initial_look) %>%  
  summarise(target = sum(target, na.rm = T),
            distractor =  sum(distractor, na.rm = T)) %>% #Counting how many looks to target and distractor by timeslice grouped by target or distractor initial trials.
  ungroup() %>%
  mutate(correct_shift = case_when(initial_look == "target" & distractor ==0 ~ TRUE,
                                   initial_look == "distractor" & target >0 ~ TRUE,
                                   TRUE~FALSE)) #Making a column to calculate correct shifts. We defined correct shift as never looking to the distractor on target initial trial, or switching to the taget on distractor initial trials

prop_shifts_distractor_initial_by_trial <- first_shift_target %>%
    filter(initial_look == "distractor") 

prop_shifts_distractor_initial_by_subject <- prop_shifts_distractor_initial_by_trial %>%
  group_by(recording_name, initial_look) %>%
    summarise(mean_prop_shift_distractor_initial = sum(correct_shift == TRUE)/n(),
              sd_prop_shift_distractor_initial = sd(as.numeric(correct_shift)),
            n_trials_prop_shift_distractor_initial = length(unique(trial_number))) #some SDs are NA because the child only has one row, and no standard deviation can be calculated from one value
  
prop_shifts_target_initial_by_trial <- first_shift_target %>%
    filter(initial_look == "target") 

prop_shifts_target_initial_by_subject <- prop_shifts_target_initial_by_trial %>%
  group_by(recording_name, initial_look) %>%
    summarise(mean_prop_shift_target_initial = sum(correct_shift == TRUE)/n(),
              sd_prop_shift_target_initial = sd(as.numeric(correct_shift)),
            n_trials_prop_shift_target_initial = length(unique(trial_number))) #some SDs are NA because the child only has one row, and no standard deviation can be calculated from one value
  

#5. Reaction time

#do we want the latency from noun onset (0) or from window of analysis(360)? Right now using window of analysis

RT_by_trial <- analysis_dataset_split %>%
  ungroup() %>%
  filter(noun_onset >= 360 & noun_onset <= 1800) %>% #Keeping the shorter window to be consistent with Fernald
    #Grouping and summarizing to get by subject by trial flagging of whether there was switching or not.
  filter(initial_look == "distractor") %>%
  filter(target == TRUE) %>%
  group_by(trial_number, media_name, recording_name, subject_id, initial_look, target) %>%
  slice_head() %>%
  mutate(latency_to_switch = noun_onset - 360) %>%
  ungroup() %>%
  dplyr::select(recording_name, trial_number, latency_to_switch, initial_look) 

RT_by_subject <- RT_by_trial %>%
  group_by(recording_name) %>%
  summarise(mean_RT = mean(latency_to_switch, na.rm = T),
            sd_RT = sd(latency_to_switch, na.rm = T),
            n_trials_RT = length(unique(trial_number))) %>%
  ungroup()


#6. Total number of switches between AOIs

number_of_switches_by_trial <- analysis_dataset_split %>%
  ungroup() %>%
  filter(noun_onset >= 360 & noun_onset <= 3000) %>%
  #for this one, get rid of track loss rows
  filter(trackloss == FALSE) %>%
  group_by(recording_name, trial_number) %>% 
  mutate(looking_stretch_id = data.table::rleid(target)) %>%
  group_by(recording_name, trial_number, looking_stretch_id) %>%
  #keep stretches that are at least 200 ms or 12 rows
  filter(n() >= 12) %>%
  mutate(where_looking = case_when(target == TRUE ~ "target",
                                   distractor == TRUE ~ "distractor",
                                   TRUE ~ "neither")) %>%
  filter(where_looking != "neither") %>%
  distinct(recording_name, trial_number, looking_stretch_id, where_looking, media_name, subject_id, initial_look) %>%
  group_by(recording_name, trial_number) %>%
  mutate(AOI_switches = case_when(lag(where_looking) == "target" & where_looking == "distractor" ~ 1,
                            lag(where_looking) == "distractor" & where_looking == "target" ~ 1)) %>%
  group_by(recording_name, trial_number, initial_look) %>%
  summarise(total_aoi_switches = sum(AOI_switches, na.rm = T)) %>%
  ungroup()

number_of_switches_by_subject <- number_of_switches_by_trial %>%
  group_by(recording_name) %>%
  summarise(mean_aoi_switches = mean(total_aoi_switches, na.rm = T),
            n_trials_mean_aoi_switches = length(unique(trial_number))) %>%
  ungroup()


#8. Mean fixation duration during trial
#Mean duration of fixations during the window of analysis within a trial. Mean by subject by trial?

mean_fixation_dur_by_trial <- analysis_dataset_split %>%
  filter(noun_onset>= 360 & noun_onset <= 3000)%>%
  group_by(recording_name, trial_number) %>%
  mutate(trackloss_group_id = data.table::rleid(trackloss)) %>%
  group_by(trackloss_group_id, recording_name, trial_number) %>%
  mutate(num_consec_trackloss_rows = n()) %>%
  ungroup() %>%
  filter(trackloss == FALSE | (trackloss == TRUE & num_consec_trackloss_rows >= 2)) %>%
  group_by(recording_name, trial_number) %>% 
  mutate(looking_stretch_id = data.table::rleid(target)) %>%
  group_by(recording_name, trial_number, looking_stretch_id) %>%
  #filter to fixations of at least 12 rows or ~ 200 ms
  filter(n() >= 12) %>%
  filter(target == TRUE) %>%
  group_by(recording_name, trial_number, media_name, looking_stretch_id, initial_look) %>%
  summarise(length_of_looks = n()) %>%
  mutate(duration_of_look = length_of_looks*(1000/60)) %>%
  group_by(recording_name, trial_number, initial_look) %>%
  summarise(duration_of_look = mean(duration_of_look, na.rm = T)) %>%
  ungroup()

mean_fixation_dur_by_subject <- mean_fixation_dur_by_trial %>% 
  group_by(recording_name) %>%
  summarise(mean_duration_of_look = mean(duration_of_look, na.rm = T),
            sd_duration_of_look = sd(duration_of_look, na.rm = T),
            n_trials_duration_of_look = length(unique(trial_number))) %>%
  ungroup()


#11. Duration of first look
### Duration of the first look recorded toward a particular AOI. - To target specifically, with at least 200 ms fixation length

first_look_duration_by_trial <- analysis_dataset_split %>%
  ungroup() %>%
  filter(noun_onset >= 360 & noun_onset <= 3000) %>%
  group_by(recording_name, trial_number) %>% 
  mutate(trackloss_group_id = data.table::rleid(trackloss)) %>%
  group_by(trackloss_group_id, recording_name, trial_number) %>%
  mutate(num_consec_trackloss_rows = n()) %>%
  ungroup() %>%
  filter(trackloss == FALSE | (trackloss == TRUE & num_consec_trackloss_rows >= 2)) %>%
  group_by(recording_name, trial_number) %>% 
  mutate(looking_stretch_id = data.table::rleid(target)) %>%
  group_by(recording_name, trial_number, looking_stretch_id) %>%
  mutate(row = row_number()) %>% 
  mutate(where_looking = case_when(target == TRUE ~ "target",
                                   distractor == TRUE ~ "distractor",
                                   TRUE ~ "neither")) %>%
  filter(where_looking == "target") %>%
  mutate(first_look_dur = max(row_number())*(1000/60)) %>% 
  filter(first_look_dur >= 200) %>%
  group_by(trial_number, recording_name) %>%
  filter(looking_stretch_id == min(looking_stretch_id)) %>% 
  ungroup() %>%
  distinct(recording_name, trial_number, media_name, first_look_dur, initial_look) %>%
  ungroup()

first_look_duration_by_subject <- first_look_duration_by_trial %>%
  group_by(recording_name) %>%
  summarise(mean_first_look_dur = mean(first_look_dur, na.rm = T),
            sd_first_look_dur = sd(first_look_dur, na.rm = T),
            n_trials_first_look_dur = length(unique(trial_number))) %>%
  ungroup()

#Pupil dilation
#Baseline pupil size in the 200ms before noun onset and then subtracted the baseline from the pupil size measurements on each trial.
#In Liz's paper they contrasted time slice by time slice across two conditions, but here we don't have switched and same language conditions. I'll do average size at baseline and avg size after noun onset for now. But then talk with team about it.


pupil_dilation <- analysis_dataset_split %>%
  ungroup() %>%
  filter(noun_onset>= -200 & noun_onset <= 500)%>%
mutate(pupil_period = case_when(noun_onset >= -200 & noun_onset <= 0 ~ "baseline",
                                TRUE ~ "post_onset"))%>% 
  dplyr::select(recording_timestamp, subject_id, recording_name, trial_number, media_name, pupil_period, pupil_right, pupil_left, initial_look) %>%
  mutate(two_pupil_mean = case_when(is.na(pupil_left) & is.na(pupil_right) ~ NA,
                                         is.na(pupil_left)  ~ pupil_right,
                                         is.na(pupil_right) ~ pupil_left,
                                         TRUE ~ (pupil_left + pupil_right)/2)) %>%
  filter(!is.na(two_pupil_mean))

#The next steps are confusing to me.Should we average baseline pupil? Should we contrast each post onset time slice to a partricular baseline time slice? We could use mean dilation, peak dilation (or peak amplitude), and/or peak latency (i.e., the time between onset and peak pupil dilation). The problem with mean dilation is that the baseline has less sampling than the post-onset. Could we do peak dilation of baseline vs. peak dilation post onset? Or peak dilation but from which baseline point? from peak? We will for sure do GCA's as extra analyses

#Peak dilation
peak_dilation_by_trial <- pupil_dilation %>%
  ungroup()%>%
  group_by(trial_number, recording_name, subject_id, pupil_period, initial_look) %>%
  summarise(peak_pupil = max(two_pupil_mean)) %>%
  pivot_wider(names_from = pupil_period, values_from ="peak_pupil")%>%
  mutate(peak_pupil_size_difference = post_onset - baseline) %>% #difference in peak pupil points
  filter(!is.na(peak_pupil_size_difference)) %>%
  rename(max_pupil_baseline = baseline,
         max_pupil_post_onset = post_onset) %>%
  ungroup()

peak_dilation_by_subject <- peak_dilation_by_trial %>%
  group_by(recording_name, subject_id) %>%
  summarise(mean_peak_pupil_size_difference = mean(peak_pupil_size_difference),
            sd_peak_pupil_size_difference = sd(peak_pupil_size_difference),
            n_trials_peak_pupil_size_difference = length(unique(trial_number))) %>%
  ungroup() 
  
#Mean dilation
mean_dilation_by_trial <- pupil_dilation %>%
  ungroup()%>%
  group_by(trial_number, recording_name, subject_id, pupil_period, initial_look) %>%
  summarise(mean_pupil = mean(two_pupil_mean, na.rm = T)) %>%
  pivot_wider(names_from = pupil_period, values_from ="mean_pupil")%>%
  mutate(mean_pupil_size_difference = post_onset - baseline) %>% #difference in peak pupil points
  filter(!is.na(mean_pupil_size_difference)) %>%
  rename(mean_pupil_baseline = baseline,
         mean_pupil_post_onset = post_onset) %>%
  ungroup() 

mean_dilation_by_subject <- mean_dilation_by_trial %>%
  group_by(recording_name, subject_id) %>%
  summarise(mean_mean_pupil_size_difference = mean(mean_pupil_size_difference),
            sd_mean_pupil_size_difference = sd(mean_pupil_size_difference),
            n_trials_mean_pupil_size_difference = length(unique(trial_number))) %>%
  ungroup()

#peak latency
peak_pupil_latency_by_trial <- pupil_dilation %>%
  ungroup()%>%
  group_by(trial_number, recording_name, pupil_period) %>%
  slice(which.max(two_pupil_mean)) %>%
  dplyr::select(recording_name, subject_id, pupil_period, peak_time_stamp = recording_timestamp, initial_look) %>%
  group_by(trial_number, recording_name, subject_id, initial_look) %>%
  summarise(peak_pupil_latency = diff(peak_time_stamp)) %>%
  ungroup()

peak_pupil_latency_by_subject <- peak_pupil_latency_by_trial %>%
  group_by(recording_name, subject_id) %>%
  summarise(mean_peak_pupil_latency = mean(peak_pupil_latency),
            sd_peak_pupil_latency = sd(peak_pupil_latency),
            n_trials_peak_pupil_latency = length(unique(trial_number)))



#------------------------------Put all together in one dataset

data_new_dvs_by_trial <- analysis_dataset_split %>%
  distinct(recording_name, trial_number, subject_id, dataset_name, age_months, target_word, distractor_word, yoked_pair, exp_to_target_lang, fre_exp, eng_exp) %>%
   rename(yoked_target = target_word,
          yoked_distractor = distractor_word) %>%
  left_join(prop_looking_by_trial) %>%
  left_join(prop_looking_diff_by_item) %>%
  left_join(fixations_total_by_trial) %>%
  left_join(prop_shifts_distractor_initial_by_trial %>% dplyr::select(-media_name, -target, -distractor)) %>%
  left_join(prop_shifts_target_initial_by_trial %>% dplyr::select(-media_name, -target, -distractor) %>% rename(remain_on_target = correct_shift)) %>%
  left_join(RT_by_trial) %>%
  left_join(number_of_switches_by_trial) %>%
  left_join(mean_fixation_dur_by_trial) %>%
  left_join(first_look_duration_by_trial) %>%
  left_join(longest_look_by_trial) %>% 
  left_join(peak_dilation_by_trial) %>%
  left_join(mean_dilation_by_trial) %>%
  left_join(peak_pupil_latency_by_trial) %>%
  ungroup() %>%
  mutate(age_months_centred = age_months - 25,
         correct_shift = case_when(correct_shift == T ~ 1,
                                   correct_shift == F ~ 0),
         remain_on_target = case_when(remain_on_target == T ~ 1,
                                   remain_on_target == F ~ 0))

data_new_dvs_by_subject <- analysis_dataset_split %>%
  distinct(recording_name, subject_id, dataset_name, age_months, exp_to_target_lang, fre_exp, eng_exp) %>% 
  left_join(prop_looking_by_subject) %>%
  left_join(prop_looking_diff_by_subject) %>%
  left_join(mean_num_fixations_by_subject) %>%
  left_join(prop_shifts_target_initial_by_subject %>% select(-initial_look)) %>%
  left_join(prop_shifts_distractor_initial_by_subject %>% select(-initial_look)) %>%
  left_join(RT_by_subject) %>%
  left_join(number_of_switches_by_subject) %>%
  left_join(mean_fixation_dur_by_subject) %>%
  left_join(first_look_duration_by_subject) %>%
  left_join(mean_longest_look_by_subject) %>% 
  left_join(peak_dilation_by_subject) %>%
  left_join(mean_dilation_by_subject) %>%
  left_join(peak_pupil_latency_by_subject) %>%
  ungroup()%>%
  mutate(age_months_centred = age_months - 25)


#export to later get means, SDs for calculating Cohen's D when dataset is run with the other experimental type
data_new_dvs_by_subject %>%
  mutate(data_split = j) %>%
  write_csv(here(paste0("all_variables_datasets/archival_by_subject_means_sds_", analysis_type, "_", j, ".csv")))

data_new_dvs_by_trial %>%
  mutate(data_split = j) %>% 
  write_csv(here(paste0("all_variables_datasets/archival_by_trial_means_sds_", analysis_type, "_", j, ".csv")))


#How many trials in average when we collapse by subject?

num_trials_per_subject <- round(data_new_dvs_by_trial %>%
  group_by(recording_name) %>%
    summarise(num_trials = length(unique(trial_number))) %>%
    summarise(avg_num_trials = mean(num_trials)) %>% pull(avg_num_trials), digits = 1)

print_list[[paste(analysis_type, "average number of trials per participant (", j, "):")]] <- num_trials_per_subject

#Save datasets to load and use in next section where non-exp and exp are both needed
# 
# save(data_new_dvs_by_subject, file = here(paste0("all_variables_datasets/peekbank_bysubject_", analysis_type, "_", j, ".Rda")))



}
}

```

#Print list

```{r}

#Save the print_list to a text file to get all the output in one place

#sink(here(paste0("beyond_looks_analyses/", analysis_type, "_code_printout.txt"))); print(print_list); sink()

```

