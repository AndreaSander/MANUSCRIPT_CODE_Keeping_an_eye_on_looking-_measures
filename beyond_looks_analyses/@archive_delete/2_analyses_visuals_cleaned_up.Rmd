---
title: "2_Analyses_and_visuals"
author: "ASM"
date: "2023-10-25"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE)
options(scipen = 999)
```

# Set variables for which dataset to analyze
```{r}

analysis_type <- "experimental" #choose from "experimental" or "non-experimental" to run the entire script on either just the experimental trials or just the non-experimental trials

```


```{r call in libraries and clean data, include=FALSE}
library(here)
library(dplyr)
library(stringr)
library(Hmisc)
library(corrplot)
library(zoo)
library(eyetrackingR)
library(psych)
library(QuantPsyc)
library(lmerTest)
library(DHARMa)
library(performance)
library(psych)
library(tidyverse)

if (analysis_type == "non-experimental") {
  load(here("archival_KBH_anonimyzed/kbh_w_items.Rda"))
  analysis_data <- kbh_w_items
  rm(kbh_w_items)
} else if (analysis_type == "experimental") {
  load(here("archival_KBH_anonimyzed/kbh_experimental_items.Rda"))
  analysis_data <- kbh_experimental_items
  rm(kbh_experimental_items)
}

`%notin%` <- negate(`%in%`)
```

#Data cleaning
```{r}
####### Only keep kids with at least 50% of interest period looking AND who have at least 25% of trials
## Total trials for each study is usually 12 (CogMisp, Mix), except CompMix, CompLearn with 16, LearnMix with 6

trial_cutoff <- analysis_data %>%
  group_by(recording_name) %>%
  distinct(studio_project_name, trial_number) %>%
  count(studio_project_name, recording_name) %>%
  group_by(studio_project_name) %>%
  rename(n_trials_subject = n) %>%
  mutate(max_trials_study = max(n_trials_subject)) %>%
  distinct(studio_project_name, max_trials_study)

n_subjects_original <- n_distinct(analysis_data$recording_name)
  
trackloss_cleaned <- analysis_data %>%
  #for each kid in each trial,
  group_by(recording_name, trial_number) %>%
  #filter to interest period
  filter(noun_onset>= 360 & noun_onset <= 3000) %>%
  #get trackloss percentage
  mutate(trackloss_pct = sum(trackloss == TRUE)/n(),
         trackloss_cutoff = case_when(trackloss_pct <.5 ~ "keep",
                                      trackloss_pct >= .5 ~ "exclude")) %>%
  ungroup() %>%
  distinct(recording_name, subject_id, trial_number, trackloss_pct, trackloss_cutoff) %>%
  filter(trackloss_cutoff == "keep") %>%
  group_by(recording_name) %>%
  mutate(n_valid_trials_subject = n()) %>%
  ungroup() %>%
  dplyr::select(recording_name, subject_id, trial_number, trackloss_pct, n_valid_trials_subject)

n_subjects_after_trackloss_exclusion <- n_distinct(trackloss_cleaned$recording_name)
  
analysis_dataset <- analysis_data %>%
  right_join(trackloss_cleaned) %>%
  left_join(trial_cutoff) %>%
  mutate(trial_n_cutoff = round(max_trials_study*.25, digits = 0)) %>%
  filter(n_valid_trials_subject >= trial_n_cutoff) %>%
  ungroup()

n_subjects_after_trackloss_and_trials_exclusion <- n_distinct(analysis_dataset$recording_name) #6 kids lost from these exclusions

```



#Make variables
```{r calculate all the different dependent variables}

###### First, create variables that will be useful for the calculations below ## TRY TO DO IT IN THE SAME DATA SET
initial_looks <- analysis_dataset %>%
  filter(noun_onset >= 260 & noun_onset < 360) %>%
  group_by(recording_name, trial_number, media_name) %>% 
     summarise(
    distractor_count = sum(distractor),
    target_count = sum(target),
    trackloss_count = sum(trackloss)
     )%>%
  mutate(initial_look = case_when(target_count >0 ~ "target", #if the child *ever* looks to target during first 100 ms, then counted as initial target look
                                  distractor_count/(distractor_count+trackloss_count) >=0.5 ~ "distractor",
                                  TRUE ~ "neither"))

analysis_dataset <- left_join(analysis_dataset, initial_looks, by= c("recording_name", "trial_number", "media_name"))

#We are considering distractor initial trials as trials where in the first 100 ms ofr the analyses window the child looked at the distractor at least 50% of the time and never looked to target.


#Mix 20 S052 has 23 rows for trials other than trial 1 with no data—remove these here, try to figure out why this happened

analysis_dataset <- analysis_dataset %>%
  filter(!(recording_name == "Mix_20_S52" & trial_number > 1))

#1. Proportion looking to target

prop_looking_by_trial <- analysis_dataset %>%
  filter(noun_onset>= 360 & noun_onset <= 3000)%>%
  group_by(recording_name, subject_id, trial_number, media_name, 
           age_months, exp_to_target_lang, initial_look) %>%
  summarise(samples_target=sum(target, na.rm = T),
            samples_distractor=sum(distractor, na.rm = T))%>%
  mutate(prop_looking = samples_target/(samples_target + samples_distractor)) %>%
  ungroup()

prop_looking_by_subject <- prop_looking_by_trial %>%
  group_by(recording_name, subject_id) %>%
  summarise(mean_prop_looking = mean(prop_looking),
            sd_prop_looking = sd(prop_looking),
            n_trials_prop_looking = length(unique(trial_number))) %>%
  ungroup()

#2. Proportion looking difference 
#Within a pair of pictures A and B, the fixation to picture A relative to B when A was the target, minus the fixation #to A when A was the distractor.

prop_looking_diff_by_item <- analysis_dataset %>%
  ungroup()%>%
  filter(noun_onset>= 360 & noun_onset <= 3000)%>%
  dplyr::select(recording_name, subject_id, recording_timestamp, target_word, distractor_word, target, distractor)%>%
  pivot_longer(c(target_word, distractor_word), names_to = "word_type", values_to = "word") %>%
  mutate(looking = case_when(word_type == "target_word" & target == TRUE ~ TRUE,
                             word_type == "distractor_word" & distractor == TRUE ~ TRUE,
                             TRUE ~ FALSE)) %>%
  group_by(recording_name, subject_id, word_type, word) %>%
  #what percent of the time when x is target are kids looking at x, what percent of the time when x is distractor are kids looking at x
  summarise(prop_looking = sum(looking == T, na.rm = T)/n()) %>%
  pivot_wider(names_from = "word_type", values_from = "prop_looking") %>%
  filter(!is.na(target_word) & !is.na(distractor_word)) %>%
  mutate(prop_looking_diff = target_word - distractor_word) %>%
  dplyr::select(recording_name, subject_id, target_word = word, prop_looking_diff) %>%
  ungroup() 

prop_looking_diff_by_subject <- prop_looking_diff_by_item %>%  
  group_by(recording_name, subject_id) %>% #Calculating this variable by subject instead of by trial for the correlation matrix.
  summarise(mean_prop_looking_diff = mean(prop_looking_diff),
            sd_prop_looking_diff = sd(prop_looking_diff),
            n_trials_prop_looking_diff = length(unique(target_word))) %>%
  ungroup() #only 165 kids have data for this variable, because they didn't have enough data/trials included with both words of each yoked pair


#For this one, stretches of same looks are counted as one fixation
fixations_total_by_trial <- analysis_dataset %>%
  ungroup() %>%
  filter(noun_onset >= 360 & noun_onset <= 3000) %>%
  group_by(recording_name, trial_number) %>%
  mutate(trackloss_group_id = data.table::rleid(trackloss)) %>%
  group_by(trackloss_group_id, recording_name, trial_number) %>%
  mutate(num_consec_trackloss_rows = n()) %>%
  ungroup() %>%
  filter(trackloss == FALSE | (trackloss == TRUE & num_consec_trackloss_rows >= 2)) %>%
  group_by(recording_name, trial_number) %>% 
  mutate(looking_stretch_id = data.table::rleid(target)) %>%
  group_by(recording_name, trial_number, looking_stretch_id) %>%
  #filter to fixations of at least 12 rows or ~ 200 ms
  filter(n() >= 12) %>%
  #filter to target fixations
  filter(target == TRUE) %>%
  distinct(recording_name, subject_id, trial_number, looking_stretch_id, initial_look) %>%
  group_by(recording_name, subject_id, trial_number, initial_look) %>%
  summarise(number_fixations = n()) %>%
  ungroup()

#before, this was just counting number of fixations... changed to mean number fixations per trial per child
mean_num_fixations_by_subject <- fixations_total_by_trial %>%
  group_by(recording_name, subject_id) %>%
  summarise(mean_number_fixations = mean(number_fixations),
            sd_number_fixations = sd(number_fixations),
            n_trials_number_fixations = length(unique(trial_number))) %>%
  ungroup()
  
#4. Correct first shift to target
#On trials where infants were fixated on the distractor upon hearing the target word (i.e., distractor-initial trials), does the kid shift to the target picture within the 300–1,800 ms window following target word onset, as a proportion of all distractor-initial trials.
  

first_shift_target <- analysis_dataset %>%
  ungroup() %>%
  filter(noun_onset >= 360 & noun_onset <= 1800) %>% #Keeping the shorter window to be consistent with Fernald

  
    #Grouping and summarizing to get by subject by trial flagging of whether there was switching or not.
     group_by(recording_name, subject_id, trial_number, media_name, initial_look) %>%  
  summarise(target = sum(target, na.rm = T),
            distractor =  sum(distractor, na.rm = T)) %>% #Counting how many looks to target and distractor by timeslice grouped by target or distractor initial trials.
  ungroup() %>%
  mutate(correct_shift = case_when(initial_look == "target" & distractor ==0 ~ TRUE,
                                   initial_look == "distractor" & target >0 ~ TRUE,
                                   TRUE~FALSE)) #Making a column to calculate correct shifts. We defined correct shift as never looking to the distractor on target initial trial, or switching to the taget on distractor initial trials

prop_shifts_distractor_initial_by_trial <- first_shift_target %>%
    filter(initial_look == "distractor") 

prop_shifts_distractor_initial_by_subject <- prop_shifts_distractor_initial_by_trial %>%
  group_by(recording_name, subject_id, initial_look) %>%
    summarise(prop_shift_distractor_initial = sum(correct_shift == TRUE)/n(),
              sd_prop_shift_distractor_initial = sd(as.numeric(correct_shift)),
            n_trials_prop_shift_distractor_initial = length(unique(trial_number))) #some SDs are NA because the child only has one row, and no standard deviation can be calculated from one value
  
prop_shifts_target_initial_by_trial <- first_shift_target %>%
    filter(initial_look == "target") 

prop_shifts_target_initial_by_subject <- prop_shifts_target_initial_by_trial %>%
  group_by(recording_name, initial_look) %>%
    summarise(mean_prop_shift_target_initial = sum(correct_shift == TRUE)/n(),
              sd_prop_shift_target_initial = sd(as.numeric(correct_shift)),
            n_trials_prop_shift_target_initial = length(unique(trial_number))) #some SDs are NA because the child only has one row, and no standard deviation can be calculated from one value
  

#5. Reaction time

#do we want the latency from noun onset (0) or from window of analysis(360)? Right now using window of analysis

RT_by_trial <- analysis_dataset %>%
  ungroup() %>%
  filter(noun_onset >= 360 & noun_onset <= 1800) %>% #Keeping the shorter window to be consistent with Fernald
    #Grouping and summarizing to get by subject by trial flagging of whether there was switching or not.
  filter(initial_look == "distractor") %>%
  filter(target == TRUE) %>%
  group_by(trial_number, media_name, recording_name, subject_id, initial_look, target) %>%
  slice_head() %>%
  mutate(latency_to_switch = noun_onset - 360) %>%
  ungroup() %>%
  dplyr::select(recording_name, subject_id, trial_number, latency_to_switch, initial_look) 

RT_by_subject <- RT_by_trial %>%
  group_by(recording_name, subject_id) %>%
  summarise(mean_RT = mean(latency_to_switch, na.rm = T),
            sd_RT = sd(latency_to_switch, na.rm = T),
            n_trials_RT = length(unique(trial_number))) %>%
  ungroup()


#6. Total number of switches between AOIs

number_of_switches_by_trial <- analysis_dataset %>%
  ungroup() %>%
  filter(noun_onset >= 360 & noun_onset <= 3000) %>%
  #for this one, get rid of track loss rows
  filter(trackloss == FALSE) %>%
  group_by(recording_name, trial_number) %>% 
  mutate(looking_stretch_id = data.table::rleid(target)) %>%
  group_by(recording_name, trial_number, looking_stretch_id) %>%
  #keep stretches that are at least 200 ms or 12 rows
  filter(n() >= 12) %>%
  mutate(where_looking = case_when(target == TRUE ~ "target",
                                   distractor == TRUE ~ "distractor",
                                   TRUE ~ "neither")) %>%
  filter(where_looking != "neither") %>%
  distinct(recording_name, trial_number, looking_stretch_id, where_looking, media_name, subject_id, initial_look) %>%
  group_by(recording_name, trial_number) %>%
  mutate(AOI_switches = case_when(lag(where_looking) == "target" & where_looking == "distractor" ~ 1,
                            lag(where_looking) == "distractor" & where_looking == "target" ~ 1)) %>%
  group_by(recording_name, subject_id, trial_number, initial_look) %>%
  summarise(total_aoi_switches = sum(AOI_switches, na.rm = T)) %>%
  ungroup()

number_of_switches_by_subject <- number_of_switches_by_trial %>%
  group_by(recording_name, subject_id) %>%
  summarise(total_aoi_switches = sum(total_aoi_switches, na.rm = T),
            n_trials_total_aoi_switches = length(unique(trial_number))) %>%
  ungroup()
  
 

#8. Mean fixation duration during trial
#Mean duration of fixations during the window of analysis within a trial. Mean by subject by trial?

mean_fixation_dur_by_trial <- analysis_dataset %>%
  filter(noun_onset>= 360 & noun_onset <= 3000)%>%
  group_by(recording_name, trial_number) %>%
  mutate(trackloss_group_id = data.table::rleid(trackloss)) %>%
  group_by(trackloss_group_id, recording_name, trial_number) %>%
  mutate(num_consec_trackloss_rows = n()) %>%
  ungroup() %>%
  filter(trackloss == FALSE | (trackloss == TRUE & num_consec_trackloss_rows >= 2)) %>%
  group_by(recording_name, trial_number) %>% 
  mutate(looking_stretch_id = data.table::rleid(target)) %>%
  group_by(recording_name, trial_number, looking_stretch_id) %>%
  #filter to fixations of at least 12 rows or ~ 200 ms
  filter(n() >= 12) %>%
  filter(target == TRUE) %>%
  group_by(recording_name,subject_id,  trial_number, media_name, looking_stretch_id, initial_look) %>%
  summarise(length_of_looks = n()) %>%
  mutate(duration_of_look = length_of_looks*(1000/60)) %>%
  group_by(recording_name, subject_id, trial_number, initial_look) %>%
  summarise(duration_of_look = mean(duration_of_look, na.rm = T)) %>%
  ungroup()

mean_fixation_dur_by_subject <- mean_fixation_dur_by_trial %>% 
  group_by(recording_name, subject_id) %>%
  summarise(mean_duration_of_look = mean(duration_of_look, na.rm = T),
            sd_duration_of_look = sd(duration_of_look, na.rm = T),
            n_trials_duration_of_look = length(unique(trial_number))) %>%
  ungroup()


#10. Pupil dilation
#Baseline pupil size in the 200ms before noun onset and then subtracted the baseline from the pupil size measurements on each trial.
#In Liz's paper they contrasted time slice by time slice across two conditions, but here we don't have switched and same language conditions. I'll do average size at baseline and avg size after noun onset for now. But then talk with team about it.


pupil_dilation <- analysis_dataset %>%
  ungroup() %>%
  filter(noun_onset>= -200 & noun_onset <= 500)%>%
mutate(pupil_period = case_when(noun_onset >= -200 & noun_onset <= 0 ~ "baseline",
                                TRUE ~ "post_onset"))%>% 
  dplyr::select(recording_timestamp, subject_id, recording_name, trial_number, media_name, pupil_period, pupil_right, pupil_left, initial_look) %>%
  mutate(two_pupil_mean = case_when(is.na(pupil_left) & is.na(pupil_right) ~ NA,
                                         is.na(pupil_left)  ~ pupil_right,
                                         is.na(pupil_right) ~ pupil_left,
                                         TRUE ~ (pupil_left + pupil_right)/2)) %>%
  filter(!is.na(two_pupil_mean))

#The next steps are confusing to me.Should we average baseline pupil? Should we contrast each post onset time slice to a partricular baseline time slice? We could use mean dilation, peak dilation (or peak amplitude), and/or peak latency (i.e., the time between onset and peak pupil dilation). The problem with mean dilation is that the baseline has less sampling than the post-onset. Could we do peak dilation of baseline vs. peak dilation post onset? Or peak dilation but from which baseline point? from peak? We will for sure do GCA's as extra analyses

#Peak dilation
peak_dilation_by_trial <- pupil_dilation %>%
  ungroup()%>%
  group_by(trial_number, recording_name, subject_id, pupil_period, initial_look) %>%
  summarise(peak_pupil = max(two_pupil_mean)) %>%
  pivot_wider(names_from = pupil_period, values_from ="peak_pupil")%>%
  mutate(peak_pupil_size_difference = post_onset - baseline) %>% #difference in peak pupil points
  filter(!is.na(peak_pupil_size_difference)) %>%
  rename(max_pupil_baseline = baseline,
         max_pupil_post_onset = post_onset) %>%
  ungroup()

peak_dilation_by_subject <- peak_dilation_by_trial %>%
  group_by(recording_name, subject_id) %>%
  summarise(mean_peak_pupil_size_difference = mean(peak_pupil_size_difference),
            sd_peak_pupil_size_difference = sd(peak_pupil_size_difference),
            n_trials_peak_pupil_size_difference = length(unique(trial_number))) %>%
  ungroup() 
  
#Mean dilation
mean_dilation_by_trial <- pupil_dilation %>%
  ungroup()%>%
  group_by(trial_number, recording_name, subject_id, pupil_period, initial_look) %>%
  summarise(mean_pupil = mean(two_pupil_mean, na.rm = T)) %>%
  pivot_wider(names_from = pupil_period, values_from ="mean_pupil")%>%
  mutate(mean_pupil_size_difference = post_onset - baseline) %>% #difference in peak pupil points
  filter(!is.na(mean_pupil_size_difference)) %>%
  rename(mean_pupil_baseline = baseline,
         mean_pupil_post_onset = post_onset) %>%
  ungroup() 

mean_dilation_by_subject <- mean_dilation_by_trial %>%
  group_by(recording_name, subject_id) %>%
  summarise(mean_mean_pupil_size_difference = mean(mean_pupil_size_difference),
            sd_mean_pupil_size_difference = sd(mean_pupil_size_difference),
            n_trials_mean_pupil_size_difference = length(unique(trial_number))) %>%
  ungroup()
  

#peak latency
peak_pupil_latency_by_trial <- pupil_dilation %>%
  ungroup()%>%
  group_by(trial_number, recording_name, pupil_period) %>%
  slice(which.max(two_pupil_mean)) %>%
  dplyr::select(recording_name, subject_id, pupil_period, peak_time_stamp = recording_timestamp, initial_look) %>%
  group_by(trial_number, recording_name, subject_id, initial_look) %>%
  summarise(peak_pupil_latency = diff(peak_time_stamp)) %>%
  ungroup()

peak_pupil_latency_by_subject <- peak_pupil_latency_by_trial %>%
  group_by(recording_name, subject_id) %>%
  summarise(mean_peak_pupil_latency = mean(peak_pupil_latency),
            sd_peak_pupil_latency = sd(peak_pupil_latency),
            n_trials_peak_pupil_latency = length(unique(trial_number)))


#11. Duration of first look
### Duration of the first look recorded toward a particular AOI. - To target specifically, with at least 200 ms fixation length

first_look_duration_by_trial <- analysis_dataset %>%
  ungroup() %>%
  filter(noun_onset >= 360 & noun_onset <= 3000) %>%
  group_by(recording_name, trial_number) %>% 
  mutate(looking_stretch_id = data.table::rleid(target)) %>%
  group_by(recording_name, trial_number, looking_stretch_id) %>%
  mutate(row = row_number()) %>% 
  mutate(where_looking = case_when(target == TRUE ~ "target",
                                   distractor == TRUE ~ "distractor",
                                   TRUE ~ "neither")) %>%
  filter(where_looking == "target") %>%
  mutate(first_look_dur = max(row_number())*(1000/60)) %>% 
  filter(first_look_dur >= 200) %>%
  group_by(trial_number, recording_name) %>%
  filter(looking_stretch_id == min(looking_stretch_id)) %>% 
  ungroup() %>%
  distinct(recording_name, subject_id, trial_number, media_name, first_look_dur, initial_look) %>%
  ungroup()

first_look_duration_by_subject <- first_look_duration_by_trial %>%
  group_by(recording_name, subject_id) %>%
  summarise(mean_first_look_dur = mean(first_look_dur, na.rm = T),
            sd_first_look_dur = sd(first_look_dur, na.rm = T),
            n_trials_first_look_dur = length(unique(trial_number))) %>%
  ungroup()
 

```

#Split data variables

##### Copy of the Make Variables chunk to revise for split dataset

```{r}

#Split dataset by initial look location - this creates a list, have to use purrr to work with this but can't figure it out
analysis_dataset_split <- analysis_dataset %>%
  group_split(initial_look) %>%
   setNames(unique(analysis_dataset$initial_look))


#1. Proportion looking to target

prop_looking_by_subject_split <- prop_looking_by_trial %>%
  group_by(recording_name, initial_look) %>%
  summarise(mean_prop_looking = mean(prop_looking),
            sd_prop_looking = sd(prop_looking),
            n_trials_prop_looking = length(unique(trial_number))) %>%
  ungroup()

#2. Proportion looking difference 
#Within a pair of pictures A and B, the fixation to picture A relative to B when A was the target, minus the fixation #to A when A was the distractor. FOR SPLIT VERSION, WE ARE FILTERING TO ITEM TRIALS WHERE THE INITIAL LOOK IS THE SAME FOR WHEN THE ITEM IS TARGET AND WHEN IT IS DISTRACTOR

prop_looking_diff_by_item_split <- analysis_dataset %>%
  ungroup()%>%
  filter(noun_onset>= 360 & noun_onset <= 3000)%>%
  dplyr::select(recording_name, recording_timestamp, target_word, distractor_word, target, distractor, initial_look)%>%
  pivot_longer(c(target_word, distractor_word), names_to = "word_type", values_to = "word") %>%
  mutate(looking = case_when(word_type == "target_word" & target == TRUE ~ TRUE,
                             word_type == "distractor_word" & distractor == TRUE ~ TRUE,
                             TRUE ~ FALSE)) %>%
  group_by(recording_name, word_type, word, initial_look) %>%
  #what percent of the time when x is target are kids looking at x, what percent of the time when x is distractor are kids looking at x
  summarise(prop_looking = sum(looking == T, na.rm = T)/n()) %>%
  group_by(word, initial_look, recording_name) %>% 
  #filter to exclude items where the initial look is different for when the word was target vs when it was distractor
  filter(n() > 1) %>%
  ungroup() %>%
  pivot_wider(names_from = "word_type", values_from = "prop_looking") %>%
  filter(!is.na(target_word) & !is.na(distractor_word)) %>%
  mutate(prop_looking_diff = target_word - distractor_word) %>%
  dplyr::select(recording_name, target_word = word, prop_looking_diff, initial_look) %>%
  ungroup() 

prop_looking_diff_by_subject_split <- prop_looking_diff_by_item_split %>%  
  group_by(recording_name, initial_look) %>% #Calculating this variable by subject instead of by trial for the correlation matrix.
  summarise(mean_prop_looking_diff = mean(prop_looking_diff),
            sd_prop_looking_diff = sd(prop_looking_diff),
            n_trials_prop_looking_diff = length(unique(target_word))) %>%
  ungroup() #only 165 kids have data for this variable, because they didn't have enough data/trials included with both words of each yoked pair


#before, this was just counting number of fixations... changed to mean number fixations per trial per child
mean_num_fixations_by_subject_split <- fixations_total_by_trial %>%
  group_by(recording_name, initial_look) %>%
  summarise(mean_number_fixations = mean(number_fixations),
            sd_number_fixations = sd(number_fixations),
            n_trials_number_fixations = length(unique(trial_number))) %>%
  ungroup()
  
#4. Correct first shift to target
#On trials where infants were fixated on the distractor upon hearing the target word (i.e., distractor-initial trials), does the kid shift to the target picture within the 300–1,800 ms window following target word onset, as a proportion of all distractor-initial trials.
  
prop_shifts_distractor_initial_by_subject_split <- prop_shifts_distractor_initial_by_subject
  
prop_shifts_target_initial_by_subject_split <- prop_shifts_target_initial_by_subject

#5. Reaction time

#do we want the latency from noun onset (0) or from window of analysis(360)? Right now using window of analysis

RT_by_subject_split <- RT_by_trial %>%
  group_by(recording_name, initial_look) %>%
  summarise(mean_RT = mean(latency_to_switch, na.rm = T),
            sd_RT = sd(latency_to_switch, na.rm = T),
            n_trials_RT = length(unique(trial_number))) %>%
  ungroup()


#6. Total number of switches between AOIs

number_of_switches_by_subject_split <- number_of_switches_by_trial %>%
  group_by(recording_name, initial_look) %>%
  summarise(total_aoi_switches = sum(total_aoi_switches, na.rm = T),
            n_trials_total_aoi_switches = length(unique(trial_number))) %>%
  ungroup()
  
  

#8. Mean fixation duration during trial
#Mean duration of fixations during the window of analysis within a trial. Mean by subject by trial?

mean_fixation_dur_by_subject_split <- mean_fixation_dur_by_trial %>% 
  group_by(recording_name, initial_look) %>%
  summarise(mean_duration_of_look = mean(duration_of_look, na.rm = T),
            sd_duration_of_look = sd(duration_of_look, na.rm = T),
            n_trials_duration_of_look = length(unique(trial_number))) %>%
  ungroup()


#10. Pupil dilation

#Peak dilation

peak_dilation_by_subject_split <- peak_dilation_by_trial %>%
  group_by(recording_name, initial_look) %>%
  summarise(mean_peak_pupil_size_difference = mean(peak_pupil_size_difference),
            sd_peak_pupil_size_difference = sd(peak_pupil_size_difference),
            n_trials_peak_pupil_size_difference = length(unique(trial_number))) %>%
  ungroup() 
  
#Mean dilation

mean_dilation_by_subject_split <- mean_dilation_by_trial %>%
  group_by(recording_name, initial_look) %>%
  summarise(mean_mean_pupil_size_difference = mean(mean_pupil_size_difference),
            sd_mean_pupil_size_difference = sd(mean_pupil_size_difference),
            n_trials_mean_pupil_size_difference = length(unique(trial_number))) %>%
  ungroup()


#peak latency

peak_pupil_latency_by_subject_split <- peak_pupil_latency_by_trial %>%
  group_by(recording_name, initial_look) %>%
  summarise(mean_peak_pupil_latency = mean(peak_pupil_latency),
            sd_peak_pupil_latency = sd(peak_pupil_latency),
            n_trials_peak_pupil_latency = length(unique(trial_number)))


#11. Duration of first look
### Duration of the first look recorded toward a particular AOI. - To target specifically, with at least 200 ms fixation length

first_look_duration_by_subject_split <- first_look_duration_by_trial %>%
  group_by(recording_name, initial_look) %>%
  summarise(mean_first_look_dur = mean(first_look_dur, na.rm = T),
            sd_first_look_dur = sd(first_look_dur, na.rm = T),
            n_trials_first_look_dur = length(unique(trial_number))) %>%
  ungroup()

```

#Add new variables to one dataset
```{r merging newly created DVs to the original dataset}

#ASM: Got rid of the "initial look column" in some of the datasets because it was causing issues when joining all the datasets together.

prop_shifts_distractor_initial_by_subject <- prop_shifts_distractor_initial_by_subject %>%
  dplyr::select(-initial_look)
prop_shifts_distractor_initial_by_trial <- prop_shifts_distractor_initial_by_trial %>%
  dplyr::select(-initial_look)
prop_shifts_target_initial_by_subject <- prop_shifts_target_initial_by_subject %>%
  dplyr::select(-initial_look)
prop_shifts_target_initial_by_trial <- prop_shifts_target_initial_by_trial %>%
  dplyr::select(-initial_look)


data_new_dvs_by_trial <- analysis_dataset %>%
  distinct(recording_name, trial_number, yoked_pair, target_word, age_months, exp_to_target_lang) %>%
  left_join(prop_looking_by_trial) %>%
  #double check if kids see the same word more than once... if so, this item will be ducplicated in the dataset
  left_join(prop_looking_diff_by_item) %>%
  # commenting out for now until we verify how to do this one left_join(sampling_fixations_total %>% dplyr::select(-subject_id)) %>%
  left_join(fixations_total_by_trial) %>%
  left_join(prop_shifts_distractor_initial_by_trial) %>%
  left_join(prop_shifts_target_initial_by_subject) %>%
  left_join(RT_by_trial) %>%
  left_join(number_of_switches_by_trial) %>%
  left_join(mean_fixation_dur_by_trial) %>%
  left_join(peak_dilation_by_trial) %>%
  left_join(mean_dilation_by_trial) %>%
  left_join(peak_pupil_latency_by_trial) %>%
  left_join(first_look_duration_by_trial) %>%
  ungroup() %>%
  mutate(exp_to_target_lang_centred = (exp_to_target_lang/100)-.5,
         age_months_centred = age_months - 25,
         correct_shift = case_when(correct_shift == T ~ 1,
                                   correct_shift == F ~ 0))

data_new_dvs_by_subject <- analysis_dataset %>%
  distinct(recording_name, age_months, exp_to_target_lang, fre_exp, eng_exp) %>% #Added french and english exposure to be able to calculate balance for some analyses.
  left_join(prop_looking_by_subject) %>%
  #double check if kids see the same word more than once... if so, this item will be ducplicated in the dataset
  left_join(prop_looking_diff_by_subject) %>%
  # commenting out for now until we verify how to do this one left_join(sampling_fixations_total %>% dplyr::select(-subject_id)) %>%
  left_join(mean_num_fixations_by_subject) %>%
  left_join(prop_shifts_target_initial_by_subject) %>%
  left_join(prop_shifts_distractor_initial_by_subject) %>%
  left_join(RT_by_subject) %>%
  left_join(number_of_switches_by_subject) %>%
  left_join(mean_fixation_dur_by_subject) %>%
  left_join(peak_dilation_by_subject) %>%
  left_join(mean_dilation_by_subject) %>%
  left_join(peak_pupil_latency_by_subject) %>%
  left_join(first_look_duration_by_subject) %>%
  ungroup()%>%
  mutate(exp_to_target_lang_centred = (exp_to_target_lang/100)-.5,
         age_months_centred = age_months - 25)


#export to later get means, SDs for calculating Cohen's D when dataset is run with the other experimental type
data_new_dvs_by_subject %>% write_csv(here(paste0("AlL_DVs_datasets/by_subject_means_sds_", analysis_type, ".csv")))


#How many trials in average when we collapse by subject?

data_new_dvs_by_trial %>%
  group_by(recording_name) %>%
    summarise(num_trials = length(unique(trial_number))) %>%
    summarise(avg_num_trials = mean(num_trials))


#Save datasets (run depending on which dataset is loaded)

#Non-Experimental trials 
#save(data_new_dvs_by_subject, file= here("ALL_DVs_datasets/kbh_bysubject_nonexperimental.Rda"))

#Experimental trials

#save(data_new_dvs_by_subject, file= here("ALL_DVs_datasets/kbh_bysubject_experimental.Rda"))


```

#Add new split variables to one dataset

```{r}
#this one is for by subject variables only, since by trial would not be different because each trial only has one initial look location value

data_new_dvs_by_subject_split <- analysis_dataset %>%
  distinct(recording_name, age_months, exp_to_target_lang, initial_look) %>%
  left_join(prop_looking_by_subject_split) %>%
  #double check if kids see the same word more than once... if so, this item will be ducplicated in the dataset
  left_join(prop_looking_diff_by_subject_split) %>%
  # commenting out for now until we verify how to do this one left_join(sampling_fixations_total %>% dplyr::select(-subject_id)) %>%
  left_join(mean_num_fixations_by_subject_split) %>%
  left_join(number_of_switches_by_subject_split) %>%
  left_join(mean_fixation_dur_by_subject_split) %>%
  left_join(peak_dilation_by_subject_split) %>%
  left_join(mean_dilation_by_subject_split) %>%
  left_join(peak_pupil_latency_by_subject_split) %>%
  left_join(first_look_duration_by_subject_split) %>%
  left_join(prop_shifts_distractor_initial_by_subject) %>%
  left_join(prop_shifts_target_initial_by_subject) %>%
  ungroup()%>%
  mutate(exp_to_target_lang_centred = (exp_to_target_lang/100)-.5,
         age_months_centred = age_months - 25)


data_new_dvs_by_subject_split %>% write_csv(here(paste0("split_by_subject_means_sds_", analysis_type, ".csv")))



#How many trials in each split of the data?

analysis_dataset %>%
  group_by(initial_look, recording_name) %>%
    summarise(num_trials = length(unique(trial_number))) %>%
  group_by(initial_look) %>%
    summarise(avg_num_trials = mean(num_trials))


#Save split datasets (run depending on which dataset is loaded)
#Non-Experimental trials

#save(data_new_dvs_by_subject_split, file= here("ALL_DVs_datasets/kbh_split_bysubject_nonexperimental.Rda"))

#Experimental trials

#save(data_new_dvs_by_subject_split2, file= here("ALL_DVs_datasets/kbh_split_bysubject_experimental.Rda"))

```


#ICC Calculation - can use for both exp and non-exp

```{r}
#--------------------------------------HK note: below I have calculated the ICC for all variables with the same code chunk, eliminating the need for the rest of the pieces in this chunk. However, when it runs, we are getting quite a few singular fit warnings

exp_icc_all_varaibles <- data_new_dvs_by_trial %>%
   dplyr::select(c(recording_name, prop_looking, prop_looking_diff, number_fixations, correct_shift, mean_prop_shift_target_initial, latency_to_switch, total_aoi_switches, duration_of_look, peak_pupil_size_difference, mean_pupil_size_difference, peak_pupil_latency, first_look_dur)) %>%
  mutate(study = str_extract(recording_name, ".*(?=_S)"),
         study = str_remove(study, "_")) %>%
  pivot_longer(prop_looking:first_look_dur, names_to = "variable", values_to = "response") %>%
  group_by(recording_name, variable) %>%
  mutate(ntrial = row_number()) %>%
  pivot_wider(names_from = ntrial, values_from = response) %>%
ungroup() %>%
  group_by(study, variable)%>%
  group_modify(~ tibble(icc = as.data.frame(list(ICC(.x[sapply(.x, is.numeric)], missing = FALSE, lmer = TRUE, alpha = 0.05)$results))) %>% filter(icc$type == "ICC3k") %>% mutate(rater_type = "Average_fixed_raters")) %>%
  unnest(icc)
  
exp_icc_across_studies_mean<- exp_icc_all_varaibles %>%
  mutate(variable = str_replace(variable, "prop", "proportion")) %>%
  mutate(variable = case_when(variable == "latency_to_switch" ~ "Reaction time",
                              variable == "first_look_dur" ~ "First look duration",
                              variable == "duration_of_look" ~ "Mean duration of looks",
                              variable == "correct_shift" ~ "Proportion trials shifting to target",
                              variable == "mean_prop_shift_target_initial" ~ "Proportion trials staying on target",
                              TRUE ~ snakecase::to_sentence_case(variable))) %>%
  group_by(variable) %>%
  dplyr::summarize(ICC= mean(ICC))

exp_icc_all_varaibles %>%
  mutate(variable = str_replace(variable, "prop", "proportion")) %>%
  mutate(variable = case_when(variable == "latency_to_switch" ~ "Reaction time",
                              variable == "first_look_dur" ~ "First look duration",
                              variable == "duration_of_look" ~ "Mean duration of looks",
                              variable == "correct_shift" ~ "Proportion trials shifting to target",
                              variable == "mean_prop_shift_target_initial" ~ "Proportion trials staying on target",
                              TRUE ~ snakecase::to_sentence_case(variable))) %>% 
  ggplot(aes(x = ICC, y = variable, color = study)) +
  geom_point(size=3, alpha = .75)+
  #geom_errorbarh(aes(xmin=all_dvs_c$CI_lower, xmax=all_dvs_c$CI_upper))+
  geom_point(data = exp_icc_across_studies_mean, aes(x = ICC, y = variable), shape = 18, size = 4, color = "black") +
  labs(x = "ICC",
       y = "Variable",
       title = paste0("Distribution of ICC across variables and studies\n(", str_to_title(analysis_type), " trials)"),
       color = "Study") +
  theme_minimal()+
  theme(plot.background = element_rect(fill = "white")) +
  scale_x_continuous(limits = c(0,1))
  
ggsave(here::here(paste0("figures/kbh_icc_plot_", analysis_type, ".png")))

```


#Correlation matrix
```{r correlation matrix between DVs}

#Select only numerical variables for correlation

#PEARSON CORRELATION
for_correlation_with_age_lang_centred<- data_new_dvs_by_subject %>%
  dplyr::select(where(is.numeric)) %>%
  dplyr::select(-fre_exp, -eng_exp, -exp_to_target_lang, -age_months) %>%
  dplyr::select(-contains("n_trials"), -contains("sd_"))

for_correlation_no_age_lang_centred<- data_new_dvs_by_subject %>%
  dplyr::select(where(is.numeric)) %>%
  dplyr::select(-contains("centred"))  %>%
  dplyr::select(-fre_exp, -eng_exp) %>%
  dplyr::select(-contains("n_trials"), -contains("sd_"))

kbh_correlation <- cor(x=for_correlation_no_age_lang_centred, use="pairwise.complete.obs")

kbh_correlation_2<- rcorr(as.matrix(for_correlation_no_age_lang_centred))

# Extract p-values
p_values <- kbh_correlation_2$P

# Flatten the matrix to adjust p-values
p_values_flat <- as.vector(p_values)

# Adjust p-values using Bonferroni correction
p_values_adj <- p.adjust(p_values_flat, method = "bonferroni")

# Convert the adjusted p-values back to a matrix
p_values_adj_matrix <- matrix(p_values_adj, ncol = ncol(for_correlation_no_age_lang_centred))

test<- as.data.frame(p_values_adj_matrix, options(scipen = 999, digits = 4)) 
  

#plotting the correlation

#Change column and row names to look nicer on plot in real words
colnames(kbh_correlation) <- c("Age in months", "Exposure to target language", "Proportion looking", "Proportion looking difference", "Total number of fixations", "Proportion trials staying on target", "Proportion trials shifting to target", "Mean reaction time", "Total number of AOI switches", "Mean duration of all looks", "Peak pupil size difference", "Mean pupil size difference", "Time to peak pupil", "Mean duration of first look")
rownames(kbh_correlation) <- c("Age in months", "Exposure to target language", "Proportion looking", "Proportion looking difference", "Total number of fixations", "Proportion trials staying on target", "Proportion trials shifting to target", "Mean reaction time", "Total number of AOI switches", "Mean duration of all looks", "Peak pupil size difference", "Mean pupil size difference", "Time to peak pupil", "Mean duration of first look")

#Reorder variables so that they apear in my costum order

custom_order<- c("Age in months", "Exposure to target language", "Proportion looking", "Proportion looking difference","Mean reaction time", "Total number of fixations","Peak pupil size difference",  "Mean pupil size difference", "Time to peak pupil", "Proportion trials shifting to target", "Proportion trials staying on target","Mean duration of all looks", "Mean duration of first look", "Total number of AOI switches")

reordered_kbh_correlation<- kbh_correlation[custom_order, custom_order]

#Create path to save correlation plot as PNG
png(filename= here("archival_KBH_anonimyzed/corrleation_experimental.png"), width = 800, height = 800 )

#Plot:
corrplot(reordered_kbh_correlation, type = 'lower', tl.col = 'black',
         cl.ratio = 0.2, tl.srt = 45, col = COL2('PiYG', 10))

#Closing the PNG graphics device.
dev.off()

#Same graph but with pie charts
corrplot(kbh_correlation, method='pie')


#Try using ggcorrplot instead

#p_mat <- ggcorrplot::cor_pmat(for_correlation_with_age)

ggcorrplot::ggcorrplot(reordered_kbh_correlation,
                       method = "circle",
                       type = "lower",
                       colors = c("#276419", "white", "#8E0152"),
                       ggtheme = ggplot2::theme_bw) +
  ggtitle(paste0("Correlation Matrix (ANON ", analysis_type, ")"))

ggsave(here::here(paste0("figures/kbh_corrleation_", analysis_type, ".png")), width = 8, height = 8)

#SPEARMAN CORRELATION
# to see the plot without the age variable, change x= to for_correlation_no_age_lang_centred
kbh_correlation_s <- cor(x=for_correlation_with_age_lang_centred, use="pairwise.complete.obs", method = "spearman")

corrplot(kbh_correlation_s)


```


#By Subject Cohen's D- All data

```{r}
#If this throws an error, it probably means the by-subject means and SDs file hasn't been generated. Run the script without this chunk to generate it, then try again using the opposite analysis type variable.

experimental_means_sds <- read_csv(here("by_subject_means_sds_experimental.csv"))

non_experimental_means_sds <- read_csv(here("by_subject_means_sds_non-experimental.csv"))


for_cohens_d <- experimental_means_sds %>%
  inner_join(non_experimental_means_sds, by=c("recording_name", "age_months", "exp_to_target_lang", "fre_exp", "eng_exp"),
             suffix = c("_exper", "_nonexper"))


#First create a dataset with by study information that we can use to calculate a by study Cohens'D 

mean_by_study <- for_cohens_d %>%
 ungroup() %>%
   mutate(study = sub("_.*", "", recording_name)) %>%
  mutate(study = case_when(str_detect(recording_name, "Mix_14")~"Mix14",
                           str_detect(recording_name, "Mix_20")~"Mix20",
                          TRUE~ study)        
)

#establish a critical value for alfa = 0.05 to later calculate 95% confidence intervals

crit_value<- qnorm(1-((0.05)/(2)))

#---------------------------------------HK note: this chunk (below) was in an older version of this script on GitHub but not the most recent one... not sure if it got deleted on purpose or by accident, but adding it back in just in case it's useful for the Cohen's D graphs. It does all the variables at the same time so you don't have to have so many bits and pieces done separately.

#HK note: make data long with column indicating analysis dataset type (experimental versus non), one column for means, one for SDs, then can calculate Cohen's D by row for each variable type. Put both means SDs dataframes into one dataframe.
experimental_means_sds_long <- experimental_means_sds %>%
  rename(mean_prop_shift_distractor_initial = prop_shift_distractor_initial,
         mean_total_aoi_switches = total_aoi_switches) %>%
  pivot_longer(c(starts_with("mean_"), starts_with("sd_"), starts_with("n_trials_")), names_to = "variable", values_to = "value") %>%
  separate(variable, into = c("var_type", "variable"), sep = "(?<=^mean|sd|n_trials)_") %>%
  mutate(var_type = paste0("experimental_", var_type)) %>%
  pivot_wider(names_from = "var_type", values_from = "value") %>%
  filter(variable != "total_aoi_switches") #HK note: I don't remember exactly why we removed this, but there is no SD for this variable in the csv files we read in for the Cohen's D stuff so if we want to include it, we'll have to remake those I think
non_experimental_means_sds_long <- non_experimental_means_sds %>%
  rename(mean_prop_shift_distractor_initial = prop_shift_distractor_initial) %>%
 pivot_longer(c(starts_with("mean_"), starts_with("sd_"), starts_with("n_trials_")), names_to = "variable", values_to = "value") %>%
  separate(variable, into = c("var_type", "variable"), sep = "(?<=^mean|sd|n_trials)_") %>%
  mutate(var_type = paste0("non_experimental_", var_type)) %>%
  pivot_wider(names_from = "var_type", values_from = "value") %>%
  filter(variable != "total_aoi_switches")
cohens_ds <- experimental_means_sds_long %>%
  inner_join(non_experimental_means_sds_long %>% dplyr::select(recording_name, variable, contains("_mean"), contains("_sd"), contains("_n_trials"))) %>%
  mutate(pooled_sd = sqrt(((non_experimental_n_trials - 1) * non_experimental_sd^2 + (experimental_n_trials - 1) * experimental_sd^2) / (non_experimental_n_trials + experimental_n_trials - 2)),
         cohens_d = (non_experimental_mean - experimental_mean) / pooled_sd,
         study = str_replace(str_extract(recording_name, ".*(?=_S.*)"), "_", ""))
#These kids are in the experimental dataset but not the non-experimental one, so cannot calculate Cohen's D:
experimental_means_sds %>% filter(recording_name %notin% non_experimental_means_sds$recording_name) %>% count(recording_name)
#These kids are in the non-experimental dataset but not the experimental one, so cannot calculate Cohen's D:
non_experimental_means_sds %>% filter(recording_name %notin% experimental_means_sds$recording_name) %>% count(recording_name)

cohens_ds_all_variables <- cohens_ds %>% 
  group_by(study, variable) %>% 
  dplyr::summarize(n_experimental = sum(!is.na(experimental_mean)),
                   n_non_experimental = sum(!is.na(non_experimental_mean)), 
                   experimental_means= mean(experimental_mean, na.rm=T),
                   non_experimental_means= mean(non_experimental_mean, na.rm=T),
                   experimental_sd= sd(experimental_mean, na.rm=T),
                   non_experimental_sd= sd(non_experimental_mean, na.rm=T)) %>% 
  rename(experimental_mean = experimental_means, 
         non_experimental_mean = non_experimental_means) %>%
  mutate(pooled_sd = sqrt((((n_experimental-1)*(experimental_sd^2))+((n_non_experimental-1)*(non_experimental_sd^2)))/((n_experimental+n_non_experimental)-2))) %>%
  mutate(cohen_d = (experimental_mean-non_experimental_mean)/pooled_sd) %>%
  mutate(SE=sqrt(((n_experimental+n_non_experimental)/(n_experimental*n_non_experimental))+
                        ((cohen_d^2)/(2*(n_experimental+n_non_experimental))))) %>%
  mutate(CI_lower = (cohen_d-(crit_value*SE))) %>%
  mutate(CI_upper = (cohen_d+(crit_value*SE))) %>% 
  ungroup() %>%
  mutate(across(c(cohen_d, CI_lower, CI_upper), abs))

# #Create cohen's d visualization
 
cohens_ds_across_studies_mean<- cohens_ds_all_variables %>%
  mutate(variable = case_when(variable == "RT" ~ "Reaction time",
                              variable == "first_look_dur" ~ "First look duration",
                              variable == "prop_shift_distractor_initial" ~ "proportion trials shifting to target",
                              variable == "prop_shift_target_initial" ~ "proportion trials staying on target",
                              TRUE ~ snakecase::to_sentence_case(variable))) %>%
  group_by(variable) %>%
  dplyr::summarize(cohen_d= abs(mean(cohen_d)))

cohens_ds_all_variables %>%
  mutate(variable = case_when(variable == "RT" ~ "Reaction time",
                              variable == "first_look_dur" ~ "First look duration",
                              variable == "prop_shift_distractor_initial" ~ "proportion trials shifting to target",
                              variable == "prop_shift_target_initial" ~ "proportion trials staying on target",
                              TRUE ~ snakecase::to_sentence_case(variable))) %>%
  ggplot(aes(x = cohen_d, y = variable, color = study)) +
  geom_point(size=3)+
  #geom_errorbarh(aes(xmin=all_dvs_c$CI_lower, xmax=all_dvs_c$CI_upper))+
  geom_point(data = cohens_ds_across_studies_mean, aes(x = cohen_d, y = variable), shape = 18, size = 4, color = "black") +
  labs(x = "Cohen's D",
       y = "Variable",
       title = "Distribution of Cohen's D across variables and studies",
       color = "Study") +
  theme_minimal()+
  theme(plot.background = element_rect(fill = "white")) +
  scale_x_continuous(limits = c(0,1))
  
#ggsave(here::here("cohens_d_plot.png"))

```


#By subject Cohen's D - distractor initial
###Hilary's one-chunk version
```{r}


experimental_means_sds_distractor_initial <- read_csv(here("split_by_subject_means_sds_experimental.csv")) %>%
  filter(initial_look == "distractor")

non_experimental_means_sds_distractor_initial <- read_csv(here("split_by_subject_means_sds_non-experimental.csv")) %>%
  filter(initial_look == "distractor")

#HK note: make data long with column indicating analysis dataset type (experimental versus non), one column for means, one for SDs, then can calculate Cohen's D by row for each variable type. Put both means SDs dataframes into one dataframe.
experimental_means_sds_long_distractor_initial <- experimental_means_sds_distractor_initial %>%
  rename(mean_prop_shift_distractor_initial = prop_shift_distractor_initial,
         mean_total_aoi_switches = total_aoi_switches) %>%
  pivot_longer(c(starts_with("mean_"), starts_with("sd_"), starts_with("n_trials_")), names_to = "variable", values_to = "value") %>%
  separate(variable, into = c("var_type", "variable"), sep = "(?<=^mean|sd|n_trials)_") %>%
  mutate(var_type = paste0("experimental_", var_type)) %>%
  pivot_wider(names_from = "var_type", values_from = "value") %>%
  filter(variable != "total_aoi_switches") #HK note: I don't remember exactly why we removed this, but there is no SD for this variable in the csv files we read in for the Cohen's D stuff so if we want to include it, we'll have to remake those I think
non_experimental_means_sds_long_distractor_initial <- non_experimental_means_sds_distractor_initial %>%
  rename(mean_prop_shift_distractor_initial = prop_shift_distractor_initial) %>%
 pivot_longer(c(starts_with("mean_"), starts_with("sd_"), starts_with("n_trials_")), names_to = "variable", values_to = "value") %>%
  separate(variable, into = c("var_type", "variable"), sep = "(?<=^mean|sd|n_trials)_") %>%
  mutate(var_type = paste0("non_experimental_", var_type)) %>%
  pivot_wider(names_from = "var_type", values_from = "value") %>%
  filter(variable != "total_aoi_switches")

cohens_ds_distractor_initial <- experimental_means_sds_long_distractor_initial %>%
  inner_join(non_experimental_means_sds_long_distractor_initial %>% dplyr::select(recording_name, variable, contains("_mean"), contains("_sd"), contains("_n_trials"))) %>%
  mutate(pooled_sd = sqrt(((non_experimental_n_trials - 1) * non_experimental_sd^2 + (experimental_n_trials - 1) * experimental_sd^2) / (non_experimental_n_trials + experimental_n_trials - 2)),
         cohens_d = (non_experimental_mean - experimental_mean) / pooled_sd,
         study = str_replace(str_extract(recording_name, ".*(?=_S.*)"), "_", ""))
#These kids are in the experimental dataset but not the non-experimental one, so cannot calculate Cohen's D:
experimental_means_sds_distractor_initial %>% filter(recording_name %notin% non_experimental_means_sds_distractor_initial$recording_name) %>% count(recording_name)
#These kids are in the non-experimental dataset but not the experimental one, so cannot calculate Cohen's D:
non_experimental_means_sds_distractor_initial %>% filter(recording_name %notin% experimental_means_sds_distractor_initial$recording_name) %>% count(recording_name)

cohens_ds_all_variables_distractor_initial <- cohens_ds_distractor_initial %>% 
  group_by(study, variable) %>% 
  dplyr::summarize(n_experimental = sum(!is.na(experimental_mean)),
                   n_non_experimental = sum(!is.na(non_experimental_mean)), 
                   experimental_means= mean(experimental_mean, na.rm=T),
                   non_experimental_means= mean(non_experimental_mean, na.rm=T),
                   experimental_sd= sd(experimental_mean, na.rm=T),
                   non_experimental_sd= sd(non_experimental_mean, na.rm=T)) %>% 
  rename(experimental_mean = experimental_means, 
         non_experimental_mean = non_experimental_means) %>%
  mutate(pooled_sd = sqrt((((n_experimental-1)*(experimental_sd^2))+((n_non_experimental-1)*(non_experimental_sd^2)))/((n_experimental+n_non_experimental)-2))) %>%
  mutate(cohen_d = (experimental_mean-non_experimental_mean)/pooled_sd) %>%
  mutate(SE=sqrt(((n_experimental+n_non_experimental)/(n_experimental*n_non_experimental))+
                        ((cohen_d^2)/(2*(n_experimental+n_non_experimental))))) %>%
  mutate(CI_lower = (cohen_d-(crit_value*SE))) %>%
  mutate(CI_upper = (cohen_d+(crit_value*SE))) %>% 
  ungroup() %>%
  mutate(across(c(cohen_d, CI_lower, CI_upper), abs)) %>%
  filter(variable != "prop_shift_target_initial")

# #Create cohen's d visualization
 
cohens_ds_across_studies_mean_distractor_initial<- cohens_ds_all_variables_distractor_initial %>%
  #remove prop looking diff because it's wacky
  filter(variable != "prop_looking_diff") %>%
  mutate(variable = case_when(variable == "RT" ~ "Reaction time",
                              variable == "first_look_dur" ~ "First look duration",
                                                            variable == "prop_shift_distractor_initial" ~ "proportion trials shifting to target",
                              TRUE ~ snakecase::to_sentence_case(variable))) %>%
  group_by(variable) %>%
  dplyr::summarize(cohen_d= abs(mean(cohen_d)))

cohens_ds_all_variables_distractor_initial %>%
  #remove prop looking diff because it's wacky
  filter(variable != "prop_looking_diff") %>%
  mutate(variable = case_when(variable == "RT" ~ "Reaction time",
                              variable == "first_look_dur" ~ "First look duration",
                                                            variable == "prop_shift_distractor_initial" ~ "proportion trials shifting to target",
                              TRUE ~ snakecase::to_sentence_case(variable))) %>%
  ggplot(aes(x = cohen_d, y = variable, color = study)) +
  geom_point(size=3, alpha = .75)+
  #geom_errorbarh(aes(xmin=all_dvs_c$CI_lower, xmax=all_dvs_c$CI_upper))+
  geom_point(data = cohens_ds_across_studies_mean_distractor_initial, aes(x = cohen_d, y = variable), shape = 18, size = 4, color = "black") +
  labs(x = "Cohen's D",
       y = "Variable",
       title = "Distribution of Cohen's D across variables and studies\n(Distractor-initial trials)",
       color = "Study") +
  theme_minimal()+
  theme(plot.background = element_rect(fill = "white")) +
  scale_x_continuous(limits = c(0,1))
  
#ggsave(here::here("cohens_d_plot_distractor_initial.png"))

```


#By subject Cohen's D- target initial
###Hilary's one-chunk version

```{r}


experimental_means_sds_target_initial <- read_csv(here("split_by_subject_means_sds_experimental.csv")) %>%
  filter(initial_look == "target")

non_experimental_means_sds_target_initial <- read_csv(here("split_by_subject_means_sds_non-experimental.csv")) %>%
  filter(initial_look == "target")


#HK note: make data long with column indicating analysis dataset type (experimental versus non), one column for means, one for SDs, then can calculate Cohen's D by row for each variable type. Put both means SDs dataframes into one dataframe.
experimental_means_sds_long_target_initial <- experimental_means_sds_target_initial %>%
  rename(mean_total_aoi_switches = total_aoi_switches) %>%
  pivot_longer(c(starts_with("mean_"), starts_with("sd_"), starts_with("n_trials_")), names_to = "variable", values_to = "value") %>%
  separate(variable, into = c("var_type", "variable"), sep = "(?<=^mean|sd|n_trials)_") %>%
  mutate(var_type = paste0("experimental_", var_type)) %>%
  pivot_wider(names_from = "var_type", values_from = "value") %>%
  filter(variable != "total_aoi_switches") #HK note: I don't remember exactly why we removed this, but there is no SD for this variable in the csv files we read in for the Cohen's D stuff so if we want to include it, we'll have to remake those I think
non_experimental_means_sds_long_target_initial <- non_experimental_means_sds_target_initial %>%
 pivot_longer(c(starts_with("mean_"), starts_with("sd_"), starts_with("n_trials_")), names_to = "variable", values_to = "value") %>%
  separate(variable, into = c("var_type", "variable"), sep = "(?<=^mean|sd|n_trials)_") %>%
  mutate(var_type = paste0("non_experimental_", var_type)) %>%
  pivot_wider(names_from = "var_type", values_from = "value") %>%
  filter(variable != "total_aoi_switches")
  
cohens_ds_target_initial <- experimental_means_sds_long_target_initial %>%
  inner_join(non_experimental_means_sds_long_target_initial %>% dplyr::select(recording_name, variable, contains("_mean"), contains("_sd"), contains("_n_trials"))) %>%
  mutate(pooled_sd = sqrt(((non_experimental_n_trials - 1) * non_experimental_sd^2 + (experimental_n_trials - 1) * experimental_sd^2) / (non_experimental_n_trials + experimental_n_trials - 2)),
         cohens_d = (non_experimental_mean - experimental_mean) / pooled_sd,
         study = str_replace(str_extract(recording_name, ".*(?=_S.*)"), "_", ""))
#These kids are in the experimental dataset but not the non-experimental one, so cannot calculate Cohen's D:
experimental_means_sds_target_initial %>% filter(recording_name %notin% non_experimental_means_sds_target_initial$recording_name) %>% count(recording_name)
#These kids are in the non-experimental dataset but not the experimental one, so cannot calculate Cohen's D:
non_experimental_means_sds_target_initial %>% filter(recording_name %notin% experimental_means_sds_target_initial$recording_name) %>% count(recording_name)

cohens_ds_all_variables_target_initial <- cohens_ds_target_initial %>% 
  group_by(study, variable) %>% 
  dplyr::summarize(n_experimental = sum(!is.na(experimental_mean)),
                   n_non_experimental = sum(!is.na(non_experimental_mean)), 
                   experimental_means= mean(experimental_mean, na.rm=T),
                   non_experimental_means= mean(non_experimental_mean, na.rm=T),
                   experimental_sd= sd(experimental_mean, na.rm=T),
                   non_experimental_sd= sd(non_experimental_mean, na.rm=T)) %>% 
  rename(experimental_mean = experimental_means, 
         non_experimental_mean = non_experimental_means) %>%
  mutate(pooled_sd = sqrt((((n_experimental-1)*(experimental_sd^2))+((n_non_experimental-1)*(non_experimental_sd^2)))/((n_experimental+n_non_experimental)-2))) %>%
  mutate(cohen_d = (experimental_mean-non_experimental_mean)/pooled_sd) %>%
  mutate(SE=sqrt(((n_experimental+n_non_experimental)/(n_experimental*n_non_experimental))+
                        ((cohen_d^2)/(2*(n_experimental+n_non_experimental))))) %>%
  mutate(CI_lower = (cohen_d-(crit_value*SE))) %>%
  mutate(CI_upper = (cohen_d+(crit_value*SE))) %>% 
  ungroup() %>%
  mutate(across(c(cohen_d, CI_lower, CI_upper), abs)) %>%
  filter(variable != "prop_shift_distractor_initial")

# #Create cohen's d visualization
 
cohens_ds_across_studies_mean_target_initial<- cohens_ds_all_variables_target_initial %>%
  #remove prop looking diff because it's wacky
  filter(variable != "prop_looking_diff") %>%
  mutate(variable = case_when(variable == "RT" ~ "Reaction time",
                              variable == "first_look_dur" ~ "First look duration",
                              variable == "prop_shift_target_initial" ~ "proportion trials staying on target",
                              TRUE ~ snakecase::to_sentence_case(variable))) %>%
  group_by(variable) %>%
  dplyr::summarize(cohen_d= abs(mean(cohen_d)))

cohens_ds_all_variables_target_initial %>%
  #remove prop looking diff because it's wacky
  filter(variable != "prop_looking_diff") %>%
  mutate(variable = case_when(variable == "RT" ~ "Reaction time",
                              variable == "first_look_dur" ~ "First look duration",
                              variable == "prop_shift_target_initial" ~ "proportion trials staying on target",
                              TRUE ~ snakecase::to_sentence_case(variable))) %>%
  ggplot(aes(x = cohen_d, y = variable, color = study)) +
  geom_point(size=3, alpha = .75)+
  #geom_errorbarh(aes(xmin=all_dvs_c$CI_lower, xmax=all_dvs_c$CI_upper))+
  geom_point(data = cohens_ds_across_studies_mean_target_initial, aes(x = cohen_d, y = variable), shape = 18, size = 4, color = "black") +
  labs(x = "Cohen's D",
       y = "Variable",
       title = "Distribution of Cohen's D across variables and studies\n(Target-initial trials)",
       color = "Study") +
  theme_minimal()+
  theme(plot.background = element_rect(fill = "white")) +
  scale_x_continuous(limits = c(0,1))
  
#ggsave(here::here("cohens_d_plot_target_initial.png"))

```



#Factor analysis
```{r}

for_factor_analysis <- for_correlation_with_age_lang_centred %>%
  dplyr::select(-c(age_months_centred, exp_to_target_lang_centred)) %>%
  as.matrix()

for_factor_analysis_noshift <- for_correlation_with_age_lang_centred %>%
  dplyr::select(-c(prop_shift_distractor_initial, mean_prop_shift_target_initial, age_months_centred, exp_to_target_lang_centred)) %>%
  as.matrix()

#We are sticking with ss loads above 1 so that leaves us with 2 factors.
fac_table_with_shifts <- unclass(psych::fac(for_factor_analysis, nfactors = 2)$loadings)

fac_tibble_with_shifts <- fac_table_with_shifts %>%
  as_tibble(.) %>%
  mutate(variable = dimnames(fac_table_with_shifts)[[1]]) %>%
  select(variable, everything()) 

fac_tibble_with_shifts %>% write_csv(here(paste0("kbh_factor_analysis_table_", analysis_type, ".csv")))

fac_tibble_with_shifts %>%
  # mutate(MR1 = abs(MR1),
  #        MR2 = abs(MR2)) %>%
  ggplot(aes(x = MR1, y = MR2, color = variable)) +
  geom_point() +
  geom_text(aes(label = variable)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_vline(xintercept = 0, linetype = "dashed")


fac_table_with_shifts_for_plot <- psych::fac(for_factor_analysis, nfactors = 2)

biplot.psych(fac_table_with_shifts_for_plot,
             # labels=iris[,5],
             # choose = c(1,2),
             pch= c(16, 16, 16)
             #group = iris[,"Species"]
             )


#Mention in a write up that without the only distractor trials the factors are quite similar so we are quite confident it is not an artifact.
psych::fac(for_factor_analysis_noshift, nfactors = 2)


#Proportion looking tends to be good because it considers both distractor initial and target initial trials. But there are other variables like number of fixations that might be good but just for certain types of trials e.g. target initial.

#Pupil is cool as a measure of surprise if they are looking at the wrong thing (distractor initial) but not during target initial trials.

#We want to ultimately give reccomendations. Is there a measure that's more robust, best for manipulations, if it only works for a type of trial, like target initial you are halving your data, so is that best? We might run reliability measures by child by trial.

```







# Models 

Make the following models for each of our variables as the outcome

proportion_looking ~ age + experience + (1|subject) + (1|item)
proportion_looking ~ age + experience + age*experience + (1|subject) + (1|item)

```{r}

#Prop Looking Models
prop_looking_simple <- lm(prop_looking ~ age_months_centred + exp_to_target_lang_centred, 
                            data = data_new_dvs_by_subject)
summary(prop_looking_simple)

prop_looking_interaction <- lm (prop_looking ~ age_months_centred*exp_to_target_lang_centred,
                            data = data_new_dvs_by_subject)
summary(prop_looking_interaction)


#Prop Looking Diff Models
prop_looking_diff_simple <- lm (prop_looking_diff ~ age_months_centred + exp_to_target_lang_centred, 
                            data = data_new_dvs_by_subject)
summary(prop_looking_diff_simple)

prop_looking_diff_interaction <- lm (prop_looking_diff ~ age_months_centred*exp_to_target_lang_centred,
                            data = data_new_dvs_by_subject)
summary(prop_looking_diff_interaction)


#Number fixations Models
number_fixations_simple <- lm (number_fixations ~ age_months_centred + exp_to_target_lang_centred,
                            data = data_new_dvs_by_subject)
summary(number_fixations_simple)

number_fixations_interaction <- lm (number_fixations ~ age_months_centred*exp_to_target_lang_centred, 
                            data = data_new_dvs_by_subject)
summary(number_fixations_interaction)


#Latency to switch Models
latency_to_switch_simple <- lm (mean_RT ~ age_months_centred + exp_to_target_lang_centred,
                            data = data_new_dvs_by_subject)
summary(latency_to_switch_simple)

latency_to_switch_interaction <- lm (mean_RT ~ age_months_centred*exp_to_target_lang_centred,
                            data = data_new_dvs_by_subject)
summary(latency_to_switch_interaction)


#Number of AOI switches Models
aoi_switches_simple <- lm (total_aoi_switches ~ age_months_centred + exp_to_target_lang_centred, 
                            data = data_new_dvs_by_subject)
summary(aoi_switches_simple)

aoi_switches_interaction <- lm (total_aoi_switches ~ age_months_centred*exp_to_target_lang_centred, 
                            data = data_new_dvs_by_subject)
summary(aoi_switches_interaction)

aoi_switches_interaction2 <- lm (total_aoi_switches ~ age_months_centred*exp_to_target_lang, 
                            data = data_new_dvs_by_subject)

interactions::interact_plot(aoi_switches_interaction2, pred= exp_to_target_lang, modx=age_months_centred, plot.points = T)

#Mean fixation duration Models
mean_fixation_dur_simple <- lm (duration_of_look ~ age_months_centred + exp_to_target_lang_centred, 
                            data = data_new_dvs_by_subject)
summary(mean_fixation_dur_simple)

mean_fixation_dur_interaction <- lm (duration_of_look ~ age_months_centred*exp_to_target_lang_centred, 
                            data = data_new_dvs_by_subject)
summary(mean_fixation_dur_interaction)




#Peak pupil size Models
peak_pupil_simple <- lm (peak_pupil_size_difference ~ age_months_centred + exp_to_target_lang_centred,
                            data = data_new_dvs_by_subject)
summary(peak_pupil_simple)

peak_pupil_interaction <- lm (peak_pupil_size_difference ~ age_months_centred*exp_to_target_lang_centred, 
                            data = data_new_dvs_by_subject)
summary(peak_pupil_interaction)


#Mean pupil size Models
mean_pupil_simple <- lm (mean_pupil_size_difference ~ age_months_centred + exp_to_target_lang_centred,
                            data = data_new_dvs_by_subject)
summary(mean_pupil_simple)

mean_pupil_interaction <- lm (mean_pupil_size_difference ~ age_months_centred*exp_to_target_lang_centred, 
                            data = data_new_dvs_by_subject)
summary(mean_pupil_interaction)


#Peak pupil latency Models
peak_pupil_latency_simple <- lm (peak_pupil_latency ~ age_months_centred + exp_to_target_lang_centred, 
                            data = data_new_dvs_by_subject)
summary(peak_pupil_latency_simple)

peak_pupil_latency_interaction <- lm (peak_pupil_latency ~ age_months_centred*exp_to_target_lang_centred, 
                            data = data_new_dvs_by_subject)
summary(peak_pupil_latency_interaction)


#First look duration Models
first_look_duration_simple <- lm (first_look_dur ~ age_months_centred + exp_to_target_lang_centred, 
                            data = data_new_dvs_by_subject)
summary(first_look_duration_simple)

first_look_duration_interaction <- lm (first_look_dur ~ age_months_centred*exp_to_target_lang_centred, 
                            data = data_new_dvs_by_subject)
summary(first_look_duration_interaction)


#Correct shift to target models

correct_shift_simple <- lm(prop_shift_distractor_initial ~ age_months_centred + exp_to_target_lang_centred, 
                            data = data_new_dvs_by_subject)
summary(correct_shift_simple)

correct_shift_interaction <- lm(prop_shift_distractor_initial ~ age_months_centred*exp_to_target_lang_centred, 
                            data = data_new_dvs_by_subject)

summary(correct_shift_interaction)


target_stay_simple <-lm(prop_shift_target_initial ~ age_months_centred + exp_to_target_lang_centred, 
                            data = data_new_dvs_by_subject)
summary(target_stay_simple)

target_stay_interaction<- lm(prop_shift_target_initial ~ age_months_centred * exp_to_target_lang_centred, 
                            data = data_new_dvs_by_subject)
summary(target_stay_interaction)


## Contrasting models performance

compare_performance(correct_shift_simple, peak_pupil_latency_simple, mean_pupil_simple, peak_pupil_simple,
                    mean_fixation_dur_simple , aoi_switches_simple, latency_to_switch_simple, prop_looking_diff_simple, number_fixations_simple, prop_looking_simple, target_stay_simple, correct_shift_simple)





```


Models with exposure balance instead of exposure to target language

```{r}
for_balance_models <- data_new_dvs_by_subject %>%
  mutate(balance_score= abs(fre_exp - eng_exp))


#Prop Looking Models
prop_looking_sbalance <- lm(prop_looking ~ age_months_centred + balance_score, 
                            data = for_balance_models)
summary(prop_looking_sbalance)

prop_looking_ibalance <- lm (prop_looking ~ age_months_centred*balance_score,
                            data = for_balance_models)
summary(prop_looking_ibalance)


#Prop Looking Diff Models
prop_looking_diff_sbalance <- lm (prop_looking_diff ~ age_months_centred + balance_score, 
                            data = for_balance_models)
summary(prop_looking_diff_sbalance)

prop_looking_diff_ibalance <- lm (prop_looking_diff ~ age_months_centred*balance_score,
                            data = for_balance_models)
summary(prop_looking_diff_ibalance)


#Number fixations Models
number_fixations_sbalance <- lm (number_fixations ~ age_months_centred + balance_score,
                            data = for_balance_models)
summary(number_fixations_sbalance)

number_fixations_ibalance <- lm (number_fixations ~ age_months_centred*balance_score, 
                            data = for_balance_models)
summary(number_fixations_ibalance)


#Latency to switch Models
latency_to_switch_sbalance <- lm (mean_RT ~ age_months_centred + balance_score,
                            data = for_balance_models)
summary(latency_to_switch_sbalance)

latency_to_switch_ibalance <- lm (mean_RT ~ age_months_centred*balance_score,
                            data = for_balance_models)
summary(latency_to_switch_ibalance)


#Number of AOI switches Models
aoi_switches_sbalance <- lm (total_aoi_switches ~ age_months_centred + balance_score, 
                            data = for_balance_models)
summary(aoi_switches_sbalance)

aoi_switches_ibalance <- lm (total_aoi_switches ~ age_months_centred*balance_score, 
                            data = for_balance_models)
summary(aoi_switches_ibalance)


#Mean fixation duration Models
mean_fixation_dur_sbalance <- lm (duration_of_look ~ age_months_centred + balance_score, 
                            data = for_balance_models)
summary(mean_fixation_dur_sbalance)

mean_fixation_dur_ibalance <- lm (duration_of_look ~ age_months_centred*balance_score, 
                            data = for_balance_models)
summary(mean_fixation_dur_ibalance)




#Peak pupil size Models
peak_pupil_sbalance <- lm (peak_pupil_size_difference ~ age_months_centred + balance_score,
                            data = for_balance_models)
summary(peak_pupil_sbalance)

peak_pupil_ibalance <- lm (peak_pupil_size_difference ~ age_months_centred*balance_score, 
                            data = for_balance_models)
summary(peak_pupil_ibalance)


#Mean pupil size Models
mean_pupil_sbalance <- lm (mean_pupil_size_difference ~ age_months_centred + balance_score,
                            data = for_balance_models)
summary(mean_pupil_sbalance)

mean_pupil_ibalance <- lm (mean_pupil_size_difference ~ age_months_centred*balance_score, 
                            data = for_balance_models)
summary(mean_pupil_ibalance)


#Peak pupil latency Models
peak_pupil_latency_sbalance <- lm (peak_pupil_latency ~ age_months_centred + balance_score, 
                            data = for_balance_models)
summary(peak_pupil_latency_sbalance)

peak_pupil_latency_ibalance <- lm (peak_pupil_latency ~ age_months_centred*balance_score, 
                            data = for_balance_models)
summary(peak_pupil_latency_ibalance)


#First look duration Models
first_look_duration_sbalance <- lm (first_look_dur ~ age_months_centred + balance_score, 
                            data = for_balance_models)
summary(first_look_duration_sbalance)

first_look_duration_ibalance <- lm (first_look_dur ~ age_months_centred*balance_score, 
                            data = for_balance_models)
summary(first_look_duration_sbalance)


#Correct shift to target models

correct_shift_sbalance <- lm(prop_shift_distractor_initial ~ age_months_centred + balance_score, 
                            data = for_balance_models)
summary(correct_shift_sbalance)

correct_shift_ibalance <- lm(prop_shift_distractor_initial ~ age_months_centred*balance_score, 
                            data = for_balance_models)

summary(correct_shift_ibalance)


target_stay_sbalance <-lm(prop_shift_target_initial ~ age_months_centred + balance_score, 
                            data = for_balance_models)
summary(target_stay_sbalance)

target_stay_ibalance<- lm(prop_shift_target_initial ~ age_months_centred * balance_score, 
                            data = for_balance_models)
summary(target_stay_ibalance)


## Contrasting models performance

compare_performance(correct_shift_sbalance, peak_pupil_latency_sbalance, mean_pupil_sbalance, peak_pupil_sbalance,
                    mean_fixation_dur_sbalance , aoi_switches_sbalance, latency_to_switch_sbalance, prop_looking_diff_sbalance, number_fixations_sbalance, prop_looking_sbalance, target_stay_sbalance, correct_shift_sbalance)










```


## Models with split data

```{r}

#Models in nested dataframe

model_data_nested <- data_new_dvs_by_subject_split %>%
  group_by(initial_look) %>%
  nest() 

models_nested <- model_data_nested %>%
  mutate(
    #Prop looking
    prop_looking_simple_split = map(data, ~lm(prop_looking ~ age_months_centred + exp_to_target_lang_centred, 
                            data = .x)),
    #Prop looking diff
         prop_looking_diff_simple_split = map(data, ~lm (prop_looking_diff ~ age_months_centred + exp_to_target_lang_centred, 
                            data = .x)),
    #Number fixations
    number_fixations_simple_split = map(data, ~lm (number_fixations ~ age_months_centred + exp_to_target_lang_centred,
                            data = .x)),
    #Latency to switch
    # latency_to_switch_simple_split = map(data, ~ lm(mean_RT ~ age_months_centred + exp_to_target_lang_centred,
    #                         data = .x)),
    #Number AOI switches
    aoi_switches_simple_split = map(data, ~ lm(total_aoi_switches ~ age_months_centred + exp_to_target_lang_centred, 
                            data = .x)),
    #Mean fixation duration
    mean_fixation_dur_simple_split = map(data, ~lm(duration_of_look ~ age_months_centred + exp_to_target_lang_centred, 
                            data = .x)),
    #Peak pupil size
    peak_pupil_simple_split = map(data, ~lm(peak_pupil_size_difference ~ age_months_centred + exp_to_target_lang_centred,
                            data = .x)),
    #Mean pupil size
    mean_pupil_simple_split = map(data, ~lm(mean_pupil_size_difference ~ age_months_centred + exp_to_target_lang_centred,
                            data = .x)),
    #Peak pupil latency
    peak_pupil_latency_simple_split = map(data, ~lm(peak_pupil_latency ~ age_months_centred + exp_to_target_lang_centred, 
                            data = .x)),
    #First look duration
    first_look_duration_simple_split = map(data, ~lm(first_look_dur ~ age_months_centred + exp_to_target_lang_centred, 
                            data = .x)),
    #Correct shift for distractor initial 
    # correct_shift_simple_split = map(data, ~lm(prop_shift_distractor_initial ~ age_months_centred + exp_to_target_lang_centred, 
    #                         data = .x)),
    # #Staying on target for target initial
    # target_stay_simple_split = map(data, ~lm(prop_shift_target_initial ~ age_months_centred + exp_to_target_lang_centred, 
    #                         data = .x))
         )


## Contrasting models performance

compare_performance(correct_shift_simple , peak_pupil_latency_simple, mean_pupil_simple, peak_pupil_simple,
                    mean_fixation_dur_simple , aoi_switches_simple, latency_to_switch_simple, prop_looking_diff_simple, number_fixations_simple, prop_looking_simple, target_stay_simple, correct_shift_simple)


models_nested_long <- models_nested %>%
  pivot_longer(contains("split"), names_to = "model_name", values_to = "model_object") %>%
  group_by(initial_look) %>%
  nest() 

#Target initial
compare_performance(models_nested_long$data[[1]]$model_object)
#Distractor initial
compare_performance(models_nested_long$data[[2]]$model_object)
#Neither initial
compare_performance(models_nested_long$data[[3]]$model_object)


#Model summaries

models_nested_long %>%
  unnest() %>%
  mutate(model_summary = map(model_object, ~summary(.x))) %>%
  pull(model_summary)

```



#Merge experimental and non experimental DV matrices to fin differences in effects

```{r}
load(here("ALL_DVs_datasets/kbh_split_bysubject_nonexperimental.Rda"))
load(here("ALL_DVs_datasets/kbh_split_bysubject_experimental.Rda"))



kbh_all_conditions <- left_join(data_new_dvs_by_subject_split, data_new_dvs_by_subject_split2, by="recording_name", relationship = "many-to-many")

```








#Check plot
```{r}

#Let's plot raw data split by initial look to make sure models make sense

data_for_check_plot <- analysis_dataset %>%
  filter(noun_onset >= 360 & noun_onset <= 3000) %>%
  make_eyetrackingr_data(., 
                               participant_column = "recording_name",
                               trial_column = "trial_number",
                               time_column = "noun_onset",
                               trackloss_column = "trackloss",
                               aoi_columns = c('target','distractor'),
                               treat_non_aoi_looks_as_missing = TRUE)
  
  
data_for_check_plot %>%
  make_time_sequence_data(., time_bin_size = 100, aois = NULL,
  predictor_columns = c("initial_look"), other_dv_columns = NULL, summarize_by = c("recording_name", "trial_number")) %>%
  ggplot(aes(x = TimeBin, y = Prop, color = AOI)) +
  geom_jitter(alpha = .1, height = .025) +
  geom_smooth() +
  facet_wrap(~initial_look)

#The looking time sequence for target-initial trials seems to have a shallow drop in looking to target over the course of the interest period, as opposed to a sharp rise for distractor-initial trials. This might help explain some of the model differences in significance after splitting by initial look location.


```

